{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Final Project\n",
    "## Transfer learning-based image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Danila Goncharenko, 2303788\n",
    "\n",
    "Ana Ferreira, 2308587\n",
    "\n",
    "Mikhail Bichagov, 2304806\n",
    "\n",
    "Experiments: python=3.9.18, torch=2.1.1, torchvision=0.16.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Students should try their best to improve the classification performance on EuroSAT by using some strategies like data augmentation. (You can follow these steps to complete the project)\n",
    "\n",
    "i. Download and read the [`miniImageNet`](https://drive.google.com/drive/folders/17a09kkqVivZQFggCw9I_YboJ23tcexNM) & [`EuroSAT(RGB)`](https://github.com/phelber/EuroSAT) datasets. (2 points)\n",
    "\n",
    "ii. Pretrain a model (ResNet10, also can be ResNet18, VGG, Vision Transformer, etc.) on the training set of miniImageNet, evaluate & test it on the validation & test set. (7 points)\n",
    "\n",
    "iii. Save the pretrained model. (1 point)\n",
    "\n",
    "iv. Choose 100 images from EuroSAT dataset, which are from 5 different categories and each category includes 25 samples. You should randomly choose 25 images from these 100 samples as training set (The 25 images should be from the 5 different categories. Each category includes 5 images). (3 points)\n",
    "\n",
    "v. Fine-tune the pretrained model with these 25 training images and test it on the rest 75 samples, show the results. Better to fine-tuning several times on different 100 EuroSAT images and get their average result. (7 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 ImageNet: Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting files from train folder\n",
    "\n",
    "#import tarfile\n",
    "#tar_file_path = 'train.tar-20231206T193341Z-001/train.tar'\n",
    "#\n",
    "#with tarfile.open(tar_file_path, 'r') as tar:\n",
    "#    tar.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting files from train google drive folder \n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "# \n",
    "# import tarfile\n",
    "# tar_file_path = '/content/gdrive/MyDrive/train.tar'\n",
    "# \n",
    "# with tarfile.open(tar_file_path, 'r') as tar:\n",
    "#    tar.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: v2 transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:43: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Loading data and splitting it to train, val, test\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "transform = v2.Compose([\n",
    "    v2.Resize((224, 224)), # Resizing to 224x224\n",
    "    v2.ToTensor(), #moving to tensor\n",
    "    #v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalizing not needed as \n",
    "])\n",
    "\n",
    "dataset = torchvision.datasets.ImageFolder('train', transform=transform) # Loading data from train folder\n",
    "\n",
    "trainset, valset, testset = torch.utils.data.random_split(dataset, [0.7, 0.15, 0.15])\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "val_data_loader = torch.utils.data.DataLoader(valset, batch_size=32, shuffle=True)\n",
    "test_data_loader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data and splitting it to train, val, test\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "transform = v2.Compose([\n",
    "    v2.Resize((224, 224)), # Resizing to 224x224\n",
    "    v2.ToTensor(), #moving to tensor\n",
    "    #v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalizing not needed as \n",
    "])\n",
    "\n",
    "dataset = torchvision.datasets.ImageFolder('train', transform=transform) # Loading data from train folder\n",
    "\n",
    "trainset, valset, testset = torch.utils.data.random_split(dataset, [0.7, 0.15, 0.15])\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "val_data_loader = torch.utils.data.DataLoader(valset, batch_size=32, shuffle=True)\n",
    "test_data_loader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: transforms Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data and splitting it to train, val, test\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), # Resizing to 224x224\n",
    "    transforms.ToTensor(), #moving to tensor\n",
    "    #v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalizing not needed as \n",
    "])\n",
    "\n",
    "dataset = torchvision.datasets.ImageFolder('train', transform=transform) # Loading data from train folder\n",
    "\n",
    "train_len = int(0.7 * len(dataset))\n",
    "val_len = int(0.15 * len(dataset))\n",
    "test_len = len(dataset) - train_len - val_len\n",
    "\n",
    "# Split the dataset\n",
    "trainset, valset, testset = torch.utils.data.random_split(dataset, [train_len, val_len, test_len])\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "val_data_loader = torch.utils.data.DataLoader(valset, batch_size=32, shuffle=True)\n",
    "test_data_loader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to calculate accuracy score\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "def get_acc(y_pred, y_true):\n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda.\n"
     ]
    }
   ],
   "source": [
    "## Possible GPU acceleration\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device_name = torch.device(\"cuda\")\n",
    "else:\n",
    "    device_name = torch.device('cpu')\n",
    "print(\"Using {}.\".format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get sample immage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "images, labels = next(iter(train_data_loader))\n",
    "plt.imshow(np.transpose(images[1], (1, 2, 0)))\n",
    "print(labels[1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel Value Range: [0.0, 1.0]\n",
      "Mean and std: [0.43413010239601135, 0.22094067931175232]\n"
     ]
    }
   ],
   "source": [
    "min_pixel_value = torch.min(images[0])\n",
    "max_pixel_value = torch.max(images[0])\n",
    "print(\"Pixel Value Range: [{}, {}]\".format(min_pixel_value, max_pixel_value))\n",
    "mean_value = torch.mean(images[0])\n",
    "std_deviation = torch.std(images[0])\n",
    "print(\"Mean and std: [{}, {}]\".format(mean_value, std_deviation))\n",
    "\n",
    "# print(f'total number of images is {32*len(data_loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Pretrain ResNet18 model on ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to C:\\Users\\dgonchar23/.cache\\torch\\hub\\checkpoints\\resnet18-5c106cde.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7eec9d43540404fa2f42d882ea6e52b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Donwloading ResNet18 model\n",
    "resnet18 = torchvision.models.resnet18(pretrained=True)\n",
    "for param in resnet18.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "resnet18.fc = nn.Linear(512, 64) # Changign last layer to output 64 featurs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in resnet18.named_parameters():\n",
    "#     print(f\"{name}: Requires Grad - {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Training Loss: 1.5190548323449635 | Training Accuracy 0.6434151785714286 \n",
      "                             | Validation loss 0.889075756072998 | Validation Accuracy 0.889075756072998\n",
      "Epoch 2 | Training Loss: 0.8662161051517441 | Training Accuracy 0.7642113095238096 \n",
      "                             | Validation loss 0.7848823070526123 | Validation Accuracy 0.7848823070526123\n",
      "Epoch 3 | Training Loss: 0.7658878141748053 | Training Accuracy 0.7825892857142858 \n",
      "                             | Validation loss 0.7659931182861328 | Validation Accuracy 0.7659931182861328\n",
      "Epoch 4 | Training Loss: 0.7133238522069795 | Training Accuracy 0.7981026785714286 \n",
      "                             | Validation loss 0.7573645114898682 | Validation Accuracy 0.7573645114898682\n",
      "Epoch 5 | Training Loss: 0.6808118347433352 | Training Accuracy 0.8034970238095238 \n",
      "                             | Validation loss 0.8156846761703491 | Validation Accuracy 0.8156846761703491\n",
      "Epoch 6 | Training Loss: 0.6525844637481939 | Training Accuracy 0.8086309523809524 \n",
      "                             | Validation loss 0.7598633170127869 | Validation Accuracy 0.7598633170127869\n",
      "Epoch 7 | Training Loss: 0.6292056190825644 | Training Accuracy 0.8147693452380952 \n",
      "                             | Validation loss 0.779708981513977 | Validation Accuracy 0.779708981513977\n",
      "Epoch 8 | Training Loss: 0.6174768065678932 | Training Accuracy 0.8188988095238096 \n",
      "                             | Validation loss 0.7751737833023071 | Validation Accuracy 0.7751737833023071\n",
      "Epoch 9 | Training Loss: 0.5993628096367631 | Training Accuracy 0.8229166666666666 \n",
      "                             | Validation loss 0.7851784229278564 | Validation Accuracy 0.7851784229278564\n",
      "Epoch 10 | Training Loss: 0.5826867655983993 | Training Accuracy 0.8263020833333333 \n",
      "                             | Validation loss 0.8127302527427673 | Validation Accuracy 0.8127302527427673\n",
      "Epoch 11 | Training Loss: 0.5758021063393071 | Training Accuracy 0.8273065476190476 \n",
      "                             | Validation loss 0.7907009124755859 | Validation Accuracy 0.7907009124755859\n",
      "Epoch 12 | Training Loss: 0.5633750258102304 | Training Accuracy 0.8301711309523809 \n",
      "                             | Validation loss 0.8160175681114197 | Validation Accuracy 0.8160175681114197\n",
      "Epoch 13 | Training Loss: 0.5582570579302099 | Training Accuracy 0.8321800595238096 \n",
      "                             | Validation loss 0.8155527114868164 | Validation Accuracy 0.8155527114868164\n",
      "Epoch 14 | Training Loss: 0.5438188019785143 | Training Accuracy 0.8361235119047619 \n",
      "                             | Validation loss 0.8455811738967896 | Validation Accuracy 0.8455811738967896\n",
      "Epoch 15 | Training Loss: 0.535789246493507 | Training Accuracy 0.8393229166666667 \n",
      "                             | Validation loss 0.8274873495101929 | Validation Accuracy 0.8274873495101929\n",
      "Epoch 16 | Training Loss: 0.5284322164331873 | Training Accuracy 0.8403645833333333 \n",
      "                             | Validation loss 0.8206246495246887 | Validation Accuracy 0.8206246495246887\n",
      "Epoch 17 | Training Loss: 0.5225928457631241 | Training Accuracy 0.8407738095238095 \n",
      "                             | Validation loss 0.8381567597389221 | Validation Accuracy 0.8381567597389221\n",
      "Epoch 18 | Training Loss: 0.5212564539164305 | Training Accuracy 0.8399925595238096 \n",
      "                             | Validation loss 0.8318942785263062 | Validation Accuracy 0.8318942785263062\n",
      "Epoch 19 | Training Loss: 0.503467728827326 | Training Accuracy 0.8468377976190476 \n",
      "                             | Validation loss 0.8544673919677734 | Validation Accuracy 0.8544673919677734\n",
      "Epoch 20 | Training Loss: 0.5078851763513826 | Training Accuracy 0.8425595238095238 \n",
      "                             | Validation loss 0.8526022434234619 | Validation Accuracy 0.8526022434234619\n",
      "Epoch 21 | Training Loss: 0.4974338326337082 | Training Accuracy 0.848735119047619 \n",
      "                             | Validation loss 0.8582520484924316 | Validation Accuracy 0.8582520484924316\n",
      "Epoch 22 | Training Loss: 0.4949307640482272 | Training Accuracy 0.8482142857142857 \n",
      "                             | Validation loss 0.8832570314407349 | Validation Accuracy 0.8832570314407349\n",
      "Epoch 23 | Training Loss: 0.4913807656882065 | Training Accuracy 0.8476190476190476 \n",
      "                             | Validation loss 0.8719629049301147 | Validation Accuracy 0.8719629049301147\n",
      "Epoch 24 | Training Loss: 0.4919656260027772 | Training Accuracy 0.8477306547619048 \n",
      "                             | Validation loss 0.8560838103294373 | Validation Accuracy 0.8560838103294373\n",
      "Epoch 25 | Training Loss: 0.48583115990318004 | Training Accuracy 0.8504092261904762 \n",
      "                             | Validation loss 0.8843113780021667 | Validation Accuracy 0.8843113780021667\n",
      "Epoch 26 | Training Loss: 0.46712789949739264 | Training Accuracy 0.8564732142857143 \n",
      "                             | Validation loss 0.8950945138931274 | Validation Accuracy 0.8950945138931274\n",
      "Epoch 27 | Training Loss: 0.47719778660241335 | Training Accuracy 0.8518973214285714 \n",
      "                             | Validation loss 0.9059619903564453 | Validation Accuracy 0.9059619903564453\n",
      "Epoch 28 | Training Loss: 0.46855594585871413 | Training Accuracy 0.8555803571428572 \n",
      "                             | Validation loss 0.8914188742637634 | Validation Accuracy 0.8914188742637634\n",
      "Epoch 29 | Training Loss: 0.46671560739300083 | Training Accuracy 0.8524925595238095 \n",
      "                             | Validation loss 0.898924708366394 | Validation Accuracy 0.898924708366394\n",
      "Epoch 30 | Training Loss: 0.46972882960523876 | Training Accuracy 0.8524553571428571 \n",
      "                             | Validation loss 0.9061569571495056 | Validation Accuracy 0.9061569571495056\n"
     ]
    }
   ],
   "source": [
    "# Model train with 30 epoch\n",
    "\n",
    "optimizer = torch.optim.Adam(resnet18.parameters())\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "resnet18.to(device)\n",
    "\n",
    "for epoch in range(30):\n",
    "    bce_loss = nn.CrossEntropyLoss()\n",
    "    resnet18.train()\n",
    "    running_train_loss = 0.\n",
    "    running_val_loss = 0.\n",
    "\n",
    "    running_train_acc = 0.\n",
    "    running_val_acc = 0.\n",
    "\n",
    "    for i, data in enumerate(train_data_loader):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred_labels = resnet18.forward(images)\n",
    "\n",
    "        loss = bce_loss(pred_labels, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_train_acc += get_acc(torch.argmax(pred_labels, dim = 1).detach().cpu().numpy(), labels.detach().cpu().numpy())\n",
    "        running_train_loss += loss.item()\n",
    "\n",
    "\n",
    "    resnet18.eval()\n",
    "    for i, data in enumerate(val_data_loader):\n",
    "\n",
    "        images_val, labels_val = data\n",
    "        images_val, labels_val = images_val.to(device), labels_val.to(device)\n",
    "\n",
    "\n",
    "        y_pred_labels = resnet18.forward(images_val)\n",
    "        val_loss = bce_loss(y_pred_labels, labels_val)\n",
    "\n",
    "        running_val_loss += val_loss\n",
    "        running_val_acc += get_acc(torch.argmax(y_pred_labels, dim = 1).detach().cpu().numpy(), labels_val.detach().cpu().numpy())\n",
    "\n",
    "    avg_train_loss = running_train_loss / len(train_data_loader)\n",
    "    avg_val_loss = running_val_loss / len(val_data_loader)\n",
    "\n",
    "    avg_train_acc = running_train_acc / len(train_data_loader)\n",
    "    avg_val_acc = running_val_loss / len(val_data_loader)\n",
    "\n",
    "    print(f'Epoch {epoch+1} | Training Loss: {avg_train_loss} | Training Accuracy {avg_train_acc} \\n \\\n",
    "                            | Validation loss {avg_val_loss} | Validation Accuracy {avg_val_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.9397718906402588 | Test Accuracy 0.7692708333333333\n"
     ]
    }
   ],
   "source": [
    "resnet18.eval()\n",
    "\n",
    "running_test_acc = 0.\n",
    "running_test_loss = 0.\n",
    "\n",
    "for i, data in enumerate(test_data_loader):\n",
    "    images_test, labels_test = data\n",
    "    images_test, labels_test = images_test.to(device), labels_test.to(device)\n",
    "\n",
    "    y_pred_labels = resnet18.forward(images_test)\n",
    "    test_loss = bce_loss(y_pred_labels, labels_test)\n",
    "\n",
    "    running_test_loss += test_loss\n",
    "    running_test_acc += get_acc(torch.argmax(y_pred_labels, dim = 1).detach().cpu().numpy(), labels_test.detach().cpu().numpy())\n",
    "    \n",
    "    \n",
    "avg_test_loss = running_test_loss / len(test_data_loader)\n",
    "avg_test_acc = running_test_acc / len(test_data_loader)\n",
    "\n",
    "print(f'Test Loss: {avg_test_loss} | Test Accuracy {avg_test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet18.state_dict(), 'resnet18_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=64, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18 = torchvision.models.resnet18(pretrained=True)\n",
    "for param in resnet18.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "resnet18.fc = nn.Linear(512, 64) # Changign last layer to output 64 featurs\n",
    "\n",
    "model = resnet18 # Initialize the model structure\n",
    "model.load_state_dict(torch.load('resnet18_model.pt', map_location=torch.device('cpu')))\n",
    "\n",
    "model.eval() # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Pretrain Vision Transformer model on ImageNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Train on 30 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device(type='cuda')\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\models\\vit\\feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import ViTModel, ViTFeatureExtractor, ViTForImageClassification\n",
    "\n",
    "image_processor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "vit = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224\", return_dict=False)\n",
    "vit = vit.to(device)\n",
    "\n",
    "for param in vit.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "vit.classifier = nn.Linear(768,64).to(device) # Chaning final output layer to map our problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vit.embeddings.cls_token: Requires Grad - False\n",
      "vit.embeddings.position_embeddings: Requires Grad - False\n",
      "vit.embeddings.patch_embeddings.projection.weight: Requires Grad - False\n",
      "vit.embeddings.patch_embeddings.projection.bias: Requires Grad - False\n",
      "vit.encoder.layer.0.attention.attention.query.weight: Requires Grad - False\n",
      "vit.encoder.layer.0.attention.attention.query.bias: Requires Grad - False\n",
      "vit.encoder.layer.0.attention.attention.key.weight: Requires Grad - False\n",
      "vit.encoder.layer.0.attention.attention.key.bias: Requires Grad - False\n",
      "vit.encoder.layer.0.attention.attention.value.weight: Requires Grad - False\n",
      "vit.encoder.layer.0.attention.attention.value.bias: Requires Grad - False\n",
      "vit.encoder.layer.0.attention.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.0.attention.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.0.intermediate.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.0.intermediate.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.0.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.0.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.0.layernorm_before.weight: Requires Grad - False\n",
      "vit.encoder.layer.0.layernorm_before.bias: Requires Grad - False\n",
      "vit.encoder.layer.0.layernorm_after.weight: Requires Grad - False\n",
      "vit.encoder.layer.0.layernorm_after.bias: Requires Grad - False\n",
      "vit.encoder.layer.1.attention.attention.query.weight: Requires Grad - False\n",
      "vit.encoder.layer.1.attention.attention.query.bias: Requires Grad - False\n",
      "vit.encoder.layer.1.attention.attention.key.weight: Requires Grad - False\n",
      "vit.encoder.layer.1.attention.attention.key.bias: Requires Grad - False\n",
      "vit.encoder.layer.1.attention.attention.value.weight: Requires Grad - False\n",
      "vit.encoder.layer.1.attention.attention.value.bias: Requires Grad - False\n",
      "vit.encoder.layer.1.attention.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.1.attention.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.1.intermediate.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.1.intermediate.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.1.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.1.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.1.layernorm_before.weight: Requires Grad - False\n",
      "vit.encoder.layer.1.layernorm_before.bias: Requires Grad - False\n",
      "vit.encoder.layer.1.layernorm_after.weight: Requires Grad - False\n",
      "vit.encoder.layer.1.layernorm_after.bias: Requires Grad - False\n",
      "vit.encoder.layer.2.attention.attention.query.weight: Requires Grad - False\n",
      "vit.encoder.layer.2.attention.attention.query.bias: Requires Grad - False\n",
      "vit.encoder.layer.2.attention.attention.key.weight: Requires Grad - False\n",
      "vit.encoder.layer.2.attention.attention.key.bias: Requires Grad - False\n",
      "vit.encoder.layer.2.attention.attention.value.weight: Requires Grad - False\n",
      "vit.encoder.layer.2.attention.attention.value.bias: Requires Grad - False\n",
      "vit.encoder.layer.2.attention.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.2.attention.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.2.intermediate.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.2.intermediate.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.2.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.2.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.2.layernorm_before.weight: Requires Grad - False\n",
      "vit.encoder.layer.2.layernorm_before.bias: Requires Grad - False\n",
      "vit.encoder.layer.2.layernorm_after.weight: Requires Grad - False\n",
      "vit.encoder.layer.2.layernorm_after.bias: Requires Grad - False\n",
      "vit.encoder.layer.3.attention.attention.query.weight: Requires Grad - False\n",
      "vit.encoder.layer.3.attention.attention.query.bias: Requires Grad - False\n",
      "vit.encoder.layer.3.attention.attention.key.weight: Requires Grad - False\n",
      "vit.encoder.layer.3.attention.attention.key.bias: Requires Grad - False\n",
      "vit.encoder.layer.3.attention.attention.value.weight: Requires Grad - False\n",
      "vit.encoder.layer.3.attention.attention.value.bias: Requires Grad - False\n",
      "vit.encoder.layer.3.attention.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.3.attention.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.3.intermediate.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.3.intermediate.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.3.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.3.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.3.layernorm_before.weight: Requires Grad - False\n",
      "vit.encoder.layer.3.layernorm_before.bias: Requires Grad - False\n",
      "vit.encoder.layer.3.layernorm_after.weight: Requires Grad - False\n",
      "vit.encoder.layer.3.layernorm_after.bias: Requires Grad - False\n",
      "vit.encoder.layer.4.attention.attention.query.weight: Requires Grad - False\n",
      "vit.encoder.layer.4.attention.attention.query.bias: Requires Grad - False\n",
      "vit.encoder.layer.4.attention.attention.key.weight: Requires Grad - False\n",
      "vit.encoder.layer.4.attention.attention.key.bias: Requires Grad - False\n",
      "vit.encoder.layer.4.attention.attention.value.weight: Requires Grad - False\n",
      "vit.encoder.layer.4.attention.attention.value.bias: Requires Grad - False\n",
      "vit.encoder.layer.4.attention.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.4.attention.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.4.intermediate.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.4.intermediate.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.4.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.4.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.4.layernorm_before.weight: Requires Grad - False\n",
      "vit.encoder.layer.4.layernorm_before.bias: Requires Grad - False\n",
      "vit.encoder.layer.4.layernorm_after.weight: Requires Grad - False\n",
      "vit.encoder.layer.4.layernorm_after.bias: Requires Grad - False\n",
      "vit.encoder.layer.5.attention.attention.query.weight: Requires Grad - False\n",
      "vit.encoder.layer.5.attention.attention.query.bias: Requires Grad - False\n",
      "vit.encoder.layer.5.attention.attention.key.weight: Requires Grad - False\n",
      "vit.encoder.layer.5.attention.attention.key.bias: Requires Grad - False\n",
      "vit.encoder.layer.5.attention.attention.value.weight: Requires Grad - False\n",
      "vit.encoder.layer.5.attention.attention.value.bias: Requires Grad - False\n",
      "vit.encoder.layer.5.attention.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.5.attention.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.5.intermediate.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.5.intermediate.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.5.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.5.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.5.layernorm_before.weight: Requires Grad - False\n",
      "vit.encoder.layer.5.layernorm_before.bias: Requires Grad - False\n",
      "vit.encoder.layer.5.layernorm_after.weight: Requires Grad - False\n",
      "vit.encoder.layer.5.layernorm_after.bias: Requires Grad - False\n",
      "vit.encoder.layer.6.attention.attention.query.weight: Requires Grad - False\n",
      "vit.encoder.layer.6.attention.attention.query.bias: Requires Grad - False\n",
      "vit.encoder.layer.6.attention.attention.key.weight: Requires Grad - False\n",
      "vit.encoder.layer.6.attention.attention.key.bias: Requires Grad - False\n",
      "vit.encoder.layer.6.attention.attention.value.weight: Requires Grad - False\n",
      "vit.encoder.layer.6.attention.attention.value.bias: Requires Grad - False\n",
      "vit.encoder.layer.6.attention.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.6.attention.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.6.intermediate.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.6.intermediate.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.6.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.6.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.6.layernorm_before.weight: Requires Grad - False\n",
      "vit.encoder.layer.6.layernorm_before.bias: Requires Grad - False\n",
      "vit.encoder.layer.6.layernorm_after.weight: Requires Grad - False\n",
      "vit.encoder.layer.6.layernorm_after.bias: Requires Grad - False\n",
      "vit.encoder.layer.7.attention.attention.query.weight: Requires Grad - False\n",
      "vit.encoder.layer.7.attention.attention.query.bias: Requires Grad - False\n",
      "vit.encoder.layer.7.attention.attention.key.weight: Requires Grad - False\n",
      "vit.encoder.layer.7.attention.attention.key.bias: Requires Grad - False\n",
      "vit.encoder.layer.7.attention.attention.value.weight: Requires Grad - False\n",
      "vit.encoder.layer.7.attention.attention.value.bias: Requires Grad - False\n",
      "vit.encoder.layer.7.attention.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.7.attention.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.7.intermediate.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.7.intermediate.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.7.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.7.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.7.layernorm_before.weight: Requires Grad - False\n",
      "vit.encoder.layer.7.layernorm_before.bias: Requires Grad - False\n",
      "vit.encoder.layer.7.layernorm_after.weight: Requires Grad - False\n",
      "vit.encoder.layer.7.layernorm_after.bias: Requires Grad - False\n",
      "vit.encoder.layer.8.attention.attention.query.weight: Requires Grad - False\n",
      "vit.encoder.layer.8.attention.attention.query.bias: Requires Grad - False\n",
      "vit.encoder.layer.8.attention.attention.key.weight: Requires Grad - False\n",
      "vit.encoder.layer.8.attention.attention.key.bias: Requires Grad - False\n",
      "vit.encoder.layer.8.attention.attention.value.weight: Requires Grad - False\n",
      "vit.encoder.layer.8.attention.attention.value.bias: Requires Grad - False\n",
      "vit.encoder.layer.8.attention.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.8.attention.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.8.intermediate.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.8.intermediate.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.8.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.8.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.8.layernorm_before.weight: Requires Grad - False\n",
      "vit.encoder.layer.8.layernorm_before.bias: Requires Grad - False\n",
      "vit.encoder.layer.8.layernorm_after.weight: Requires Grad - False\n",
      "vit.encoder.layer.8.layernorm_after.bias: Requires Grad - False\n",
      "vit.encoder.layer.9.attention.attention.query.weight: Requires Grad - False\n",
      "vit.encoder.layer.9.attention.attention.query.bias: Requires Grad - False\n",
      "vit.encoder.layer.9.attention.attention.key.weight: Requires Grad - False\n",
      "vit.encoder.layer.9.attention.attention.key.bias: Requires Grad - False\n",
      "vit.encoder.layer.9.attention.attention.value.weight: Requires Grad - False\n",
      "vit.encoder.layer.9.attention.attention.value.bias: Requires Grad - False\n",
      "vit.encoder.layer.9.attention.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.9.attention.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.9.intermediate.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.9.intermediate.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.9.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.9.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.9.layernorm_before.weight: Requires Grad - False\n",
      "vit.encoder.layer.9.layernorm_before.bias: Requires Grad - False\n",
      "vit.encoder.layer.9.layernorm_after.weight: Requires Grad - False\n",
      "vit.encoder.layer.9.layernorm_after.bias: Requires Grad - False\n",
      "vit.encoder.layer.10.attention.attention.query.weight: Requires Grad - False\n",
      "vit.encoder.layer.10.attention.attention.query.bias: Requires Grad - False\n",
      "vit.encoder.layer.10.attention.attention.key.weight: Requires Grad - False\n",
      "vit.encoder.layer.10.attention.attention.key.bias: Requires Grad - False\n",
      "vit.encoder.layer.10.attention.attention.value.weight: Requires Grad - False\n",
      "vit.encoder.layer.10.attention.attention.value.bias: Requires Grad - False\n",
      "vit.encoder.layer.10.attention.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.10.attention.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.10.intermediate.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.10.intermediate.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.10.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.10.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.10.layernorm_before.weight: Requires Grad - False\n",
      "vit.encoder.layer.10.layernorm_before.bias: Requires Grad - False\n",
      "vit.encoder.layer.10.layernorm_after.weight: Requires Grad - False\n",
      "vit.encoder.layer.10.layernorm_after.bias: Requires Grad - False\n",
      "vit.encoder.layer.11.attention.attention.query.weight: Requires Grad - False\n",
      "vit.encoder.layer.11.attention.attention.query.bias: Requires Grad - False\n",
      "vit.encoder.layer.11.attention.attention.key.weight: Requires Grad - False\n",
      "vit.encoder.layer.11.attention.attention.key.bias: Requires Grad - False\n",
      "vit.encoder.layer.11.attention.attention.value.weight: Requires Grad - False\n",
      "vit.encoder.layer.11.attention.attention.value.bias: Requires Grad - False\n",
      "vit.encoder.layer.11.attention.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.11.attention.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.11.intermediate.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.11.intermediate.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.11.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.11.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.11.layernorm_before.weight: Requires Grad - False\n",
      "vit.encoder.layer.11.layernorm_before.bias: Requires Grad - False\n",
      "vit.encoder.layer.11.layernorm_after.weight: Requires Grad - False\n",
      "vit.encoder.layer.11.layernorm_after.bias: Requires Grad - False\n",
      "vit.layernorm.weight: Requires Grad - False\n",
      "vit.layernorm.bias: Requires Grad - False\n",
      "classifier.weight: Requires Grad - True\n",
      "classifier.bias: Requires Grad - True\n"
     ]
    }
   ],
   "source": [
    "for name, param in vit.named_parameters():\n",
    "    print(f\"{name}: Requires Grad - {param.requires_grad}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: \n",
      "Training Loss: 0.3403508795760683 | Training Accuracy 0.9222098214285714 \n",
      "Validation loss 0.21284125745296478 | Validation Accuracy 0.940625\n",
      "Epoch 2: \n",
      "Training Loss: 0.12581108682262268 | Training Accuracy 0.9647321428571428 \n",
      "Validation loss 0.2258845716714859 | Validation Accuracy 0.9381944444444444\n",
      "Epoch 3: \n",
      "Training Loss: 0.07336552744631522 | Training Accuracy 0.9806547619047619 \n",
      "Validation loss 0.23824287950992584 | Validation Accuracy 0.9357638888888888\n",
      "Epoch 4: \n",
      "Training Loss: 0.04721137410635406 | Training Accuracy 0.9879092261904762 \n",
      "Validation loss 0.2546827793121338 | Validation Accuracy 0.9362847222222223\n",
      "Epoch 5: \n",
      "Training Loss: 0.03007040217468914 | Training Accuracy 0.993266369047619 \n",
      "Validation loss 0.26733312010765076 | Validation Accuracy 0.9347222222222222\n",
      "Epoch 6: \n",
      "Training Loss: 0.022052670196925257 | Training Accuracy 0.9956101190476191 \n",
      "Validation loss 0.27509239315986633 | Validation Accuracy 0.9345486111111111\n",
      "Epoch 7: \n",
      "Training Loss: 0.016714953235073368 | Training Accuracy 0.9963541666666667 \n",
      "Validation loss 0.2861812114715576 | Validation Accuracy 0.9347222222222222\n",
      "Epoch 8: \n",
      "Training Loss: 0.012326407671874524 | Training Accuracy 0.9977306547619048 \n",
      "Validation loss 0.30146652460098267 | Validation Accuracy 0.9322916666666666\n",
      "Epoch 9: \n",
      "Training Loss: 0.010476002829351013 | Training Accuracy 0.9981026785714285 \n",
      "Validation loss 0.3079192042350769 | Validation Accuracy 0.9345486111111111\n",
      "Epoch 10: \n",
      "Training Loss: 0.008274067579380547 | Training Accuracy 0.9986607142857142 \n",
      "Validation loss 0.33089679479599 | Validation Accuracy 0.9321180555555556\n",
      "Epoch 11: \n",
      "Training Loss: 0.006173099684254642 | Training Accuracy 0.9989583333333333 \n",
      "Validation loss 0.334865927696228 | Validation Accuracy 0.9329861111111111\n",
      "Epoch 12: \n",
      "Training Loss: 0.00537025359816263 | Training Accuracy 0.9991443452380953 \n",
      "Validation loss 0.34590405225753784 | Validation Accuracy 0.9326388888888889\n",
      "Epoch 13: \n",
      "Training Loss: 0.005203728001537283 | Training Accuracy 0.9988095238095238 \n",
      "Validation loss 0.36246776580810547 | Validation Accuracy 0.9303819444444444\n",
      "Epoch 14: \n",
      "Training Loss: 0.004760074050571867 | Training Accuracy 0.9989583333333333 \n",
      "Validation loss 0.3715468645095825 | Validation Accuracy 0.9331597222222222\n",
      "Epoch 15: \n",
      "Training Loss: 0.0036079114648340954 | Training Accuracy 0.9994047619047619 \n",
      "Validation loss 0.39976030588150024 | Validation Accuracy 0.9317708333333333\n",
      "Epoch 16: \n",
      "Training Loss: 0.0025319673475288646 | Training Accuracy 0.9996279761904762 \n",
      "Validation loss 0.39457419514656067 | Validation Accuracy 0.9328125\n",
      "Epoch 17: \n",
      "Training Loss: 0.002935462393500237 | Training Accuracy 0.99921875 \n",
      "Validation loss 0.41495952010154724 | Validation Accuracy 0.9315972222222222\n",
      "Epoch 18: \n",
      "Training Loss: 0.0024388667143709665 | Training Accuracy 0.9995163690476191 \n",
      "Validation loss 0.40839245915412903 | Validation Accuracy 0.934375\n",
      "Epoch 19: \n",
      "Training Loss: 0.0014580041056945331 | Training Accuracy 0.9998511904761904 \n",
      "Validation loss 0.420245885848999 | Validation Accuracy 0.9326388888888889\n",
      "Epoch 20: \n",
      "Training Loss: 0.0013454658219600225 | Training Accuracy 0.999702380952381 \n",
      "Validation loss 0.4351527988910675 | Validation Accuracy 0.9322916666666666\n",
      "Epoch 21: \n",
      "Training Loss: 0.0015255707540296455 | Training Accuracy 0.9997767857142857 \n",
      "Validation loss 0.44219017028808594 | Validation Accuracy 0.9319444444444445\n",
      "Epoch 22: \n",
      "Training Loss: 0.0017917229181444482 | Training Accuracy 0.9996651785714286 \n",
      "Validation loss 0.4696877598762512 | Validation Accuracy 0.9307291666666667\n",
      "Epoch 23: \n",
      "Training Loss: 0.0023326965682469694 | Training Accuracy 0.9993675595238095 \n",
      "Validation loss 0.47871553897857666 | Validation Accuracy 0.9303819444444444\n",
      "Epoch 24: \n",
      "Training Loss: 0.001676160162635586 | Training Accuracy 0.9994047619047619 \n",
      "Validation loss 0.49271994829177856 | Validation Accuracy 0.9291666666666667\n",
      "Epoch 25: \n",
      "Training Loss: 0.0005911426961146406 | Training Accuracy 1.0 \n",
      "Validation loss 0.48701512813568115 | Validation Accuracy 0.9295138888888889\n",
      "Epoch 26: \n",
      "Training Loss: 0.0012117323750942433 | Training Accuracy 0.999702380952381 \n",
      "Validation loss 0.4932389259338379 | Validation Accuracy 0.9310763888888889\n",
      "Epoch 27: \n",
      "Training Loss: 0.0005467091449317996 | Training Accuracy 0.9999255952380952 \n",
      "Validation loss 0.49342676997184753 | Validation Accuracy 0.9309027777777777\n",
      "Epoch 28: \n",
      "Training Loss: 0.0003394062813616057 | Training Accuracy 1.0 \n",
      "Validation loss 0.4978167712688446 | Validation Accuracy 0.9314236111111112\n",
      "Epoch 29: \n",
      "Training Loss: 0.0008955779406164427 | Training Accuracy 0.9998511904761904 \n",
      "Validation loss 0.517025351524353 | Validation Accuracy 0.9319444444444445\n",
      "Epoch 30: \n",
      "Training Loss: 0.0005712608591125328 | Training Accuracy 0.9999255952380952 \n",
      "Validation loss 0.5281529426574707 | Validation Accuracy 0.9305555555555556\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(vit.parameters())\n",
    "\n",
    "for epoch in range(30):\n",
    "    bce_loss = nn.CrossEntropyLoss()\n",
    "    vit.train()\n",
    "    running_train_loss = 0.\n",
    "    running_val_loss = 0.\n",
    "\n",
    "    running_train_acc = 0.\n",
    "    running_val_acc = 0.\n",
    "\n",
    "    for i, data in enumerate(train_data_loader):\n",
    "        images, labels = data\n",
    "        images = list(images.unbind())  # Unbind the images tensor into a list of image tensors\n",
    "        images = image_processor(images=images, do_normalize = False)\n",
    "        images = torch.tensor(np.stack(images['pixel_values'], axis = 0))\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred_labels = vit.forward(images)\n",
    "\n",
    "        loss = bce_loss(pred_labels[0], labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_train_acc += get_acc(torch.argmax(pred_labels[0], dim = 1).detach().cpu().numpy(), labels.detach().cpu().numpy())\n",
    "        running_train_loss += loss.item()\n",
    "\n",
    "\n",
    "    vit.eval()\n",
    "    for i, data in enumerate(val_data_loader):\n",
    "\n",
    "        images_val, labels_val = data\n",
    "        images_val = list(images_val.unbind())\n",
    "\n",
    "        images_val = image_processor(images_val, do_normalize = False)\n",
    "        images_val = torch.tensor(np.stack(images_val['pixel_values'], axis = 0))\n",
    "\n",
    "        images_val, labels_val = images_val.to(device), labels_val.to(device)\n",
    "\n",
    "\n",
    "        y_pred_labels = vit.forward(images_val)\n",
    "        val_loss = bce_loss(y_pred_labels[0], labels_val)\n",
    "\n",
    "        running_val_loss += val_loss\n",
    "        running_val_acc += get_acc(torch.argmax(y_pred_labels[0], dim = 1).detach().cpu().numpy(), labels_val.detach().cpu().numpy())\n",
    "\n",
    "    avg_train_loss = running_train_loss / len(train_data_loader)\n",
    "    avg_val_loss = running_val_loss / len(val_data_loader)\n",
    "\n",
    "    avg_train_acc = running_train_acc / len(train_data_loader)\n",
    "    avg_val_acc = running_val_acc / len(val_data_loader)\n",
    "\n",
    "    print(f'Epoch {epoch+1}: \\nTraining Loss: {avg_train_loss} | Training Accuracy {avg_train_acc} \\nValidation loss {avg_val_loss} | Validation Accuracy {avg_val_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.46368536353111267 | Test Accuracy 0.9340277777777778\n"
     ]
    }
   ],
   "source": [
    "vit.eval()\n",
    "\n",
    "running_test_acc = 0.\n",
    "running_test_loss = 0.\n",
    "\n",
    "for i, data in enumerate(test_data_loader):\n",
    "    images_test, labels_test = data\n",
    "    images_test = list(images_test.unbind())\n",
    "\n",
    "    images_test = image_processor(images_test, do_normalize = False)\n",
    "    images_test = torch.tensor(np.stack(images_test['pixel_values'], axis = 0))\n",
    "\n",
    "    images_test, labels_test = images_test.to(device), labels_test.to(device)\n",
    "\n",
    "    y_pred_labels = vit.forward(images_test)\n",
    "    test_loss = bce_loss(y_pred_labels[0], labels_test)\n",
    "\n",
    "    running_test_loss += test_loss\n",
    "    running_test_acc += get_acc(torch.argmax(y_pred_labels[0], dim = 1).detach().cpu().numpy(), labels_test.detach().cpu().numpy())\n",
    "    \n",
    "    \n",
    "avg_test_loss = running_test_loss / len(test_data_loader)\n",
    "avg_test_acc = running_test_acc / len(test_data_loader)\n",
    "\n",
    "print(f'Test Loss: {avg_test_loss} | Test Accuracy {avg_test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vit.state_dict(), 'vit_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViTForImageClassification(\n",
       "  (vit): ViTModel(\n",
       "    (embeddings): ViTEmbeddings(\n",
       "      (patch_embeddings): PatchEmbeddings(\n",
       "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): ViTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (6): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (7): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (8): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (9): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (10): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (11): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=64, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = vit # Initialize the model structure\n",
    "model.load_state_dict(torch.load('vit_model.pt', map_location=torch.device('cpu')))\n",
    "\n",
    "model.eval() # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Train on 5 epochs\n",
    "better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.08907675743103027 | Test Accuracy 0.9791666666666666\n"
     ]
    }
   ],
   "source": [
    "image_processor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "vit = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224\", return_dict=False)\n",
    "vit = vit.to(device)\n",
    "\n",
    "for param in vit.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "vit.classifier = nn.Linear(768,64).to(device) # Chaning final output layer to map our problem\n",
    "\n",
    "model = vit # Initialize the model structure\n",
    "\n",
    "model.load_state_dict(torch.load('vit_model_5ep.pt', map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "\n",
    "running_test_acc = 0.\n",
    "running_test_loss = 0.\n",
    "bce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "for i, data in enumerate(test_data_loader):\n",
    "    images_test, labels_test = data\n",
    "    images_test = list(images_test.unbind())\n",
    "\n",
    "    images_test = image_processor(images_test, do_normalize = False)\n",
    "    images_test = torch.tensor(np.stack(images_test['pixel_values'], axis = 0))\n",
    "\n",
    "    images_test, labels_test = images_test.to(device), labels_test.to(device)\n",
    "\n",
    "    y_pred_labels = model.forward(images_test)\n",
    "    test_loss = bce_loss(y_pred_labels[0], labels_test)\n",
    "\n",
    "    running_test_loss += test_loss\n",
    "    running_test_acc += get_acc(torch.argmax(y_pred_labels[0], dim = 1).detach().cpu().numpy(), labels_test.detach().cpu().numpy())\n",
    "    \n",
    "    \n",
    "avg_test_loss = running_test_loss / len(test_data_loader)\n",
    "avg_test_acc = running_test_acc / len(test_data_loader)\n",
    "\n",
    "print(f'Test Loss: {avg_test_loss} | Test Accuracy {avg_test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3 Unexpected error\n",
    "Same code, after running on local computer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 5.474754810333252 | Test Accuracy 0.012152777777777778\n"
     ]
    }
   ],
   "source": [
    "image_processor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "vit = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224\", return_dict=False)\n",
    "vit = vit.to(device)\n",
    "\n",
    "for param in vit.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "vit.classifier = nn.Linear(768,64).to(device) # Chaning final output layer to map our problem\n",
    "\n",
    "model = vit # Initialize the model structure\n",
    "\n",
    "model.load_state_dict(torch.load('vit_model_5ep.pt', map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "\n",
    "running_test_acc = 0.\n",
    "running_test_loss = 0.\n",
    "bce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "for i, data in enumerate(test_data_loader):\n",
    "    images_test, labels_test = data\n",
    "    images_test = list(images_test.unbind())\n",
    "\n",
    "    images_test = image_processor(images_test, do_normalize = False)\n",
    "    images_test = torch.tensor(np.stack(images_test['pixel_values'], axis = 0))\n",
    "\n",
    "    images_test, labels_test = images_test.to(device), labels_test.to(device)\n",
    "\n",
    "    y_pred_labels = model.forward(images_test)\n",
    "    test_loss = bce_loss(y_pred_labels[0], labels_test)\n",
    "\n",
    "    running_test_loss += test_loss\n",
    "    running_test_acc += get_acc(torch.argmax(y_pred_labels[0], dim = 1).detach().cpu().numpy(), labels_test.detach().cpu().numpy())\n",
    "    \n",
    "    \n",
    "avg_test_loss = running_test_loss / len(test_data_loader)\n",
    "avg_test_acc = running_test_acc / len(test_data_loader)\n",
    "\n",
    "print(f'Test Loss: {avg_test_loss} | Test Accuracy {avg_test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Fine Tuning\n",
    "\n",
    "Compare the performance of different models (ResNet18, VGG, Vision Transformer, etc.), and investigate the different optimization strategies. (This part will be used as a bonus item, 2 points)\n",
    "\n",
    "Used ResNet18, Vision Transformer, \n",
    "<br>Ana: VGG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 EuroSAT: ResNet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 EuroSAT: ResNet18 w & w/o augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainging 2 resnet models, first on 5 EuroSat dataset. Another with data augmentation on 5 different datasets.\n",
    "<br> Augmentation does not improve our accuracy. Next step - to try to add few more layers (like Norm and Linear) / unfreze more layers in model\n",
    "<br> I Have downloaded EuroSat dataset from git repo and extracted it already, as python would take longer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 3 times below code.\n",
    "<br>First attempt: With augmentation avg test accuracy is 0.864 and loss is 0.3875, Without augmentation avg test accuracy is 0.848 and loss is 0.445\n",
    "<br>Second attempt: With augmentation avg test accuracy is 0.888 and loss is 0.3115, Without augmentation avg test accuracy is 0.872 and loss is 0.338\n",
    "<br>Third attempt: With augmentation avg test accuracy is 0.896 and loss is 0.3237, Without augmentation avg test accuracy is 0.88 and loss is 0.321"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 | Epoch 10 | Training Loss: 0.6860550940036774 | Training Accuracy 0.7866666666666666\n",
      "Dataset 1 | Epoch 20 | Training Loss: 0.396595906217893 | Training Accuracy 0.9333333333333333\n",
      "Dataset 1 | Epoch 30 | Training Loss: 0.2566543345650037 | Training Accuracy 0.9600000000000002\n",
      "Dataset 1 | Epoch 40 | Training Loss: 0.26598720575372375 | Training Accuracy 0.9066666666666667\n",
      "Dataset 1 | Epoch 50 | Training Loss: 0.2608462671438853 | Training Accuracy 0.9066666666666666\n",
      "Dataset 1 | Test Loss: 0.6153009533882141 | Test Accuracy 0.8400000000000001\n",
      "Dataset 1 | Epoch 10 | Augmented Training Loss: 0.6792805254459381 | Augmented Training Accuracy 0.7733333333333334\n",
      "Dataset 1 | Epoch 20 | Augmented Training Loss: 0.47035458087921145 | Augmented Training Accuracy 0.8800000000000001\n",
      "Dataset 1 | Epoch 30 | Augmented Training Loss: 0.3927986979484558 | Augmented Training Accuracy 0.8933333333333333\n",
      "Dataset 1 | Epoch 40 | Augmented Training Loss: 0.36764580979943273 | Augmented Training Accuracy 0.8400000000000002\n",
      "Dataset 1 | Epoch 50 | Augmented Training Loss: 0.36475545515616736 | Augmented Training Accuracy 0.8533333333333335\n",
      "Dataset 1 | Augmented Test Loss: 0.4991772770881653 | Augmented Test Accuracy 0.9199999999999999\n",
      "Dataset 2 | Epoch 10 | Training Loss: 0.46330204407374065 | Training Accuracy 0.88\n",
      "Dataset 2 | Epoch 20 | Training Loss: 0.27152517090241113 | Training Accuracy 0.9333333333333333\n",
      "Dataset 2 | Epoch 30 | Training Loss: 0.2697902411222458 | Training Accuracy 0.9066666666666667\n",
      "Dataset 2 | Epoch 40 | Training Loss: 0.3452772840857506 | Training Accuracy 0.8933333333333332\n",
      "Dataset 2 | Epoch 50 | Training Loss: 0.2056376449763775 | Training Accuracy 0.9333333333333333\n",
      "Dataset 2 | Test Loss: 0.316689670085907 | Test Accuracy 0.8799999999999999\n",
      "Dataset 2 | Epoch 10 | Augmented Training Loss: 0.6280934989452363 | Augmented Training Accuracy 0.7866666666666667\n",
      "Dataset 2 | Epoch 20 | Augmented Training Loss: 0.2950209878385067 | Augmented Training Accuracy 0.9333333333333333\n",
      "Dataset 2 | Epoch 30 | Augmented Training Loss: 0.29932022591431934 | Augmented Training Accuracy 0.8800000000000002\n",
      "Dataset 2 | Epoch 40 | Augmented Training Loss: 0.21585621138413746 | Augmented Training Accuracy 0.9466666666666668\n",
      "Dataset 2 | Epoch 50 | Augmented Training Loss: 0.39263746825357276 | Augmented Training Accuracy 0.8933333333333333\n",
      "Dataset 2 | Augmented Test Loss: 0.29617103934288025 | Augmented Test Accuracy 0.9199999999999999\n",
      "Dataset 3 | Epoch 10 | Training Loss: 0.817262914776802 | Training Accuracy 0.7066666666666667\n",
      "Dataset 3 | Epoch 20 | Training Loss: 0.39243007004261016 | Training Accuracy 0.8933333333333333\n",
      "Dataset 3 | Epoch 30 | Training Loss: 0.33265003164609275 | Training Accuracy 0.8800000000000001\n",
      "Dataset 3 | Epoch 40 | Training Loss: 0.18411765868465105 | Training Accuracy 0.9466666666666667\n",
      "Dataset 3 | Epoch 50 | Training Loss: 0.3140427847703298 | Training Accuracy 0.9066666666666668\n",
      "Dataset 3 | Test Loss: 0.3257933557033539 | Test Accuracy 0.8800000000000001\n",
      "Dataset 3 | Epoch 10 | Augmented Training Loss: 0.5711773534615835 | Augmented Training Accuracy 0.8666666666666669\n",
      "Dataset 3 | Epoch 20 | Augmented Training Loss: 0.40000977714856467 | Augmented Training Accuracy 0.8800000000000001\n",
      "Dataset 3 | Epoch 30 | Augmented Training Loss: 0.28846446772416434 | Augmented Training Accuracy 0.8933333333333333\n",
      "Dataset 3 | Epoch 40 | Augmented Training Loss: 0.45676243901252744 | Augmented Training Accuracy 0.8266666666666667\n",
      "Dataset 3 | Epoch 50 | Augmented Training Loss: 0.24145498673121135 | Augmented Training Accuracy 0.9733333333333334\n",
      "Dataset 3 | Augmented Test Loss: 0.25445839762687683 | Augmented Test Accuracy 0.96\n",
      "Dataset 4 | Epoch 10 | Training Loss: 0.8192445576190949 | Training Accuracy 0.7333333333333333\n",
      "Dataset 4 | Epoch 20 | Training Loss: 0.4230471670627594 | Training Accuracy 0.8666666666666668\n",
      "Dataset 4 | Epoch 30 | Training Loss: 0.3831381157040596 | Training Accuracy 0.9200000000000002\n",
      "Dataset 4 | Epoch 40 | Training Loss: 0.4025522162516912 | Training Accuracy 0.8933333333333333\n",
      "Dataset 4 | Epoch 50 | Training Loss: 0.3502529705564181 | Training Accuracy 0.9066666666666666\n",
      "Dataset 4 | Test Loss: 0.4671151340007782 | Test Accuracy 0.8\n",
      "Dataset 4 | Epoch 10 | Augmented Training Loss: 0.7462359468142191 | Augmented Training Accuracy 0.7333333333333333\n",
      "Dataset 4 | Epoch 20 | Augmented Training Loss: 0.7225423360864321 | Augmented Training Accuracy 0.7333333333333335\n",
      "Dataset 4 | Epoch 30 | Augmented Training Loss: 0.5039166222016017 | Augmented Training Accuracy 0.84\n",
      "Dataset 4 | Epoch 40 | Augmented Training Loss: 0.3043134915331999 | Augmented Training Accuracy 0.92\n",
      "Dataset 4 | Epoch 50 | Augmented Training Loss: 0.2765974613527457 | Augmented Training Accuracy 0.9066666666666667\n",
      "Dataset 4 | Augmented Test Loss: 0.36140137910842896 | Augmented Test Accuracy 0.8799999999999999\n",
      "Dataset 5 | Epoch 10 | Training Loss: 0.5294400135676066 | Training Accuracy 0.9066666666666667\n",
      "Dataset 5 | Epoch 20 | Training Loss: 0.2951246157288551 | Training Accuracy 0.9066666666666667\n",
      "Dataset 5 | Epoch 30 | Training Loss: 0.16764443491895994 | Training Accuracy 0.9600000000000001\n",
      "Dataset 5 | Epoch 40 | Training Loss: 0.20537954556445281 | Training Accuracy 0.9466666666666668\n",
      "Dataset 5 | Epoch 50 | Training Loss: 0.19828146137297153 | Training Accuracy 0.9333333333333335\n",
      "Dataset 5 | Test Loss: 0.2555728554725647 | Test Accuracy 0.9199999999999999\n",
      "Dataset 5 | Epoch 10 | Augmented Training Loss: 0.580002079407374 | Augmented Training Accuracy 0.8666666666666668\n",
      "Dataset 5 | Epoch 20 | Augmented Training Loss: 0.3410333866874377 | Augmented Training Accuracy 0.9466666666666668\n",
      "Dataset 5 | Epoch 30 | Augmented Training Loss: 0.326114950577418 | Augmented Training Accuracy 0.9066666666666666\n",
      "Dataset 5 | Epoch 40 | Augmented Training Loss: 0.16915092108150323 | Augmented Training Accuracy 0.9600000000000001\n",
      "Dataset 5 | Epoch 50 | Augmented Training Loss: 0.1820890790472428 | Augmented Training Accuracy 0.9466666666666668\n",
      "Dataset 5 | Augmented Test Loss: 0.2353857308626175 | Augmented Test Accuracy 0.9199999999999999\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "fin_test_loss = []\n",
    "fin_test_acc = []\n",
    "\n",
    "fin_test_loss_aug = []\n",
    "fin_test_acc_aug = []\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    # Option1:\n",
    "#     transform = v2.Compose([\n",
    "#     v2.Resize((224, 224)), # Resizing to 224x224\n",
    "#     v2.ToTensor(), #moving to tensor\n",
    "#     #v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalizing not needed as \n",
    "#     ])\n",
    "    \n",
    "    # Option2:\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)), # Resizing to 224x224\n",
    "        transforms.ToTensor(), #moving to tensor\n",
    "    ])\n",
    "    dataset = torchvision.datasets.ImageFolder('EuroSAT_RGB/EuroSAT_RGB', transform=transform)\n",
    "    dataset = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "    stop = False\n",
    "    images_arr = []\n",
    "    labels_arr = []\n",
    "    while not stop:## Iterating until stop is True\n",
    "\n",
    "        batch = next(iter(dataset))# Getting batch of 32 images\n",
    "\n",
    "        for imh_num in range(batch[0].shape[0]): # Iterate through each image in batch\n",
    "\n",
    "            image = batch[0][imh_num] \n",
    "            label = batch[1][imh_num].item()\n",
    "\n",
    "            if (len(np.unique(labels_arr)) == 5 and np.isin(label, unique_values) or len(np.unique(labels_arr)) < 5)\\\n",
    "                and len(labels_arr)<100:\n",
    "\n",
    "                unique_values, counts = np.unique(labels_arr, return_counts=True)\n",
    "                indx = np.where(unique_values == label)\n",
    "\n",
    "                if counts[indx] < 20 or not np.isin(label, unique_values):\n",
    "\n",
    "                    images_arr.append(image)\n",
    "                    labels_arr.append(label)\n",
    "\n",
    "            if len(labels_arr) == 100: # Once we reach 100 images we stop\n",
    "                stop = True\n",
    "\n",
    "    ## This is required as Model expects labels to have values starting with 0 if we want to use as final output less values than we had previosuly\n",
    "\n",
    "    value_mapping = dict(zip(np.unique(labels_arr), range(0, len(np.unique(labels_arr)))))\n",
    "    arr_mapped = np.vectorize(value_mapping.get)(labels_arr)\n",
    "\n",
    "    ## If you want to test that its indeed generating each time unique image dataset change list(arr_mapped) to labels_arr.\n",
    "    ## It will show images with original labels, but then model wont workS\n",
    "    train_img, test_img, train_labels, test_labels = train_test_split(images_arr, list(arr_mapped), test_size = 0.25, random_state = 0, stratify = labels_arr)\n",
    "    train_data_loader = torch.utils.data.DataLoader(list(zip(train_img, train_labels)), batch_size=5, shuffle=True)\n",
    "    test_data_loader = torch.utils.data.DataLoader(list(zip(test_img, test_labels)), batch_size=5, shuffle=True)\n",
    "\n",
    "    # Just checking for image visualization\n",
    "    #images, labels = next(iter(train_data_loader))\n",
    "    #plt.imshow(np.transpose(images[1], (1, 2, 0)))\n",
    "    #print(labels[1].item())\n",
    "    #plt.show()\n",
    "\n",
    "    ## Loading the model each time for the training\n",
    "    resnet18 = torchvision.models.resnet18(pretrained=True)\n",
    "    for param in resnet18.parameters():\n",
    "        param.requires_grad = False\n",
    "    resnet18.fc = nn.Linear(512, 64) # Changign last layer to output 64 features\n",
    "\n",
    "    model = resnet18 # Initialize the model structure\n",
    "    model.load_state_dict(torch.load('resnet18_model.pt', map_location=torch.device('cpu')))\n",
    "    model.fc = nn.Linear(512, 5) \n",
    "\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(50):\n",
    "        bce_loss = nn.CrossEntropyLoss()\n",
    "        model.train()\n",
    "        running_train_loss = 0.\n",
    "        running_train_acc = 0.\n",
    "\n",
    "        for g, data in enumerate(train_data_loader):\n",
    "            images, labels = data\n",
    "            labels = labels.type(torch.LongTensor) ## This is required as it expect in Long format, but for some reason after replacing label values with 0,1,2... it returned as wide format\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred_labels = model.forward(images)\n",
    "\n",
    "            loss = bce_loss(pred_labels, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_train_acc += get_acc(torch.argmax(pred_labels, dim = 1).detach().cpu().numpy(), labels.detach().cpu().numpy())\n",
    "            running_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = running_train_loss / len(train_data_loader)\n",
    "        avg_train_acc = running_train_acc / len(train_data_loader)\n",
    "\n",
    "        if (epoch+1)%10==0:\n",
    "            print(f'Dataset {i+1} | Epoch {epoch+1} | Training Loss: {avg_train_loss} | Training Accuracy {avg_train_acc}')\n",
    "\n",
    "\n",
    "    ## Evaluating model on train test to see our accuracy\n",
    "    model.eval()\n",
    "\n",
    "    running_test_acc = 0.\n",
    "    running_test_loss = 0.\n",
    "    \n",
    "    for g, data in enumerate(test_data_loader):\n",
    "        bce_loss = nn.CrossEntropyLoss()\n",
    "        images_test, labels_test = data\n",
    "        labels_test = labels_test.type(torch.LongTensor)\n",
    "        images_test, labels_test = images_test.to(device), labels_test.to(device)\n",
    "    \n",
    "        y_pred_labels = model.forward(images_test)\n",
    "        test_loss = bce_loss(y_pred_labels, labels_test)\n",
    "    \n",
    "        running_test_loss += test_loss\n",
    "        running_test_acc += get_acc(torch.argmax(y_pred_labels, dim = 1).detach().cpu().numpy(), labels_test.detach().cpu().numpy())\n",
    "        \n",
    "        \n",
    "    avg_test_loss = running_test_loss / len(test_data_loader)\n",
    "    avg_test_acc = running_test_acc / len(test_data_loader)\n",
    "    \n",
    "    print(f'Dataset {i+1} | Test Loss: {avg_test_loss} | Test Accuracy {avg_test_acc}')\n",
    "\n",
    "    fin_test_loss.append(avg_test_loss)\n",
    "    fin_test_acc.append(avg_test_acc)\n",
    "\n",
    "\n",
    "    ### Here starts model with data augmentation\n",
    "    # Option1\n",
    "#     transform = torch.nn.Sequential(\n",
    "#     v2.RandomHorizontalFlip(p=0.5),\n",
    "#     #v2.RandomZoomOut(p = 0.3),\n",
    "#     #v2.RandomInvert(p = 0.3),\n",
    "#     v2.ToTensor()\n",
    "#     )\n",
    "\n",
    "    # Option2\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    ## Preloading model same as in previous steps\n",
    "    resnet18 = torchvision.models.resnet18(pretrained=True)\n",
    "    for param in resnet18.parameters():\n",
    "        param.requires_grad = False\n",
    "    resnet18.fc = nn.Linear(512, 64) # Changign last layer to output 64 featurs\n",
    "\n",
    "    model = resnet18 # Initialize the model structure\n",
    "    model.load_state_dict(torch.load('resnet18_model.pt', map_location=torch.device('cpu')))\n",
    "    model.fc = nn.Linear(512, 5) \n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.001, weight_decay=0.001)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(50):\n",
    "        bce_loss = nn.CrossEntropyLoss()\n",
    "        model.train()\n",
    "        running_train_loss = 0.\n",
    "        running_train_acc = 0.\n",
    "\n",
    "        for g, data in enumerate(train_data_loader):\n",
    "            images, labels = data\n",
    "            labels = labels.type(torch.LongTensor) ## This is required as it expect in Long format, but for some reason after replacing label values with 0,1,2... it returned as wide format\n",
    "            images = [transform(img) for img in images] ## Apply random transformation to images\n",
    "            images = torch.stack(images)\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred_labels = model.forward(images)\n",
    "\n",
    "            loss = bce_loss(pred_labels, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_train_acc += get_acc(torch.argmax(pred_labels, dim = 1).detach().cpu().numpy(), labels.detach().cpu().numpy())\n",
    "            running_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss_aug = running_train_loss / len(train_data_loader)\n",
    "        avg_train_acc_aug = running_train_acc / len(train_data_loader)\n",
    "\n",
    "        if (epoch+1)%10==0:\n",
    "            print(f'Dataset {i+1} | Epoch {epoch+1} | Augmented Training Loss: {avg_train_loss_aug} | Augmented Training Accuracy {avg_train_acc_aug}')\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    running_test_acc = 0.\n",
    "    running_test_loss = 0.\n",
    "    \n",
    "    for g, data in enumerate(test_data_loader):\n",
    "        bce_loss = nn.CrossEntropyLoss()\n",
    "        images_test, labels_test = data\n",
    "        labels_test = labels_test.type(torch.LongTensor)\n",
    "        images_test, labels_test = images_test.to(device), labels_test.to(device)\n",
    "    \n",
    "        y_pred_labels = model.forward(images_test)\n",
    "        test_loss = bce_loss(y_pred_labels, labels_test)\n",
    "    \n",
    "        running_test_loss += test_loss\n",
    "        running_test_acc += get_acc(torch.argmax(y_pred_labels, dim = 1).detach().cpu().numpy(), labels_test.detach().cpu().numpy())\n",
    "        \n",
    "        \n",
    "    avg_test_loss = running_test_loss / len(test_data_loader)\n",
    "    avg_test_acc = running_test_acc / len(test_data_loader)\n",
    "    \n",
    "    print(f'Dataset {i+1} | Augmented Test Loss: {avg_test_loss} | Augmented Test Accuracy {avg_test_acc}')\n",
    "\n",
    "    fin_test_loss_aug.append(avg_test_loss)\n",
    "    fin_test_acc_aug.append(avg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With augmentation avg test accuracy is 0.9199999999999999 and loss is 0.32931876480579375\n",
      "Without augmentation avg test accuracy is 0.8640000000000001 and loss is 0.3960943937301636\n"
     ]
    }
   ],
   "source": [
    "# TEST WITH AUGMENTATION\n",
    "\n",
    "fin_test_loss_aug = [x.item() for x in fin_test_loss_aug]\n",
    "fin_test_loss = [x.item() for x in fin_test_loss]\n",
    "\n",
    "\n",
    "print (f'With augmentation avg test accuracy is {np.mean(fin_test_acc_aug)} and loss is {np.mean(fin_test_loss_aug)}')\n",
    "print (f'Without augmentation avg test accuracy is {np.mean(fin_test_acc)} and loss is {np.mean(fin_test_loss)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 EuroSAT: ResNet18 w & w/o freezing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No improvements. Things tried with below:\n",
    "1. lr = 0.0001, weight_decay=0.01\n",
    "2. lr = 0.001, weight_decay=0.01\n",
    "3. lr = 0.001, weight_decay=0.001\n",
    "4. lr = 0.0001, weight_decay=0.001\n",
    "5. lr = 0.00001, weight_decay=0.00001\n",
    "6. lr = 0.0001\n",
    "7. lr = 0.00001\n",
    "8. lr = 0.000001\n",
    "9. lr = 0.1\n",
    "<br>Some notes: big weight_decay and lr=0.00001 returned best reeslts, that were close to just basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 | Epoch 10 | Training Loss: 0.6933428684870402 | Training Accuracy 0.8533333333333335\n",
      "Dataset 1 | Epoch 20 | Training Loss: 0.5081756249070167 | Training Accuracy 0.7866666666666665\n",
      "Dataset 1 | Epoch 30 | Training Loss: 0.30178268800179164 | Training Accuracy 0.92\n",
      "Dataset 1 | Epoch 40 | Training Loss: 0.4228097826242447 | Training Accuracy 0.8533333333333333\n",
      "Dataset 1 | Epoch 50 | Training Loss: 0.23922257944941522 | Training Accuracy 0.9600000000000002\n",
      "Dataset 1 | Test Loss: 0.39154911041259766 | Test Accuracy 0.9199999999999999\n",
      "Dataset 1 | Epoch 10 | Unfreezed Training Loss: 0.06992005884336928 | Unfreezed Training Accuracy 1.0\n",
      "Dataset 1 | Epoch 20 | Unfreezed Training Loss: 0.03366510464499394 | Unfreezed Training Accuracy 1.0\n",
      "Dataset 1 | Epoch 30 | Unfreezed Training Loss: 0.10164662295331557 | Unfreezed Training Accuracy 0.9733333333333334\n",
      "Dataset 1 | Epoch 40 | Unfreezed Training Loss: 0.17664438548187414 | Unfreezed Training Accuracy 0.9333333333333333\n",
      "Dataset 1 | Epoch 50 | Unfreezed Training Loss: 0.2297937237036725 | Unfreezed Training Accuracy 0.9333333333333333\n",
      "Dataset 1 | Epoch 60 | Unfreezed Training Loss: 0.026104084914550185 | Unfreezed Training Accuracy 1.0\n",
      "Dataset 1 | Epoch 70 | Unfreezed Training Loss: 0.026754197074721257 | Unfreezed Training Accuracy 1.0\n",
      "Dataset 1 | Epoch 80 | Unfreezed Training Loss: 0.1553354452412653 | Unfreezed Training Accuracy 0.9333333333333335\n",
      "Dataset 1 | Epoch 90 | Unfreezed Training Loss: 0.09238686601941784 | Unfreezed Training Accuracy 0.9733333333333334\n",
      "Dataset 1 | Epoch 100 | Unfreezed Training Loss: 0.017674527895481636 | Unfreezed Training Accuracy 1.0\n",
      "Dataset 1 | Unfreezed Test Loss: 0.09792567789554596 | Unfreezed Test Accuracy 1.0\n",
      "Dataset 2 | Epoch 10 | Training Loss: 0.7073437949021657 | Training Accuracy 0.7066666666666668\n",
      "Dataset 2 | Epoch 20 | Training Loss: 0.4432291805744171 | Training Accuracy 0.8800000000000001\n",
      "Dataset 2 | Epoch 30 | Training Loss: 0.25616025974353157 | Training Accuracy 0.9333333333333333\n",
      "Dataset 2 | Epoch 40 | Training Loss: 0.23784883668025333 | Training Accuracy 0.9466666666666667\n",
      "Dataset 2 | Epoch 50 | Training Loss: 0.28888052875796955 | Training Accuracy 0.92\n",
      "Dataset 2 | Test Loss: 0.24812009930610657 | Test Accuracy 0.9199999999999999\n",
      "Dataset 2 | Epoch 10 | Unfreezed Training Loss: 0.1365095897888144 | Unfreezed Training Accuracy 0.9733333333333333\n",
      "Dataset 2 | Epoch 20 | Unfreezed Training Loss: 0.07966203661635518 | Unfreezed Training Accuracy 0.9733333333333333\n",
      "Dataset 2 | Epoch 30 | Unfreezed Training Loss: 0.048345094469065465 | Unfreezed Training Accuracy 0.9733333333333334\n",
      "Dataset 2 | Epoch 40 | Unfreezed Training Loss: 0.15309785790741443 | Unfreezed Training Accuracy 0.9733333333333334\n",
      "Dataset 2 | Epoch 50 | Unfreezed Training Loss: 0.06253215766822298 | Unfreezed Training Accuracy 0.9866666666666667\n",
      "Dataset 2 | Epoch 60 | Unfreezed Training Loss: 0.13471881402656435 | Unfreezed Training Accuracy 0.9599999999999999\n",
      "Dataset 2 | Epoch 70 | Unfreezed Training Loss: 0.05052085062488913 | Unfreezed Training Accuracy 1.0\n",
      "Dataset 2 | Epoch 80 | Unfreezed Training Loss: 0.020156457282913227 | Unfreezed Training Accuracy 1.0\n",
      "Dataset 2 | Epoch 90 | Unfreezed Training Loss: 0.09279341448564082 | Unfreezed Training Accuracy 0.9600000000000001\n",
      "Dataset 2 | Epoch 100 | Unfreezed Training Loss: 0.058253283915109935 | Unfreezed Training Accuracy 0.9600000000000001\n",
      "Dataset 2 | Unfreezed Test Loss: 0.2704079747200012 | Unfreezed Test Accuracy 0.8800000000000001\n",
      "Dataset 3 | Epoch 10 | Training Loss: 0.6079670816659928 | Training Accuracy 0.7466666666666667\n",
      "Dataset 3 | Epoch 20 | Training Loss: 0.43709963063399 | Training Accuracy 0.8533333333333334\n",
      "Dataset 3 | Epoch 30 | Training Loss: 0.29023896108071007 | Training Accuracy 0.9066666666666666\n",
      "Dataset 3 | Epoch 40 | Training Loss: 0.2969789445400238 | Training Accuracy 0.9066666666666667\n",
      "Dataset 3 | Epoch 50 | Training Loss: 0.2977266358832518 | Training Accuracy 0.88\n",
      "Dataset 3 | Test Loss: 0.23322255909442902 | Test Accuracy 0.8800000000000001\n",
      "Dataset 3 | Epoch 10 | Unfreezed Training Loss: 0.13212110556972523 | Unfreezed Training Accuracy 1.0\n",
      "Dataset 3 | Epoch 20 | Unfreezed Training Loss: 0.07908610105902578 | Unfreezed Training Accuracy 0.9866666666666667\n",
      "Dataset 3 | Epoch 30 | Unfreezed Training Loss: 0.051571606565266846 | Unfreezed Training Accuracy 0.9866666666666667\n",
      "Dataset 3 | Epoch 40 | Unfreezed Training Loss: 0.13698619920760394 | Unfreezed Training Accuracy 0.9733333333333333\n",
      "Dataset 3 | Epoch 50 | Unfreezed Training Loss: 0.0426421805517748 | Unfreezed Training Accuracy 1.0\n",
      "Dataset 3 | Epoch 60 | Unfreezed Training Loss: 0.02208006752965351 | Unfreezed Training Accuracy 1.0\n",
      "Dataset 3 | Epoch 70 | Unfreezed Training Loss: 0.07272175008547492 | Unfreezed Training Accuracy 0.9733333333333333\n",
      "Dataset 3 | Epoch 80 | Unfreezed Training Loss: 0.1321205236017704 | Unfreezed Training Accuracy 0.92\n",
      "Dataset 3 | Epoch 90 | Unfreezed Training Loss: 0.04188977449666709 | Unfreezed Training Accuracy 0.9866666666666667\n",
      "Dataset 3 | Epoch 100 | Unfreezed Training Loss: 0.03797552220833798 | Unfreezed Training Accuracy 0.9866666666666667\n",
      "Dataset 3 | Unfreezed Test Loss: 0.07004599273204803 | Unfreezed Test Accuracy 1.0\n",
      "Dataset 4 | Epoch 10 | Training Loss: 0.6745190064112345 | Training Accuracy 0.7466666666666667\n",
      "Dataset 4 | Epoch 20 | Training Loss: 0.379259625573953 | Training Accuracy 0.8933333333333333\n",
      "Dataset 4 | Epoch 30 | Training Loss: 0.4042777975400289 | Training Accuracy 0.8933333333333332\n",
      "Dataset 4 | Epoch 40 | Training Loss: 0.20165654097994168 | Training Accuracy 0.9466666666666668\n",
      "Dataset 4 | Epoch 50 | Training Loss: 0.36902983374893666 | Training Accuracy 0.8933333333333333\n",
      "Dataset 4 | Test Loss: 0.2947138249874115 | Test Accuracy 0.9199999999999999\n",
      "Dataset 4 | Epoch 10 | Unfreezed Training Loss: 0.060522762748102345 | Unfreezed Training Accuracy 0.9866666666666667\n",
      "Dataset 4 | Epoch 20 | Unfreezed Training Loss: 0.029940408437202373 | Unfreezed Training Accuracy 0.9866666666666667\n",
      "Dataset 4 | Epoch 30 | Unfreezed Training Loss: 0.03866923047074427 | Unfreezed Training Accuracy 0.9866666666666667\n",
      "Dataset 4 | Epoch 40 | Unfreezed Training Loss: 0.034512752954227226 | Unfreezed Training Accuracy 0.9866666666666667\n",
      "Dataset 4 | Epoch 50 | Unfreezed Training Loss: 0.22423270273332793 | Unfreezed Training Accuracy 0.9466666666666668\n",
      "Dataset 4 | Epoch 60 | Unfreezed Training Loss: 0.02191188626845057 | Unfreezed Training Accuracy 1.0\n",
      "Dataset 4 | Epoch 70 | Unfreezed Training Loss: 0.01404881476579855 | Unfreezed Training Accuracy 1.0\n",
      "Dataset 4 | Epoch 80 | Unfreezed Training Loss: 0.05203527060026924 | Unfreezed Training Accuracy 0.9733333333333333\n",
      "Dataset 4 | Epoch 90 | Unfreezed Training Loss: 0.042226024072927734 | Unfreezed Training Accuracy 1.0\n",
      "Dataset 4 | Epoch 100 | Unfreezed Training Loss: 0.14436587233406803 | Unfreezed Training Accuracy 0.9466666666666667\n",
      "Dataset 4 | Unfreezed Test Loss: 0.1704055517911911 | Unfreezed Test Accuracy 0.9199999999999999\n",
      "Dataset 5 | Epoch 10 | Training Loss: 0.5580977161725362 | Training Accuracy 0.8533333333333334\n",
      "Dataset 5 | Epoch 20 | Training Loss: 0.5021155461668968 | Training Accuracy 0.7866666666666666\n",
      "Dataset 5 | Epoch 30 | Training Loss: 0.2636544418831666 | Training Accuracy 0.9333333333333333\n",
      "Dataset 5 | Epoch 40 | Training Loss: 0.3533718263109525 | Training Accuracy 0.9066666666666667\n",
      "Dataset 5 | Epoch 50 | Training Loss: 0.191713589305679 | Training Accuracy 0.9600000000000002\n",
      "Dataset 5 | Test Loss: 0.2247530221939087 | Test Accuracy 0.9199999999999999\n",
      "Dataset 5 | Epoch 10 | Unfreezed Training Loss: 0.09478720308591922 | Unfreezed Training Accuracy 0.9733333333333333\n",
      "Dataset 5 | Epoch 20 | Unfreezed Training Loss: 0.08790805983978013 | Unfreezed Training Accuracy 0.9600000000000002\n",
      "Dataset 5 | Epoch 30 | Unfreezed Training Loss: 0.05427480509970337 | Unfreezed Training Accuracy 0.9866666666666667\n",
      "Dataset 5 | Epoch 40 | Unfreezed Training Loss: 0.025500989922632774 | Unfreezed Training Accuracy 1.0\n",
      "Dataset 5 | Epoch 50 | Unfreezed Training Loss: 0.02837863069338103 | Unfreezed Training Accuracy 1.0\n",
      "Dataset 5 | Epoch 60 | Unfreezed Training Loss: 0.1279293875830869 | Unfreezed Training Accuracy 0.9333333333333335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 5 | Epoch 70 | Unfreezed Training Loss: 0.1436296508841527 | Unfreezed Training Accuracy 0.9600000000000001\n",
      "Dataset 5 | Epoch 80 | Unfreezed Training Loss: 0.015798903105314822 | Unfreezed Training Accuracy 1.0\n",
      "Dataset 5 | Epoch 90 | Unfreezed Training Loss: 0.047279136312621026 | Unfreezed Training Accuracy 0.9866666666666667\n",
      "Dataset 5 | Epoch 100 | Unfreezed Training Loss: 0.0448555547123154 | Unfreezed Training Accuracy 0.9866666666666667\n",
      "Dataset 5 | Unfreezed Test Loss: 0.20235474407672882 | Unfreezed Test Accuracy 0.9199999999999999\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "fin_test_loss = []\n",
    "fin_test_acc = []\n",
    "\n",
    "fin_test_loss_aug = []\n",
    "fin_test_acc_aug = []\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    # Option1:\n",
    "#     transform = v2.Compose([\n",
    "#     v2.Resize((224, 224)), # Resizing to 224x224\n",
    "#     v2.ToTensor(), #moving to tensor\n",
    "#     #v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalizing not needed as \n",
    "#     ])\n",
    "    \n",
    "    # Option2:\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)), # Resizing to 224x224\n",
    "        transforms.ToTensor(), #moving to tensor\n",
    "    ])\n",
    "    \n",
    "    dataset = torchvision.datasets.ImageFolder('EuroSAT_RGB/EuroSAT_RGB', transform=transform)\n",
    "    dataset = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "    stop = False\n",
    "    images_arr = []\n",
    "    labels_arr = []\n",
    "    while not stop:## Iterating until stop is True\n",
    "\n",
    "        batch = next(iter(dataset))# Getting batch of 32 images\n",
    "\n",
    "        for imh_num in range(batch[0].shape[0]): # Iterate through each image in batch\n",
    "\n",
    "            image = batch[0][imh_num] \n",
    "            label = batch[1][imh_num].item()\n",
    "\n",
    "            if (len(np.unique(labels_arr)) == 5 and np.isin(label, unique_values) or len(np.unique(labels_arr)) < 5)\\\n",
    "                and len(labels_arr)<100:\n",
    "\n",
    "                unique_values, counts = np.unique(labels_arr, return_counts=True)\n",
    "                indx = np.where(unique_values == label)\n",
    "\n",
    "                if counts[indx] < 20 or not np.isin(label, unique_values):\n",
    "\n",
    "                    images_arr.append(image)\n",
    "                    labels_arr.append(label)\n",
    "\n",
    "            if len(labels_arr) == 100: # Once we reach 100 images we stop\n",
    "                stop = True\n",
    "\n",
    "    ## This is required as Model expects labels to have values starting with 0 if we want to use as final output less values than we had previosuly\n",
    "\n",
    "    value_mapping = dict(zip(np.unique(labels_arr), range(0, len(np.unique(labels_arr)))))\n",
    "    arr_mapped = np.vectorize(value_mapping.get)(labels_arr)\n",
    "\n",
    "    ## If you want to test that its indeed generating each time unique image dataset change list(arr_mapped) to labels_arr.\n",
    "    ## It will show images with original labels, but then model wont workS\n",
    "    train_img, test_img, train_labels, test_labels = train_test_split(images_arr, list(arr_mapped), test_size = 0.25, random_state = 0, stratify = labels_arr)\n",
    "    train_data_loader = torch.utils.data.DataLoader(list(zip(train_img, train_labels)), batch_size=5, shuffle=True)\n",
    "    test_data_loader = torch.utils.data.DataLoader(list(zip(test_img, test_labels)), batch_size=5, shuffle=True)\n",
    "\n",
    "    # Just checking for image visualization\n",
    "    #images, labels = next(iter(train_data_loader))\n",
    "    #plt.imshow(np.transpose(images[1], (1, 2, 0)))\n",
    "    #print(labels[1].item())\n",
    "    #plt.show()\n",
    "\n",
    "## Loading the model each time for the training\n",
    "    resnet18 = torchvision.models.resnet18(pretrained=True)\n",
    "    for param in resnet18.parameters():\n",
    "        param.requires_grad = False\n",
    "    resnet18.fc = nn.Linear(512, 64) # Changign last layer to output 64 features\n",
    "\n",
    "    model = resnet18 # Initialize the model structure\n",
    "    model.load_state_dict(torch.load('resnet18_model.pt', map_location=torch.device('cpu')))\n",
    "    model.fc = nn.Linear(512, 5) \n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(50):\n",
    "        bce_loss = nn.CrossEntropyLoss()\n",
    "        model.train()\n",
    "        running_train_loss = 0.\n",
    "        running_train_acc = 0.\n",
    "\n",
    "        for g, data in enumerate(train_data_loader):\n",
    "            images, labels = data\n",
    "            labels = labels.type(torch.LongTensor) ## This is required as it expect in Long format, but for some reason after replacing label values with 0,1,2... it returned as wide format\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred_labels = model.forward(images)\n",
    "\n",
    "            loss = bce_loss(pred_labels, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_train_acc += get_acc(torch.argmax(pred_labels, dim = 1).detach().cpu().numpy(), labels.detach().cpu().numpy())\n",
    "            running_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = running_train_loss / len(train_data_loader)\n",
    "        avg_train_acc = running_train_acc / len(train_data_loader)\n",
    "\n",
    "        if (epoch+1)%10==0:\n",
    "            print(f'Dataset {i+1} | Epoch {epoch+1} | Training Loss: {avg_train_loss} | Training Accuracy {avg_train_acc}')\n",
    "\n",
    "\n",
    "    ## Evaluating model on train test to see our accuracy\n",
    "    model.eval()\n",
    "\n",
    "    running_test_acc = 0.\n",
    "    running_test_loss = 0.\n",
    "    \n",
    "    for g, data in enumerate(test_data_loader):\n",
    "        bce_loss = nn.CrossEntropyLoss()\n",
    "        images_test, labels_test = data\n",
    "        labels_test = labels_test.type(torch.LongTensor)\n",
    "        images_test, labels_test = images_test.to(device), labels_test.to(device)\n",
    "    \n",
    "        y_pred_labels = model.forward(images_test)\n",
    "        test_loss = bce_loss(y_pred_labels, labels_test)\n",
    "    \n",
    "        running_test_loss += test_loss\n",
    "        running_test_acc += get_acc(torch.argmax(y_pred_labels, dim = 1).detach().cpu().numpy(), labels_test.detach().cpu().numpy())\n",
    "        \n",
    "        \n",
    "    avg_test_loss = running_test_loss / len(test_data_loader)\n",
    "    avg_test_acc = running_test_acc / len(test_data_loader)\n",
    "    \n",
    "    print(f'Dataset {i+1} | Test Loss: {avg_test_loss} | Test Accuracy {avg_test_acc}')\n",
    "\n",
    "    fin_test_loss.append(avg_test_loss)\n",
    "    fin_test_acc.append(avg_test_acc)\n",
    "\n",
    "\n",
    "## Preloading model same as in previous steps\n",
    "    resnet18 = torchvision.models.resnet18(pretrained=True)\n",
    "    for param in resnet18.parameters():\n",
    "        param.requires_grad = False\n",
    "    resnet18.fc = nn.Linear(512, 64) # Changign last layer to output 64 featurs\n",
    "\n",
    "    model = resnet18 # Initialize the model structure\n",
    "    model.load_state_dict(torch.load('resnet18_model.pt', map_location=torch.device('cpu')))\n",
    "    model.fc = nn.Linear(512, 5) \n",
    "\n",
    "    for param in model.layer4.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001, weight_decay=0.01)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(100):\n",
    "        bce_loss = nn.CrossEntropyLoss()\n",
    "        model.train()\n",
    "        running_train_loss = 0.\n",
    "        running_train_acc = 0.\n",
    "\n",
    "        for g, data in enumerate(train_data_loader):\n",
    "            images, labels = data\n",
    "            labels = labels.type(torch.LongTensor) ## This is required as it expect in Long format, but for some reason after replacing label values with 0,1,2... it returned as wide format\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred_labels = model.forward(images)\n",
    "\n",
    "            loss = bce_loss(pred_labels, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_train_acc += get_acc(torch.argmax(pred_labels, dim = 1).detach().cpu().numpy(), labels.detach().cpu().numpy())\n",
    "            running_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss_aug = running_train_loss / len(train_data_loader)\n",
    "        avg_train_acc_aug = running_train_acc / len(train_data_loader)\n",
    "\n",
    "        if (epoch+1)%10==0:\n",
    "            print(f'Dataset {i+1} | Epoch {epoch+1} | Unfreezed Training Loss: {avg_train_loss_aug} | Unfreezed Training Accuracy {avg_train_acc_aug}')\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    running_test_acc = 0.\n",
    "    running_test_loss = 0.\n",
    "    \n",
    "    for g, data in enumerate(test_data_loader):\n",
    "        bce_loss = nn.CrossEntropyLoss()\n",
    "        images_test, labels_test = data\n",
    "        labels_test = labels_test.type(torch.LongTensor)\n",
    "        images_test, labels_test = images_test.to(device), labels_test.to(device)\n",
    "    \n",
    "        y_pred_labels = model.forward(images_test)\n",
    "        test_loss = bce_loss(y_pred_labels, labels_test)\n",
    "    \n",
    "        running_test_loss += test_loss\n",
    "        running_test_acc += get_acc(torch.argmax(y_pred_labels, dim = 1).detach().cpu().numpy(), labels_test.detach().cpu().numpy())\n",
    "        \n",
    "        \n",
    "    avg_test_loss = running_test_loss / len(test_data_loader)\n",
    "    avg_test_acc = running_test_acc / len(test_data_loader)\n",
    "    \n",
    "    print(f'Dataset {i+1} | Unfreezed Test Loss: {avg_test_loss} | Unfreezed Test Accuracy {avg_test_acc}')\n",
    "\n",
    "    fin_test_loss_aug.append(avg_test_loss)\n",
    "    fin_test_acc_aug.append(avg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Unfreezed layers avg test accuracy is 0.944 and loss is 0.16222798824310303\n",
      "Without Unfreezed layers avg test accuracy is 0.9119999999999999 and loss is 0.2784717381000519\n"
     ]
    }
   ],
   "source": [
    "# WITH UNFREEZING V2\n",
    "\n",
    "fin_test_loss_aug = [x for x in fin_test_loss_aug]\n",
    "fin_test_loss = [x for x in fin_test_loss]\n",
    "\n",
    "\n",
    "print (f'With Unfreezed layers avg test accuracy is {torch.mean(torch.tensor(fin_test_acc_aug))} and loss is {torch.mean(torch.tensor(fin_test_loss_aug))}')\n",
    "print (f'Without Unfreezed layers avg test accuracy is {torch.mean(torch.tensor(fin_test_acc))} and loss is {torch.mean(torch.tensor(fin_test_loss))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 EuroSAT: ResNet18 w & w/o freezing v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 | Epoch 10 | Training Loss: 0.5608939945697784 | Training Accuracy 0.8133333333333334\n",
      "Dataset 1 | Epoch 20 | Training Loss: 0.42408994138240813 | Training Accuracy 0.9066666666666667\n",
      "Dataset 1 | Epoch 30 | Training Loss: 0.33352275788784025 | Training Accuracy 0.9066666666666666\n",
      "Dataset 1 | Epoch 40 | Training Loss: 0.29139218827088675 | Training Accuracy 0.92\n",
      "Dataset 1 | Epoch 50 | Training Loss: 0.20674103274941444 | Training Accuracy 0.9600000000000001\n",
      "Dataset 1 | Test Loss: 0.1793377697467804 | Test Accuracy 0.96\n",
      "Dataset 1 | Epoch 10 | Unfreezed Training Loss: 1.4803040345509848 | Unfreezed Training Accuracy 0.36000000000000004\n",
      "Dataset 1 | Epoch 20 | Unfreezed Training Loss: 1.293644920984904 | Unfreezed Training Accuracy 0.4666666666666667\n",
      "Dataset 1 | Epoch 30 | Unfreezed Training Loss: 1.115692150592804 | Unfreezed Training Accuracy 0.6133333333333334\n",
      "Dataset 1 | Epoch 40 | Unfreezed Training Loss: 0.9903124292691549 | Unfreezed Training Accuracy 0.7600000000000001\n",
      "Dataset 1 | Epoch 50 | Unfreezed Training Loss: 0.9529927968978882 | Unfreezed Training Accuracy 0.7599999999999999\n",
      "Dataset 1 | Epoch 60 | Unfreezed Training Loss: 0.8668044567108154 | Unfreezed Training Accuracy 0.7466666666666667\n",
      "Dataset 1 | Epoch 70 | Unfreezed Training Loss: 0.7411448140939076 | Unfreezed Training Accuracy 0.8666666666666668\n",
      "Dataset 1 | Epoch 80 | Unfreezed Training Loss: 0.7100626746813457 | Unfreezed Training Accuracy 0.8666666666666667\n",
      "Dataset 1 | Epoch 90 | Unfreezed Training Loss: 0.562992517153422 | Unfreezed Training Accuracy 0.9333333333333335\n",
      "Dataset 1 | Epoch 100 | Unfreezed Training Loss: 0.47613690594832103 | Unfreezed Training Accuracy 0.9600000000000002\n",
      "Dataset 1 | Epoch 110 | Unfreezed Training Loss: 0.5330047527949016 | Unfreezed Training Accuracy 0.8800000000000001\n",
      "Dataset 1 | Epoch 120 | Unfreezed Training Loss: 0.4737127999464671 | Unfreezed Training Accuracy 0.9333333333333333\n",
      "Dataset 1 | Epoch 130 | Unfreezed Training Loss: 0.38418494959672295 | Unfreezed Training Accuracy 0.9600000000000001\n",
      "Dataset 1 | Epoch 140 | Unfreezed Training Loss: 0.42126956284046174 | Unfreezed Training Accuracy 0.9333333333333335\n",
      "Dataset 1 | Epoch 150 | Unfreezed Training Loss: 0.3557512452205022 | Unfreezed Training Accuracy 0.9600000000000001\n",
      "Dataset 1 | Unfreezed Test Loss: 0.4519777297973633 | Unfreezed Test Accuracy 0.8400000000000001\n",
      "Dataset 2 | Epoch 10 | Training Loss: 0.5012522945801418 | Training Accuracy 0.8800000000000002\n",
      "Dataset 2 | Epoch 20 | Training Loss: 0.29791061182816825 | Training Accuracy 0.9733333333333333\n",
      "Dataset 2 | Epoch 30 | Training Loss: 0.35953153123458226 | Training Accuracy 0.8933333333333333\n",
      "Dataset 2 | Epoch 40 | Training Loss: 0.3298341838022073 | Training Accuracy 0.8666666666666668\n",
      "Dataset 2 | Epoch 50 | Training Loss: 0.19015057521561782 | Training Accuracy 0.9466666666666667\n",
      "Dataset 2 | Test Loss: 0.2997405529022217 | Test Accuracy 0.8800000000000001\n",
      "Dataset 2 | Epoch 10 | Unfreezed Training Loss: 1.441162077585856 | Unfreezed Training Accuracy 0.44000000000000006\n",
      "Dataset 2 | Epoch 20 | Unfreezed Training Loss: 1.3193764448165894 | Unfreezed Training Accuracy 0.5066666666666666\n",
      "Dataset 2 | Epoch 30 | Unfreezed Training Loss: 1.1203104217847188 | Unfreezed Training Accuracy 0.6533333333333334\n",
      "Dataset 2 | Epoch 40 | Unfreezed Training Loss: 1.100825802485148 | Unfreezed Training Accuracy 0.6133333333333332\n",
      "Dataset 2 | Epoch 50 | Unfreezed Training Loss: 0.9217513362566631 | Unfreezed Training Accuracy 0.76\n",
      "Dataset 2 | Epoch 60 | Unfreezed Training Loss: 0.8731842478116353 | Unfreezed Training Accuracy 0.7866666666666666\n",
      "Dataset 2 | Epoch 70 | Unfreezed Training Loss: 0.758578085899353 | Unfreezed Training Accuracy 0.8533333333333334\n",
      "Dataset 2 | Epoch 80 | Unfreezed Training Loss: 0.5904056966304779 | Unfreezed Training Accuracy 0.9733333333333333\n",
      "Dataset 2 | Epoch 90 | Unfreezed Training Loss: 0.6135585884253184 | Unfreezed Training Accuracy 0.9066666666666667\n",
      "Dataset 2 | Epoch 100 | Unfreezed Training Loss: 0.5553521871566772 | Unfreezed Training Accuracy 0.9066666666666667\n",
      "Dataset 2 | Epoch 110 | Unfreezed Training Loss: 0.5643286923567454 | Unfreezed Training Accuracy 0.9066666666666666\n",
      "Dataset 2 | Epoch 120 | Unfreezed Training Loss: 0.4289443631966909 | Unfreezed Training Accuracy 0.9466666666666667\n",
      "Dataset 2 | Epoch 130 | Unfreezed Training Loss: 0.367327473560969 | Unfreezed Training Accuracy 0.9333333333333333\n",
      "Dataset 2 | Epoch 140 | Unfreezed Training Loss: 0.4563335965077082 | Unfreezed Training Accuracy 0.92\n",
      "Dataset 2 | Epoch 150 | Unfreezed Training Loss: 0.4110638161500295 | Unfreezed Training Accuracy 0.9733333333333334\n",
      "Dataset 2 | Unfreezed Test Loss: 0.5417654514312744 | Unfreezed Test Accuracy 0.8800000000000001\n",
      "Dataset 3 | Epoch 10 | Training Loss: 0.7339663525422414 | Training Accuracy 0.7466666666666668\n",
      "Dataset 3 | Epoch 20 | Training Loss: 0.43091282645861306 | Training Accuracy 0.8933333333333333\n",
      "Dataset 3 | Epoch 30 | Training Loss: 0.2630162790417671 | Training Accuracy 0.9466666666666667\n",
      "Dataset 3 | Epoch 40 | Training Loss: 0.3244228074947993 | Training Accuracy 0.8666666666666668\n",
      "Dataset 3 | Epoch 50 | Training Loss: 0.18657426660259566 | Training Accuracy 0.9466666666666669\n",
      "Dataset 3 | Test Loss: 0.5243284106254578 | Test Accuracy 0.8\n",
      "Dataset 3 | Epoch 10 | Unfreezed Training Loss: 1.659256931145986 | Unfreezed Training Accuracy 0.27999999999999997\n",
      "Dataset 3 | Epoch 20 | Unfreezed Training Loss: 1.3458583037058511 | Unfreezed Training Accuracy 0.5066666666666666\n",
      "Dataset 3 | Epoch 30 | Unfreezed Training Loss: 1.2539076169331869 | Unfreezed Training Accuracy 0.4933333333333333\n",
      "Dataset 3 | Epoch 40 | Unfreezed Training Loss: 1.0414372444152833 | Unfreezed Training Accuracy 0.6533333333333332\n",
      "Dataset 3 | Epoch 50 | Unfreezed Training Loss: 1.0479042530059814 | Unfreezed Training Accuracy 0.6266666666666666\n",
      "Dataset 3 | Epoch 60 | Unfreezed Training Loss: 0.8417515516281128 | Unfreezed Training Accuracy 0.76\n",
      "Dataset 3 | Epoch 70 | Unfreezed Training Loss: 0.8202352205912272 | Unfreezed Training Accuracy 0.72\n",
      "Dataset 3 | Epoch 80 | Unfreezed Training Loss: 0.690068260828654 | Unfreezed Training Accuracy 0.8400000000000001\n",
      "Dataset 3 | Epoch 90 | Unfreezed Training Loss: 0.6986433525880178 | Unfreezed Training Accuracy 0.8800000000000001\n",
      "Dataset 3 | Epoch 100 | Unfreezed Training Loss: 0.7128503322601318 | Unfreezed Training Accuracy 0.8133333333333334\n",
      "Dataset 3 | Epoch 110 | Unfreezed Training Loss: 0.5866145879030228 | Unfreezed Training Accuracy 0.8533333333333335\n",
      "Dataset 3 | Epoch 120 | Unfreezed Training Loss: 0.5504265904426575 | Unfreezed Training Accuracy 0.8800000000000002\n",
      "Dataset 3 | Epoch 130 | Unfreezed Training Loss: 0.5227365831534068 | Unfreezed Training Accuracy 0.92\n",
      "Dataset 3 | Epoch 140 | Unfreezed Training Loss: 0.4985143045584361 | Unfreezed Training Accuracy 0.9066666666666666\n",
      "Dataset 3 | Epoch 150 | Unfreezed Training Loss: 0.576558185617129 | Unfreezed Training Accuracy 0.9066666666666666\n",
      "Dataset 3 | Unfreezed Test Loss: 0.5750809907913208 | Unfreezed Test Accuracy 0.8\n",
      "Dataset 4 | Epoch 10 | Training Loss: 0.639485075076421 | Training Accuracy 0.7733333333333333\n",
      "Dataset 4 | Epoch 20 | Training Loss: 0.3704323396086693 | Training Accuracy 0.8800000000000001\n",
      "Dataset 4 | Epoch 30 | Training Loss: 0.26777959764003756 | Training Accuracy 0.9066666666666666\n",
      "Dataset 4 | Epoch 40 | Training Loss: 0.21488644778728486 | Training Accuracy 0.92\n",
      "Dataset 4 | Epoch 50 | Training Loss: 0.19948549903929233 | Training Accuracy 0.9066666666666667\n",
      "Dataset 4 | Test Loss: 0.3751368522644043 | Test Accuracy 0.8800000000000001\n",
      "Dataset 4 | Epoch 10 | Unfreezed Training Loss: 1.6763118505477905 | Unfreezed Training Accuracy 0.22666666666666668\n",
      "Dataset 4 | Epoch 20 | Unfreezed Training Loss: 1.442123572031657 | Unfreezed Training Accuracy 0.29333333333333333\n",
      "Dataset 4 | Epoch 30 | Unfreezed Training Loss: 1.126806664466858 | Unfreezed Training Accuracy 0.5466666666666665\n",
      "Dataset 4 | Epoch 40 | Unfreezed Training Loss: 1.0056214332580566 | Unfreezed Training Accuracy 0.6533333333333334\n",
      "Dataset 4 | Epoch 50 | Unfreezed Training Loss: 0.9347296833992005 | Unfreezed Training Accuracy 0.7200000000000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 4 | Epoch 60 | Unfreezed Training Loss: 0.7947090943654378 | Unfreezed Training Accuracy 0.7466666666666666\n",
      "Dataset 4 | Epoch 70 | Unfreezed Training Loss: 0.7575373391310374 | Unfreezed Training Accuracy 0.8133333333333334\n",
      "Dataset 4 | Epoch 80 | Unfreezed Training Loss: 0.687869789203008 | Unfreezed Training Accuracy 0.8400000000000001\n",
      "Dataset 4 | Epoch 90 | Unfreezed Training Loss: 0.613182270526886 | Unfreezed Training Accuracy 0.8933333333333333\n",
      "Dataset 4 | Epoch 100 | Unfreezed Training Loss: 0.4827963640292486 | Unfreezed Training Accuracy 0.9466666666666668\n",
      "Dataset 4 | Epoch 110 | Unfreezed Training Loss: 0.41946218609809877 | Unfreezed Training Accuracy 0.9600000000000001\n",
      "Dataset 4 | Epoch 120 | Unfreezed Training Loss: 0.42937727669874826 | Unfreezed Training Accuracy 0.92\n",
      "Dataset 4 | Epoch 130 | Unfreezed Training Loss: 0.46991870005925496 | Unfreezed Training Accuracy 0.8933333333333333\n",
      "Dataset 4 | Epoch 140 | Unfreezed Training Loss: 0.4357589448491732 | Unfreezed Training Accuracy 0.8933333333333332\n",
      "Dataset 4 | Epoch 150 | Unfreezed Training Loss: 0.48379986236492795 | Unfreezed Training Accuracy 0.9066666666666666\n",
      "Dataset 4 | Unfreezed Test Loss: 0.3091427981853485 | Unfreezed Test Accuracy 1.0\n",
      "Dataset 5 | Epoch 10 | Training Loss: 0.5194851915041606 | Training Accuracy 0.8933333333333334\n",
      "Dataset 5 | Epoch 20 | Training Loss: 0.4644800206025442 | Training Accuracy 0.8533333333333334\n",
      "Dataset 5 | Epoch 30 | Training Loss: 0.3050533021489779 | Training Accuracy 0.9333333333333336\n",
      "Dataset 5 | Epoch 40 | Training Loss: 0.24243509496251742 | Training Accuracy 0.9333333333333335\n",
      "Dataset 5 | Epoch 50 | Training Loss: 0.2515318604807059 | Training Accuracy 0.88\n",
      "Dataset 5 | Test Loss: 0.3700574040412903 | Test Accuracy 0.8\n",
      "Dataset 5 | Epoch 10 | Unfreezed Training Loss: 1.469353159268697 | Unfreezed Training Accuracy 0.3733333333333333\n",
      "Dataset 5 | Epoch 20 | Unfreezed Training Loss: 1.2745195666948954 | Unfreezed Training Accuracy 0.5333333333333333\n",
      "Dataset 5 | Epoch 30 | Unfreezed Training Loss: 1.0805617213249206 | Unfreezed Training Accuracy 0.6666666666666666\n",
      "Dataset 5 | Epoch 40 | Unfreezed Training Loss: 0.9606428543726603 | Unfreezed Training Accuracy 0.7733333333333333\n",
      "Dataset 5 | Epoch 50 | Unfreezed Training Loss: 0.846651554107666 | Unfreezed Training Accuracy 0.8133333333333334\n",
      "Dataset 5 | Epoch 60 | Unfreezed Training Loss: 0.750198495388031 | Unfreezed Training Accuracy 0.8133333333333334\n",
      "Dataset 5 | Epoch 70 | Unfreezed Training Loss: 0.7184589326381683 | Unfreezed Training Accuracy 0.84\n",
      "Dataset 5 | Epoch 80 | Unfreezed Training Loss: 0.6279031892617544 | Unfreezed Training Accuracy 0.8933333333333333\n",
      "Dataset 5 | Epoch 90 | Unfreezed Training Loss: 0.541115274031957 | Unfreezed Training Accuracy 0.9466666666666667\n",
      "Dataset 5 | Epoch 100 | Unfreezed Training Loss: 0.5743893265724183 | Unfreezed Training Accuracy 0.88\n",
      "Dataset 5 | Epoch 110 | Unfreezed Training Loss: 0.5645339628060658 | Unfreezed Training Accuracy 0.8800000000000002\n",
      "Dataset 5 | Epoch 120 | Unfreezed Training Loss: 0.48842883308728535 | Unfreezed Training Accuracy 0.8933333333333333\n",
      "Dataset 5 | Epoch 130 | Unfreezed Training Loss: 0.3843694135546684 | Unfreezed Training Accuracy 0.9733333333333333\n",
      "Dataset 5 | Epoch 140 | Unfreezed Training Loss: 0.37884903450806934 | Unfreezed Training Accuracy 0.9466666666666668\n",
      "Dataset 5 | Epoch 150 | Unfreezed Training Loss: 0.3759429256121318 | Unfreezed Training Accuracy 0.9466666666666667\n",
      "Dataset 5 | Unfreezed Test Loss: 0.5129867196083069 | Unfreezed Test Accuracy 0.8\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "fin_test_loss = []\n",
    "fin_test_acc = []\n",
    "\n",
    "fin_test_loss_aug = []\n",
    "fin_test_acc_aug = []\n",
    "\n",
    "\n",
    "loss_results = []\n",
    "acc_results = []\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    # Option1:\n",
    "#     transform = v2.Compose([\n",
    "#     v2.Resize((224, 224)), # Resizing to 224x224\n",
    "#     v2.ToTensor(), #moving to tensor\n",
    "#     #v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalizing not needed as \n",
    "#     ])\n",
    "    \n",
    "    # Option2:\n",
    "    transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), # Resizing to 224x224\n",
    "    transforms.ToTensor(), #moving to tensor\n",
    "    #v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalizing not needed as \n",
    "    ])\n",
    "    \n",
    "    dataset = torchvision.datasets.ImageFolder('EuroSAT_RGB/EuroSAT_RGB', transform=transform)\n",
    "    dataset = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "    stop = False\n",
    "    images_arr = []\n",
    "    labels_arr = []\n",
    "    while not stop:## Iterating until stop is True\n",
    "\n",
    "        batch = next(iter(dataset))# Getting batch of 32 images\n",
    "\n",
    "        for imh_num in range(batch[0].shape[0]): # Iterate through each image in batch\n",
    "\n",
    "            image = batch[0][imh_num] \n",
    "            label = batch[1][imh_num].item()\n",
    "\n",
    "            if (len(np.unique(labels_arr)) == 5 and np.isin(label, unique_values) or len(np.unique(labels_arr)) < 5)\\\n",
    "                and len(labels_arr)<100:\n",
    "\n",
    "                unique_values, counts = np.unique(labels_arr, return_counts=True)\n",
    "                indx = np.where(unique_values == label)\n",
    "\n",
    "                if counts[indx] < 20 or not np.isin(label, unique_values):\n",
    "\n",
    "                    images_arr.append(image)\n",
    "                    labels_arr.append(label)\n",
    "\n",
    "            if len(labels_arr) == 100: # Once we reach 100 images we stop\n",
    "                stop = True\n",
    "\n",
    "    ## This is required as Model expects labels to have values starting with 0 if we want to use as final output less values than we had previosuly\n",
    "\n",
    "    value_mapping = dict(zip(np.unique(labels_arr), range(0, len(np.unique(labels_arr)))))\n",
    "    arr_mapped = np.vectorize(value_mapping.get)(labels_arr)\n",
    "\n",
    "    ## If you want to test that its indeed generating each time unique image dataset change list(arr_mapped) to labels_arr.\n",
    "    ## It will show images with original labels, but then model wont workS\n",
    "    train_img, test_img, train_labels, test_labels = train_test_split(images_arr, list(arr_mapped), test_size = 0.25, random_state = 0, stratify = labels_arr)\n",
    "    train_data_loader = torch.utils.data.DataLoader(list(zip(train_img, train_labels)), batch_size=5, shuffle=True)\n",
    "    test_data_loader = torch.utils.data.DataLoader(list(zip(test_img, test_labels)), batch_size=5, shuffle=True)\n",
    "\n",
    "    # Just checking for image visualization\n",
    "    #images, labels = next(iter(train_data_loader))\n",
    "    #plt.imshow(np.transpose(images[1], (1, 2, 0)))\n",
    "    #print(labels[1].item())\n",
    "    #plt.show()\n",
    "\n",
    "    ## Loading the model each time for the training\n",
    "    resnet18 = torchvision.models.resnet18(pretrained=True)\n",
    "    for param in resnet18.parameters():\n",
    "        param.requires_grad = False\n",
    "    resnet18.fc = nn.Linear(512, 64) # Changign last layer to output 64 features\n",
    "\n",
    "    model = resnet18 # Initialize the model structure\n",
    "    model.load_state_dict(torch.load('resnet18_model.pt', map_location=torch.device('cpu')))\n",
    "    model.fc = nn.Linear(512, 5) \n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "\n",
    "    for epoch in range(50):\n",
    "        bce_loss = nn.CrossEntropyLoss()\n",
    "        model.train()\n",
    "        running_train_loss = 0.\n",
    "        running_train_acc = 0.\n",
    "\n",
    "        for g, data in enumerate(train_data_loader):\n",
    "            images, labels = data\n",
    "            labels = labels.type(torch.LongTensor) ## This is required as it expect in Long format, but for some reason after replacing label values with 0,1,2... it returned as wide format\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred_labels = model.forward(images)\n",
    "\n",
    "            loss = bce_loss(pred_labels, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_train_acc += get_acc(torch.argmax(pred_labels, dim = 1).detach().cpu().numpy(), labels.detach().cpu().numpy())\n",
    "            running_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = running_train_loss / len(train_data_loader)\n",
    "        avg_train_acc = running_train_acc / len(train_data_loader)\n",
    "\n",
    "        if (epoch+1)%10==0:\n",
    "            print(f'Dataset {i+1} | Epoch {epoch+1} | Training Loss: {avg_train_loss} | Training Accuracy {avg_train_acc}')\n",
    "\n",
    "\n",
    "    ## Evaluating model on train test to see our accuracy\n",
    "    model.eval()\n",
    "\n",
    "    running_test_acc = 0.\n",
    "    running_test_loss = 0.\n",
    "    \n",
    "    for g, data in enumerate(test_data_loader):\n",
    "        bce_loss = nn.CrossEntropyLoss()\n",
    "        images_test, labels_test = data\n",
    "        labels_test = labels_test.type(torch.LongTensor)\n",
    "        images_test, labels_test = images_test.to(device), labels_test.to(device)\n",
    "    \n",
    "        y_pred_labels = model.forward(images_test)\n",
    "        test_loss = bce_loss(y_pred_labels, labels_test)\n",
    "    \n",
    "        running_test_loss += test_loss\n",
    "        running_test_acc += get_acc(torch.argmax(y_pred_labels, dim = 1).detach().cpu().numpy(), labels_test.detach().cpu().numpy())\n",
    "        \n",
    "        \n",
    "    avg_test_loss = running_test_loss / len(test_data_loader)\n",
    "    avg_test_acc = running_test_acc / len(test_data_loader)\n",
    "    \n",
    "    print(f'Dataset {i+1} | Test Loss: {avg_test_loss} | Test Accuracy {avg_test_acc}')\n",
    "\n",
    "    fin_test_loss.append(avg_test_loss)\n",
    "    fin_test_acc.append(avg_test_acc)\n",
    "\n",
    "\n",
    "## Preloading model same as in previous steps\n",
    "    resnet18 = torchvision.models.resnet18(pretrained=True)\n",
    "    for param in resnet18.parameters():\n",
    "        param.requires_grad = False\n",
    "    resnet18.fc = nn.Linear(512, 64) # Changign last layer to output 64 featurs\n",
    "\n",
    "    model = resnet18 # Initialize the model structure\n",
    "    model.load_state_dict(torch.load('resnet18_model.pt', map_location=torch.device('cpu')))\n",
    "    model.fc = nn.Linear(512, 5) \n",
    "\n",
    "    for param in model.layer4.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.000001, \n",
    "                                 #weight_decay=0.00001)\n",
    "                                )\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    ls = []\n",
    "    ac = []\n",
    "\n",
    "    for epoch in range(150):\n",
    "        bce_loss = nn.CrossEntropyLoss()\n",
    "        model.train()\n",
    "        running_train_loss = 0.\n",
    "        running_train_acc = 0.\n",
    "\n",
    "        for g, data in enumerate(train_data_loader):\n",
    "            images, labels = data\n",
    "            labels = labels.type(torch.LongTensor) ## This is required as it expect in Long format, but for some reason after replacing label values with 0,1,2... it returned as wide format\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred_labels = model.forward(images)\n",
    "\n",
    "            loss = bce_loss(pred_labels, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_train_acc += get_acc(torch.argmax(pred_labels, dim = 1).detach().cpu().numpy(), labels.detach().cpu().numpy())\n",
    "            running_train_loss += loss.item()\n",
    "\n",
    "\n",
    "        avg_train_loss_aug = running_train_loss / len(train_data_loader)\n",
    "        avg_train_acc_aug = running_train_acc / len(train_data_loader)\n",
    "\n",
    "        ls.append(avg_train_loss_aug)\n",
    "        ac.append(avg_train_acc_aug)\n",
    "\n",
    "        if (epoch+1)%10==0:\n",
    "            print(f'Dataset {i+1} | Epoch {epoch+1} | Unfreezed Training Loss: {avg_train_loss_aug} | Unfreezed Training Accuracy {avg_train_acc_aug}')\n",
    "\n",
    "    loss_results.append(ls)\n",
    "    acc_results.append(ac)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    running_test_acc = 0.\n",
    "    running_test_loss = 0.\n",
    "    \n",
    "    for g, data in enumerate(test_data_loader):\n",
    "        bce_loss = nn.CrossEntropyLoss()\n",
    "        images_test, labels_test = data\n",
    "        labels_test = labels_test.type(torch.LongTensor)\n",
    "        images_test, labels_test = images_test.to(device), labels_test.to(device)\n",
    "    \n",
    "        y_pred_labels = model.forward(images_test)\n",
    "        test_loss = bce_loss(y_pred_labels, labels_test)\n",
    "    \n",
    "        running_test_loss += test_loss\n",
    "        running_test_acc += get_acc(torch.argmax(y_pred_labels, dim = 1).detach().cpu().numpy(), labels_test.detach().cpu().numpy())\n",
    "        \n",
    "        \n",
    "    avg_test_loss = running_test_loss / len(test_data_loader)\n",
    "    avg_test_acc = running_test_acc / len(test_data_loader)\n",
    "    \n",
    "    print(f'Dataset {i+1} | Unfreezed Test Loss: {avg_test_loss} | Unfreezed Test Accuracy {avg_test_acc}')\n",
    "\n",
    "    fin_test_loss_aug.append(avg_test_loss)\n",
    "    fin_test_acc_aug.append(avg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Unfreezed layers avg test accuracy is 0.8640000000000001 and loss is 0.47819074988365173\n",
      "Without Unfreezed layers avg test accuracy is 0.8640000000000001 and loss is 0.34972018003463745\n"
     ]
    }
   ],
   "source": [
    "# WITH UNFREEZING V2\n",
    "\n",
    "fin_test_loss_aug = [x for x in fin_test_loss_aug]\n",
    "fin_test_loss = [x for x in fin_test_loss]\n",
    "\n",
    "\n",
    "print (f'With Unfreezed layers avg test accuracy is {torch.mean(torch.tensor(fin_test_acc_aug))} and loss is {torch.mean(torch.tensor(fin_test_loss_aug))}')\n",
    "print (f'Without Unfreezed layers avg test accuracy is {torch.mean(torch.tensor(fin_test_acc))} and loss is {torch.mean(torch.tensor(fin_test_loss))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 EuroSAT: ResNet18 w & w/o changed optimizer, introduction of Step Learner and unfrozen 3rd and 4th layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has yelded the best result with on average 5% improvement in accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 | Epoch 10 | Training Loss: 0.5997679630915324 | Training Accuracy 0.8533333333333333\n",
      "Dataset 1 | Epoch 20 | Training Loss: 0.4216290255387624 | Training Accuracy 0.8666666666666667\n",
      "Dataset 1 | Epoch 30 | Training Loss: 0.24203631492952507 | Training Accuracy 0.9333333333333333\n",
      "Dataset 1 | Epoch 40 | Training Loss: 0.2893396593630314 | Training Accuracy 0.92\n",
      "Dataset 1 | Epoch 50 | Training Loss: 0.3613928941388925 | Training Accuracy 0.8800000000000001\n",
      "Dataset 1 | Test Loss: 0.6446877121925354 | Test Accuracy 0.8800000000000001\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Dataset 1 | Epoch 10 | Unfreezed Training Loss: 0.05467582304651539 | Unfreezed Training Accuracy 1.0\n",
      "Dataset 1 | Epoch 20 | Unfreezed Training Loss: 0.09423513460593919 | Unfreezed Training Accuracy 0.9733333333333333\n",
      "Dataset 1 | Epoch 30 | Unfreezed Training Loss: 0.15510200311740238 | Unfreezed Training Accuracy 0.9599999999999999\n",
      "Dataset 1 | Epoch 40 | Unfreezed Training Loss: 0.05798072858403126 | Unfreezed Training Accuracy 0.9866666666666667\n",
      "Dataset 1 | Epoch 50 | Unfreezed Training Loss: 0.06550459278126558 | Unfreezed Training Accuracy 1.0\n",
      "Dataset 1 | Unfreezed Test Loss: 0.47779256105422974 | Unfreezed Test Accuracy 0.8800000000000001\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Dataset 2 | Epoch 10 | Training Loss: 0.6903857241074244 | Training Accuracy 0.7733333333333334\n",
      "Dataset 2 | Epoch 20 | Training Loss: 0.3901504561305046 | Training Accuracy 0.9200000000000002\n",
      "Dataset 2 | Epoch 30 | Training Loss: 0.37804548889398576 | Training Accuracy 0.8933333333333334\n",
      "Dataset 2 | Epoch 40 | Training Loss: 0.3138435413440069 | Training Accuracy 0.9066666666666667\n",
      "Dataset 2 | Epoch 50 | Training Loss: 0.24392570555210114 | Training Accuracy 0.9333333333333333\n",
      "Dataset 2 | Test Loss: 0.3753938674926758 | Test Accuracy 0.8800000000000001\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Dataset 2 | Epoch 10 | Unfreezed Training Loss: 0.11164313089102507 | Unfreezed Training Accuracy 0.9733333333333333\n",
      "Dataset 2 | Epoch 20 | Unfreezed Training Loss: 0.11215824874428411 | Unfreezed Training Accuracy 0.9733333333333333\n",
      "Dataset 2 | Epoch 30 | Unfreezed Training Loss: 0.08171330417195956 | Unfreezed Training Accuracy 1.0\n",
      "Dataset 2 | Epoch 40 | Unfreezed Training Loss: 0.0367173133417964 | Unfreezed Training Accuracy 1.0\n",
      "Dataset 2 | Epoch 50 | Unfreezed Training Loss: 0.1500419361827274 | Unfreezed Training Accuracy 0.9733333333333333\n",
      "Dataset 2 | Unfreezed Test Loss: 0.341386079788208 | Unfreezed Test Accuracy 0.8799999999999999\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Dataset 3 | Epoch 10 | Training Loss: 0.5421732127666473 | Training Accuracy 0.8399999999999999\n",
      "Dataset 3 | Epoch 20 | Training Loss: 0.33271019359429677 | Training Accuracy 0.8933333333333333\n",
      "Dataset 3 | Epoch 30 | Training Loss: 0.26759490196903546 | Training Accuracy 0.9466666666666668\n",
      "Dataset 3 | Epoch 40 | Training Loss: 0.25829506367444993 | Training Accuracy 0.9066666666666667\n",
      "Dataset 3 | Epoch 50 | Training Loss: 0.19131493208309014 | Training Accuracy 0.9466666666666668\n",
      "Dataset 3 | Test Loss: 0.19081568717956543 | Test Accuracy 1.0\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Dataset 3 | Epoch 10 | Unfreezed Training Loss: 0.10543123297393323 | Unfreezed Training Accuracy 0.9733333333333333\n",
      "Dataset 3 | Epoch 20 | Unfreezed Training Loss: 0.1555428002650539 | Unfreezed Training Accuracy 0.92\n",
      "Dataset 3 | Epoch 30 | Unfreezed Training Loss: 0.09111348750690619 | Unfreezed Training Accuracy 0.9866666666666667\n",
      "Dataset 3 | Epoch 40 | Unfreezed Training Loss: 0.15368791348300875 | Unfreezed Training Accuracy 0.9600000000000001\n",
      "Dataset 3 | Epoch 50 | Unfreezed Training Loss: 0.08295694896951318 | Unfreezed Training Accuracy 0.9866666666666667\n",
      "Dataset 3 | Unfreezed Test Loss: 0.10094936937093735 | Unfreezed Test Accuracy 1.0\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Dataset 4 | Epoch 10 | Training Loss: 0.5667137463887533 | Training Accuracy 0.8266666666666665\n",
      "Dataset 4 | Epoch 20 | Training Loss: 0.40391124387582145 | Training Accuracy 0.92\n",
      "Dataset 4 | Epoch 30 | Training Loss: 0.19730869680643082 | Training Accuracy 0.9866666666666667\n",
      "Dataset 4 | Epoch 40 | Training Loss: 0.31186396926641463 | Training Accuracy 0.9066666666666667\n",
      "Dataset 4 | Epoch 50 | Training Loss: 0.22865772483249505 | Training Accuracy 0.9333333333333333\n",
      "Dataset 4 | Test Loss: 0.38329336047172546 | Test Accuracy 0.8400000000000001\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Dataset 4 | Epoch 10 | Unfreezed Training Loss: 0.18531095311045648 | Unfreezed Training Accuracy 0.9466666666666667\n",
      "Dataset 4 | Epoch 20 | Unfreezed Training Loss: 0.1318248523399234 | Unfreezed Training Accuracy 0.9600000000000001\n",
      "Dataset 4 | Epoch 30 | Unfreezed Training Loss: 0.0558021882083267 | Unfreezed Training Accuracy 1.0\n",
      "Dataset 4 | Epoch 40 | Unfreezed Training Loss: 0.06602298778792222 | Unfreezed Training Accuracy 1.0\n",
      "Dataset 4 | Epoch 50 | Unfreezed Training Loss: 0.0680600222821037 | Unfreezed Training Accuracy 1.0\n",
      "Dataset 4 | Unfreezed Test Loss: 0.32591912150382996 | Unfreezed Test Accuracy 0.8800000000000001\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Dataset 5 | Epoch 10 | Training Loss: 0.690906302134196 | Training Accuracy 0.7466666666666666\n",
      "Dataset 5 | Epoch 20 | Training Loss: 0.3023982549707095 | Training Accuracy 0.9600000000000001\n",
      "Dataset 5 | Epoch 30 | Training Loss: 0.23988549088438352 | Training Accuracy 0.9466666666666668\n",
      "Dataset 5 | Epoch 40 | Training Loss: 0.28781627913316093 | Training Accuracy 0.9333333333333333\n",
      "Dataset 5 | Epoch 50 | Training Loss: 0.2600783556699753 | Training Accuracy 0.9333333333333333\n",
      "Dataset 5 | Test Loss: 0.23634831607341766 | Test Accuracy 0.8800000000000001\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Dataset 5 | Epoch 10 | Unfreezed Training Loss: 0.18433827171102166 | Unfreezed Training Accuracy 0.9333333333333332\n",
      "Dataset 5 | Epoch 20 | Unfreezed Training Loss: 0.06937189244975646 | Unfreezed Training Accuracy 0.9866666666666667\n",
      "Dataset 5 | Epoch 30 | Unfreezed Training Loss: 0.10239266542096932 | Unfreezed Training Accuracy 1.0\n",
      "Dataset 5 | Epoch 40 | Unfreezed Training Loss: 0.05986351259052754 | Unfreezed Training Accuracy 1.0\n",
      "Dataset 5 | Epoch 50 | Unfreezed Training Loss: 0.090212599777927 | Unfreezed Training Accuracy 0.9866666666666667\n",
      "Dataset 5 | Unfreezed Test Loss: 0.24597382545471191 | Unfreezed Test Accuracy 0.9199999999999999\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "fin_test_loss = []\n",
    "fin_test_acc = []\n",
    "\n",
    "fin_test_loss_aug = []\n",
    "fin_test_acc_aug = []\n",
    "\n",
    "\n",
    "loss_results = []\n",
    "acc_results = []\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    # Option1:\n",
    "#     transform = v2.Compose([\n",
    "#     v2.Resize((224, 224)), # Resizing to 224x224\n",
    "#     v2.ToTensor(), #moving to tensor\n",
    "#     #v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalizing not needed as \n",
    "#     ])\n",
    "    \n",
    "    # Option2:\n",
    "    transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), # Resizing to 224x224\n",
    "    transforms.ToTensor(), #moving to tensor\n",
    "    #v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalizing not needed as \n",
    "    ])\n",
    "    \n",
    "    dataset = torchvision.datasets.ImageFolder('EuroSAT_RGB/EuroSAT_RGB', transform=transform)\n",
    "    dataset = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "    stop = False\n",
    "    images_arr = []\n",
    "    labels_arr = []\n",
    "    while not stop:## Iterating until stop is True\n",
    "\n",
    "        batch = next(iter(dataset))# Getting batch of 32 images\n",
    "\n",
    "        for imh_num in range(batch[0].shape[0]): # Iterate through each image in batch\n",
    "\n",
    "            image = batch[0][imh_num] \n",
    "            label = batch[1][imh_num].item()\n",
    "\n",
    "            if (len(np.unique(labels_arr)) == 5 and np.isin(label, unique_values) or len(np.unique(labels_arr)) < 5)\\\n",
    "                and len(labels_arr)<100:\n",
    "\n",
    "                unique_values, counts = np.unique(labels_arr, return_counts=True)\n",
    "                indx = np.where(unique_values == label)\n",
    "\n",
    "                if counts[indx] < 20 or not np.isin(label, unique_values):\n",
    "\n",
    "                    images_arr.append(image)\n",
    "                    labels_arr.append(label)\n",
    "\n",
    "            if len(labels_arr) == 100: # Once we reach 100 images we stop\n",
    "                stop = True\n",
    "\n",
    "    ## This is required as Model expects labels to have values starting with 0 if we want to use as final output less values than we had previosuly\n",
    "\n",
    "    value_mapping = dict(zip(np.unique(labels_arr), range(0, len(np.unique(labels_arr)))))\n",
    "    arr_mapped = np.vectorize(value_mapping.get)(labels_arr)\n",
    "\n",
    "    ## If you want to test that its indeed generating each time unique image dataset change list(arr_mapped) to labels_arr.\n",
    "    ## It will show images with original labels, but then model wont workS\n",
    "    train_img, test_img, train_labels, test_labels = train_test_split(images_arr, list(arr_mapped), test_size = 0.25, random_state = 0, stratify = labels_arr)\n",
    "    train_data_loader = torch.utils.data.DataLoader(list(zip(train_img, train_labels)), batch_size=5, shuffle=True)\n",
    "    test_data_loader = torch.utils.data.DataLoader(list(zip(test_img, test_labels)), batch_size=5, shuffle=True)\n",
    "\n",
    "    # Just checking for image visualization\n",
    "    #images, labels = next(iter(train_data_loader))\n",
    "    #plt.imshow(np.transpose(images[1], (1, 2, 0)))\n",
    "    #print(labels[1].item())\n",
    "    #plt.show()\n",
    "\n",
    "    ## Loading the model each time for the training\n",
    "    resnet18 = torchvision.models.resnet18(pretrained=True)\n",
    "    for param in resnet18.parameters():\n",
    "        param.requires_grad = False\n",
    "    resnet18.fc = nn.Linear(512, 64) # Changign last layer to output 64 features\n",
    "\n",
    "    model = resnet18 # Initialize the model structure\n",
    "    model.load_state_dict(torch.load('resnet18_model.pt', map_location=torch.device('cpu')))\n",
    "    model.fc = nn.Linear(512, 5) \n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "\n",
    "    for epoch in range(50):\n",
    "        bce_loss = nn.CrossEntropyLoss()\n",
    "        model.train()\n",
    "        running_train_loss = 0.\n",
    "        running_train_acc = 0.\n",
    "\n",
    "        for g, data in enumerate(train_data_loader):\n",
    "            images, labels = data\n",
    "            labels = labels.type(torch.LongTensor) ## This is required as it expect in Long format, but for some reason after replacing label values with 0,1,2... it returned as wide format\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred_labels = model.forward(images)\n",
    "\n",
    "            loss = bce_loss(pred_labels, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_train_acc += get_acc(torch.argmax(pred_labels, dim = 1).detach().cpu().numpy(), labels.detach().cpu().numpy())\n",
    "            running_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = running_train_loss / len(train_data_loader)\n",
    "        avg_train_acc = running_train_acc / len(train_data_loader)\n",
    "\n",
    "        if (epoch+1)%10==0:\n",
    "            print(f'Dataset {i+1} | Epoch {epoch+1} | Training Loss: {avg_train_loss} | Training Accuracy {avg_train_acc}')\n",
    "\n",
    "\n",
    "    ## Evaluating model on train test to see our accuracy\n",
    "    model.eval()\n",
    "\n",
    "    running_test_acc = 0.\n",
    "    running_test_loss = 0.\n",
    "    \n",
    "    for g, data in enumerate(test_data_loader):\n",
    "        bce_loss = nn.CrossEntropyLoss()\n",
    "        images_test, labels_test = data\n",
    "        labels_test = labels_test.type(torch.LongTensor)\n",
    "        images_test, labels_test = images_test.to(device), labels_test.to(device)\n",
    "    \n",
    "        y_pred_labels = model.forward(images_test)\n",
    "        test_loss = bce_loss(y_pred_labels, labels_test)\n",
    "    \n",
    "        running_test_loss += test_loss\n",
    "        running_test_acc += get_acc(torch.argmax(y_pred_labels, dim = 1).detach().cpu().numpy(), labels_test.detach().cpu().numpy())\n",
    "        \n",
    "        \n",
    "    avg_test_loss = running_test_loss / len(test_data_loader)\n",
    "    avg_test_acc = running_test_acc / len(test_data_loader)\n",
    "    \n",
    "    print(f'Dataset {i+1} | Test Loss: {avg_test_loss} | Test Accuracy {avg_test_acc}')\n",
    "    print('-'*110)\n",
    "\n",
    "    fin_test_loss.append(avg_test_loss)\n",
    "    fin_test_acc.append(avg_test_acc)\n",
    "\n",
    "\n",
    "    ## Preloading model same as in previous steps\n",
    "    resnet18 = torchvision.models.resnet18(pretrained=True)\n",
    "    for param in resnet18.parameters():\n",
    "        param.requires_grad = False\n",
    "    resnet18.fc = nn.Linear(512, 64) # Changign last layer to output 64 featurs\n",
    "\n",
    "    model = resnet18 # Initialize the model structure\n",
    "    model.load_state_dict(torch.load('resnet18_model.pt', map_location=torch.device('cpu')))\n",
    "    model.fc = nn.Linear(512, 5) \n",
    "\n",
    "    for param in model.layer3.parameters():\n",
    "        param.requires_grad = True\n",
    "    for param in model.layer4.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = 0.001, momentum=0.9\n",
    "                                )\n",
    "    \n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    ls = []\n",
    "    ac = []\n",
    "\n",
    "    for epoch in range(50):\n",
    "        bce_loss = nn.CrossEntropyLoss()\n",
    "        model.train()\n",
    "        running_train_loss = 0.\n",
    "        running_train_acc = 0.\n",
    "\n",
    "        for g, data in enumerate(train_data_loader):\n",
    "            images, labels = data\n",
    "            labels = labels.type(torch.LongTensor) ## This is required as it expect in Long format, but for some reason after replacing label values with 0,1,2... it returned as wide format\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred_labels = model.forward(images)\n",
    "\n",
    "            loss = bce_loss(pred_labels, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_train_acc += get_acc(torch.argmax(pred_labels, dim = 1).detach().cpu().numpy(), labels.detach().cpu().numpy())\n",
    "            running_train_loss += loss.item()\n",
    "\n",
    "        scheduler.step()\n",
    "        avg_train_loss_aug = running_train_loss / len(train_data_loader)\n",
    "        avg_train_acc_aug = running_train_acc / len(train_data_loader)\n",
    "\n",
    "        ls.append(avg_train_loss_aug)\n",
    "        ac.append(avg_train_acc_aug)\n",
    "\n",
    "        if (epoch+1)%10==0:\n",
    "            print(f'Dataset {i+1} | Epoch {epoch+1} | Unfreezed Training Loss: {avg_train_loss_aug} | Unfreezed Training Accuracy {avg_train_acc_aug}')\n",
    "\n",
    "    loss_results.append(ls)\n",
    "    acc_results.append(ac)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    running_test_acc = 0.\n",
    "    running_test_loss = 0.\n",
    "    \n",
    "    for g, data in enumerate(test_data_loader):\n",
    "        bce_loss = nn.CrossEntropyLoss()\n",
    "        images_test, labels_test = data\n",
    "        labels_test = labels_test.type(torch.LongTensor)\n",
    "        images_test, labels_test = images_test.to(device), labels_test.to(device)\n",
    "    \n",
    "        y_pred_labels = model.forward(images_test)\n",
    "        test_loss = bce_loss(y_pred_labels, labels_test)\n",
    "    \n",
    "        running_test_loss += test_loss\n",
    "        running_test_acc += get_acc(torch.argmax(y_pred_labels, dim = 1).detach().cpu().numpy(), labels_test.detach().cpu().numpy())\n",
    "        \n",
    "        \n",
    "    avg_test_loss = running_test_loss / len(test_data_loader)\n",
    "    avg_test_acc = running_test_acc / len(test_data_loader)\n",
    "    \n",
    "    print(f'Dataset {i+1} | Unfreezed Test Loss: {avg_test_loss} | Unfreezed Test Accuracy {avg_test_acc}')\n",
    "    print('-'*120)\n",
    "\n",
    "    fin_test_loss_aug.append(avg_test_loss)\n",
    "    fin_test_acc_aug.append(avg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Changed optimizer avg test accuracy is 0.9119999999999999 and loss is 0.2984041914343834\n",
      "Without Changed optimizer avg test accuracy is 0.8960000000000001 and loss is 0.36610778868198396\n"
     ]
    }
   ],
   "source": [
    "fin_test_loss_aug = [x.item() for x in fin_test_loss_aug]\n",
    "fin_test_loss = [x.item() for x in fin_test_loss]\n",
    "\n",
    "\n",
    "print (f'With Changed optimizer avg test accuracy is {np.mean(fin_test_acc_aug)} and loss is {np.mean(fin_test_loss_aug)}')\n",
    "print (f'Without Changed optimizer avg test accuracy is {np.mean(fin_test_acc)} and loss is {np.mean(fin_test_loss)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 EuroSAT: VIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 2.2.1 EuroSAT: VIT w and w/o augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 | Epoch 10 | Training Loss: 0.36430183400710425 | Training Accuracy 0.8933333333333332\n",
      "Dataset 1 | Epoch 20 | Training Loss: 0.04149418100714684 | Training Accuracy 1.0\n",
      "Dataset 1 | Epoch 30 | Training Loss: 0.019713115443785987 | Training Accuracy 1.0\n",
      "Dataset 1 | Epoch 40 | Training Loss: 0.012345898694669207 | Training Accuracy 1.0\n",
      "Dataset 1 | Epoch 50 | Training Loss: 0.008643029956147075 | Training Accuracy 1.0\n",
      "Dataset 1 | Test Loss: 0.3670055866241455 | Test Accuracy 0.8800000000000001\n",
      "Dataset 1 | Epoch 10 | Augmented Training Loss: 0.3979152473310629 | Augmented Training Accuracy 0.8666666666666667\n",
      "Dataset 1 | Epoch 20 | Augmented Training Loss: 0.05069485877950986 | Augmented Training Accuracy 1.0\n",
      "Dataset 1 | Epoch 30 | Augmented Training Loss: 0.02097157374955714 | Augmented Training Accuracy 1.0\n",
      "Dataset 1 | Epoch 40 | Augmented Training Loss: 0.011148336258096 | Augmented Training Accuracy 1.0\n",
      "Dataset 1 | Epoch 50 | Augmented Training Loss: 0.010555509920231998 | Augmented Training Accuracy 1.0\n",
      "Dataset 1 | Augmented Test Loss: 0.34775468707084656 | Augmented Test Accuracy 0.96\n",
      "Dataset 2 | Epoch 10 | Training Loss: 0.5984968602036437 | Training Accuracy 0.8533333333333334\n",
      "Dataset 2 | Epoch 20 | Training Loss: 0.06211418844759464 | Training Accuracy 1.0\n",
      "Dataset 2 | Epoch 30 | Training Loss: 0.025925409514456987 | Training Accuracy 1.0\n",
      "Dataset 2 | Epoch 40 | Training Loss: 0.015537229304512342 | Training Accuracy 1.0\n",
      "Dataset 2 | Epoch 50 | Training Loss: 0.010855953861027955 | Training Accuracy 1.0\n",
      "Dataset 2 | Test Loss: 1.4870463609695435 | Test Accuracy 0.64\n",
      "Dataset 2 | Epoch 10 | Augmented Training Loss: 0.5669811457395554 | Augmented Training Accuracy 0.8400000000000001\n",
      "Dataset 2 | Epoch 20 | Augmented Training Loss: 0.09125370134909948 | Augmented Training Accuracy 1.0\n",
      "Dataset 2 | Epoch 30 | Augmented Training Loss: 0.0256553723787268 | Augmented Training Accuracy 1.0\n",
      "Dataset 2 | Epoch 40 | Augmented Training Loss: 0.016530457542588313 | Augmented Training Accuracy 1.0\n",
      "Dataset 2 | Epoch 50 | Augmented Training Loss: 0.012767594152440628 | Augmented Training Accuracy 1.0\n",
      "Dataset 2 | Augmented Test Loss: 1.398452639579773 | Augmented Test Accuracy 0.6399999999999999\n",
      "Dataset 3 | Epoch 10 | Training Loss: 0.3501223985105753 | Training Accuracy 0.9333333333333333\n",
      "Dataset 3 | Epoch 20 | Training Loss: 0.03831576790350179 | Training Accuracy 1.0\n",
      "Dataset 3 | Epoch 30 | Training Loss: 0.017750463945170245 | Training Accuracy 1.0\n",
      "Dataset 3 | Epoch 40 | Training Loss: 0.011113174833978216 | Training Accuracy 1.0\n",
      "Dataset 3 | Epoch 50 | Training Loss: 0.007783428253605962 | Training Accuracy 1.0\n",
      "Dataset 3 | Test Loss: 1.0033470392227173 | Test Accuracy 0.8\n",
      "Dataset 3 | Epoch 10 | Augmented Training Loss: 0.4146590564399958 | Augmented Training Accuracy 0.8933333333333334\n",
      "Dataset 3 | Epoch 20 | Augmented Training Loss: 0.047084409681459265 | Augmented Training Accuracy 1.0\n",
      "Dataset 3 | Epoch 30 | Augmented Training Loss: 0.02353903589149316 | Augmented Training Accuracy 1.0\n",
      "Dataset 3 | Epoch 40 | Augmented Training Loss: 0.016776206518989055 | Augmented Training Accuracy 1.0\n",
      "Dataset 3 | Epoch 50 | Augmented Training Loss: 0.010909357201308012 | Augmented Training Accuracy 1.0\n",
      "Dataset 3 | Augmented Test Loss: 0.9454755187034607 | Augmented Test Accuracy 0.8\n",
      "Dataset 4 | Epoch 10 | Training Loss: 0.1763178360958894 | Training Accuracy 0.9466666666666668\n",
      "Dataset 4 | Epoch 20 | Training Loss: 0.034768597595393656 | Training Accuracy 1.0\n",
      "Dataset 4 | Epoch 30 | Training Loss: 0.01727257564974328 | Training Accuracy 1.0\n",
      "Dataset 4 | Epoch 40 | Training Loss: 0.011040132244427998 | Training Accuracy 1.0\n",
      "Dataset 4 | Epoch 50 | Training Loss: 0.007701148884370923 | Training Accuracy 1.0\n",
      "Dataset 4 | Test Loss: 0.3825792670249939 | Test Accuracy 0.9199999999999999\n",
      "Dataset 4 | Epoch 10 | Augmented Training Loss: 0.22933881878852844 | Augmented Training Accuracy 0.9066666666666667\n",
      "Dataset 4 | Epoch 20 | Augmented Training Loss: 0.034862721400956316 | Augmented Training Accuracy 1.0\n",
      "Dataset 4 | Epoch 30 | Augmented Training Loss: 0.01918159450093905 | Augmented Training Accuracy 1.0\n",
      "Dataset 4 | Epoch 40 | Augmented Training Loss: 0.01188493554169933 | Augmented Training Accuracy 1.0\n",
      "Dataset 4 | Epoch 50 | Augmented Training Loss: 0.0084326618971924 | Augmented Training Accuracy 1.0\n",
      "Dataset 4 | Augmented Test Loss: 0.24374599754810333 | Augmented Test Accuracy 0.9199999999999999\n",
      "Dataset 5 | Epoch 10 | Training Loss: 0.3563920561224222 | Training Accuracy 0.9066666666666668\n",
      "Dataset 5 | Epoch 20 | Training Loss: 0.052930121682584284 | Training Accuracy 1.0\n",
      "Dataset 5 | Epoch 30 | Training Loss: 0.023232417988280456 | Training Accuracy 1.0\n",
      "Dataset 5 | Epoch 40 | Training Loss: 0.014356042258441448 | Training Accuracy 1.0\n",
      "Dataset 5 | Epoch 50 | Training Loss: 0.00977298365905881 | Training Accuracy 1.0\n",
      "Dataset 5 | Test Loss: 1.4922642707824707 | Test Accuracy 0.6799999999999999\n",
      "Dataset 5 | Epoch 10 | Augmented Training Loss: 0.5019701444854339 | Augmented Training Accuracy 0.8533333333333335\n",
      "Dataset 5 | Epoch 20 | Augmented Training Loss: 0.0598973390335838 | Augmented Training Accuracy 1.0\n",
      "Dataset 5 | Epoch 30 | Augmented Training Loss: 0.025807461724616586 | Augmented Training Accuracy 1.0\n",
      "Dataset 5 | Epoch 40 | Augmented Training Loss: 0.01731269471347332 | Augmented Training Accuracy 1.0\n",
      "Dataset 5 | Epoch 50 | Augmented Training Loss: 0.00998171983131518 | Augmented Training Accuracy 1.0\n",
      "Dataset 5 | Augmented Test Loss: 1.367743730545044 | Augmented Test Accuracy 0.7200000000000001\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from transformers import ViTModel, ViTFeatureExtractor, ViTForImageClassification\n",
    "\n",
    "fin_test_loss = []\n",
    "fin_test_acc = []\n",
    "\n",
    "fin_test_loss_aug = []\n",
    "fin_test_acc_aug = []\n",
    "\n",
    "\n",
    "loss_results = []\n",
    "acc_results = []\n",
    "\n",
    "# fine-tuning 5 times on different 100 EuroSAT images\n",
    "for i in range(5):\n",
    "\n",
    "    # Option1:\n",
    "#     transform = v2.Compose([\n",
    "#     v2.Resize((224, 224)), # Resizing to 224x224\n",
    "#     v2.ToTensor(), #moving to tensor\n",
    "#     #v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalizing not needed as \n",
    "#     ])\n",
    "    \n",
    "    # Option2:\n",
    "    transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), # Resizing to 224x224\n",
    "    transforms.ToTensor(), #moving to tensor\n",
    "    #v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalizing not needed as \n",
    "    ])\n",
    "    \n",
    "    dataset = torchvision.datasets.ImageFolder('EuroSAT_RGB/EuroSAT_RGB', transform=transform)\n",
    "    dataset = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    # Choose 100 images from EuroSAT dataset\n",
    "    # 25 samples for 5 categories\n",
    "    stop = False\n",
    "    images_arr = []\n",
    "    labels_arr = []\n",
    "    while not stop:## Iterating until stop is True\n",
    "\n",
    "        batch = next(iter(dataset))# Getting batch of 32 images\n",
    "\n",
    "        for imh_num in range(batch[0].shape[0]): # Iterate through each image in batch\n",
    "\n",
    "            image = batch[0][imh_num] \n",
    "            label = batch[1][imh_num].item()\n",
    "\n",
    "            if (len(np.unique(labels_arr)) == 5 and np.isin(label, unique_values) or len(np.unique(labels_arr)) < 5)\\\n",
    "                and len(labels_arr)<100:\n",
    "\n",
    "                unique_values, counts = np.unique(labels_arr, return_counts=True)\n",
    "                indx = np.where(unique_values == label)\n",
    "\n",
    "                if counts[indx] < 20 or not np.isin(label, unique_values):\n",
    "\n",
    "                    images_arr.append(image)\n",
    "                    labels_arr.append(label)\n",
    "\n",
    "            if len(labels_arr) == 100: # Once we reach 100 images we stop\n",
    "                stop = True\n",
    "\n",
    "    ## This is required as Model expects labels to have values starting with 0 if we want to use as final output less values than we had previosuly\n",
    "\n",
    "    value_mapping = dict(zip(np.unique(labels_arr), range(0, len(np.unique(labels_arr)))))\n",
    "    arr_mapped = np.vectorize(value_mapping.get)(labels_arr)\n",
    "\n",
    "    # Randomly choose 25 images as training set\n",
    "    # 5 images for 5 categories\n",
    "    \n",
    "    ## If you want to test that its indeed generating each time unique image dataset change list(arr_mapped) to labels_arr.\n",
    "    ## It will show images with original labels, but then model wont workS\n",
    "    train_img, test_img, train_labels, test_labels = train_test_split(images_arr, list(arr_mapped), test_size = 0.75, random_state = 0, stratify = labels_arr)\n",
    "    train_data_loader = torch.utils.data.DataLoader(list(zip(train_img, train_labels)), batch_size=5, shuffle=True)\n",
    "    test_data_loader = torch.utils.data.DataLoader(list(zip(test_img, test_labels)), batch_size=5, shuffle=True)\n",
    "\n",
    "    # Just checking for image visualization\n",
    "    #images, labels = next(iter(train_data_loader))\n",
    "    #plt.imshow(np.transpose(images[1], (1, 2, 0)))\n",
    "    #print(labels[1].item())\n",
    "    #plt.show()\n",
    "\n",
    "## Loading the model each time for the training\n",
    "    image_processor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "    vit = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224\", return_dict=False)\n",
    "    vit = vit.to(device)\n",
    "\n",
    "    for param in vit.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    vit.classifier = nn.Linear(768,64) # Chaning final output layer to map our problem\n",
    "\n",
    "    model = vit # Initialize the model structure\n",
    "    model.load_state_dict(torch.load('vit_model.pt', map_location=torch.device('cpu')))\n",
    "    model.classifier = nn.Linear(768, 5)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "\n",
    "    for epoch in range(50):\n",
    "        bce_loss = nn.CrossEntropyLoss()\n",
    "        model.train()\n",
    "        running_train_loss = 0.\n",
    "        running_train_acc = 0.\n",
    "\n",
    "        for g, data in enumerate(train_data_loader):\n",
    "            images, labels = data\n",
    "            labels = labels.type(torch.LongTensor) ## This is required as it expect in Long format, but for some reason after replacing label values with 0,1,2... it returned as wide format\n",
    "            images = list(images.unbind())  # Unbind the images tensor into a list of image tensors\n",
    "            images = image_processor(images=images, do_normalize = False)\n",
    "            images = torch.tensor(np.stack(images['pixel_values'], axis = 0))\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred_labels = model.forward(images)\n",
    "\n",
    "            loss = bce_loss(pred_labels[0], labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_train_acc += get_acc(torch.argmax(pred_labels[0], dim = 1).detach().cpu().numpy(), labels.detach().cpu().numpy())\n",
    "            running_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = running_train_loss / len(train_data_loader)\n",
    "        avg_train_acc = running_train_acc / len(train_data_loader)\n",
    "\n",
    "        if (epoch+1)%10==0:\n",
    "            print(f'Dataset {i+1} | Epoch {epoch+1} | Training Loss: {avg_train_loss} | Training Accuracy {avg_train_acc}')\n",
    "\n",
    "    # Test model on the rest 75 samples\n",
    "    # Show results\n",
    "\n",
    "    ## Evaluating model on train test to see our accuracy\n",
    "    model.eval()\n",
    "\n",
    "    running_test_acc = 0.\n",
    "    running_test_loss = 0.\n",
    "    \n",
    "    for g, data in enumerate(test_data_loader):\n",
    "        bce_loss = nn.CrossEntropyLoss()\n",
    "        images_test, labels_test = data\n",
    "        labels_test = labels_test.type(torch.LongTensor)\n",
    "        images_test = list(images_test.unbind())  # Unbind the images tensor into a list of image tensors\n",
    "        images_test = image_processor(images=images_test, do_normalize = False)\n",
    "        images_test = torch.tensor(np.stack(images_test['pixel_values'], axis = 0))\n",
    "        images_test, labels_test = images_test.to(device), labels_test.to(device)\n",
    "    \n",
    "        y_pred_labels = model.forward(images_test)\n",
    "        test_loss = bce_loss(y_pred_labels[0], labels_test)\n",
    "    \n",
    "        running_test_loss += test_loss\n",
    "        running_test_acc += get_acc(torch.argmax(y_pred_labels[0], dim = 1).detach().cpu().numpy(), labels_test.detach().cpu().numpy())\n",
    "        \n",
    "        \n",
    "    avg_test_loss = running_test_loss / len(test_data_loader)\n",
    "    avg_test_acc = running_test_acc / len(test_data_loader)\n",
    "    \n",
    "    print(f'Dataset {i+1} | Test Loss: {avg_test_loss} | Test Accuracy {avg_test_acc}')\n",
    "\n",
    "    fin_test_loss.append(avg_test_loss)\n",
    "    fin_test_acc.append(avg_test_acc)\n",
    "\n",
    "### Here starts model with data augmentation\n",
    "\n",
    "    # Option1\n",
    "#     transform = torch.nn.Sequential(\n",
    "#     v2.RandomHorizontalFlip(p=0.5),\n",
    "#     #v2.RandomZoomOut(p = 0.3),\n",
    "#     #v2.RandomInvert(p = 0.3),\n",
    "#     v2.ToTensor()\n",
    "#     )\n",
    "\n",
    "    # Option2\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    ## Preloading model same as in previous steps\n",
    "    ## Loading the model each time for the training\n",
    "    image_processor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "    vit = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224\", return_dict=False)\n",
    "    vit = vit.to(device)\n",
    "\n",
    "    for param in vit.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    vit.classifier = nn.Linear(768,64) # Chaning final output layer to map our problem\n",
    "\n",
    "    model = vit # Initialize the model structure\n",
    "    model.load_state_dict(torch.load('vit_model.pt', map_location=torch.device('cpu')))\n",
    "    model.classifier = nn.Linear(768, 5)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.001, weight_decay=0.001)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(50):\n",
    "        bce_loss = nn.CrossEntropyLoss()\n",
    "        model.train()\n",
    "        running_train_loss = 0.\n",
    "        running_train_acc = 0.\n",
    "\n",
    "        for g, data in enumerate(train_data_loader):\n",
    "            images, labels = data\n",
    "            labels = labels.type(torch.LongTensor) ## This is required as it expect in Long format, but for some reason after replacing label values with 0,1,2... it returned as wide format\n",
    "            images = [transform(img) for img in images] ## Apply random transformation to images\n",
    "            images = torch.stack(images)\n",
    "            images = list(images.unbind())  # Unbind the images tensor into a list of image tensors\n",
    "            images = image_processor(images=images, do_normalize = False)\n",
    "            images = torch.tensor(np.stack(images['pixel_values'], axis = 0))\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred_labels = model.forward(images)\n",
    "\n",
    "            loss = bce_loss(pred_labels[0], labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_train_acc += get_acc(torch.argmax(pred_labels[0], dim = 1).detach().cpu().numpy(), labels.detach().cpu().numpy())\n",
    "            running_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss_aug = running_train_loss / len(train_data_loader)\n",
    "        avg_train_acc_aug = running_train_acc / len(train_data_loader)\n",
    "\n",
    "        if (epoch+1)%10==0:\n",
    "            print(f'Dataset {i+1} | Epoch {epoch+1} | Augmented Training Loss: {avg_train_loss_aug} | Augmented Training Accuracy {avg_train_acc_aug}')\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    running_test_acc = 0.\n",
    "    running_test_loss = 0.\n",
    "    \n",
    "    for g, data in enumerate(test_data_loader):\n",
    "        bce_loss = nn.CrossEntropyLoss()\n",
    "        images_test, labels_test = data\n",
    "        labels_test = labels_test.type(torch.LongTensor)\n",
    "        images_test = list(images_test.unbind())  # Unbind the images tensor into a list of image tensors\n",
    "        images_test = image_processor(images=images_test, do_normalize = False)\n",
    "        images_test = torch.tensor(np.stack(images_test['pixel_values'], axis = 0))\n",
    "        images_test, labels_test = images_test.to(device), labels_test.to(device)\n",
    "    \n",
    "        y_pred_labels = model.forward(images_test)\n",
    "        test_loss = bce_loss(y_pred_labels[0], labels_test)\n",
    "    \n",
    "        running_test_loss += test_loss\n",
    "        running_test_acc += get_acc(torch.argmax(y_pred_labels[0], dim = 1).detach().cpu().numpy(), labels_test.detach().cpu().numpy())\n",
    "        \n",
    "        \n",
    "    avg_test_loss = running_test_loss / len(test_data_loader)\n",
    "    avg_test_acc = running_test_acc / len(test_data_loader)\n",
    "    \n",
    "    print(f'Dataset {i+1} | Augmented Test Loss: {avg_test_loss} | Augmented Test Accuracy {avg_test_acc}')\n",
    "\n",
    "    fin_test_loss_aug.append(avg_test_loss)\n",
    "    fin_test_acc_aug.append(avg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With augmentation avg test accuracy is 0.808 and loss is 0.8606345146894455\n",
      "Without augmentation avg test accuracy is 0.784 and loss is 0.9464485049247742\n"
     ]
    }
   ],
   "source": [
    "# VIT TEST WITH AUGMENTATION\n",
    "\n",
    "# Get the average result of fine-tuned model trained on 5 datasets\n",
    "\n",
    "fin_test_loss_aug = [x.item() for x in fin_test_loss_aug]\n",
    "fin_test_loss = [x.item() for x in fin_test_loss]\n",
    "\n",
    "\n",
    "print (f'With augmentation avg test accuracy is {np.mean(fin_test_acc_aug)} and loss is {np.mean(fin_test_loss_aug)}')\n",
    "print (f'Without augmentation avg test accuracy is {np.mean(fin_test_acc)} and loss is {np.mean(fin_test_loss)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 EuroSAT: ViT w & w/o changed optimizer: Adam vs SGD, Step Learner, Unfrozen layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adam >> SGD\n",
    "\n",
    "Adam >> SGD + sched\n",
    "\n",
    "Adam >> RMS\n",
    "\n",
    "Adam > Adam + sched\n",
    "\n",
    "Adam 3 layers >> Adam 2 layers\n",
    "\n",
    "Adam 50 eps > Adam 150 eps >> Adam 10 eps\n",
    "\n",
    "ViT 5 eps > ViT 30 eps (Not always the case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adam ViT 30 ep VS Adam ViT 5 ep:\n",
    "\n",
    "1. run: acc 0.848 loss 0.7632 VS acc 0.920 loss 0.3616\n",
    "2. run: acc 0.952 loss 0.4305 VS acc 0.936 loss 0.2901\n",
    "3. run: acc 0.872 loss 1.0439 VS acc 0.887 loss 0.5506"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 | Epoch 10 | SGD Training Loss: 0.007524559297598899 | SGD Training Accuracy 1.0\n",
      "Dataset 1 | Epoch 20 | SGD Training Loss: 0.005961211794055998 | SGD Training Accuracy 1.0\n",
      "Dataset 1 | Epoch 30 | SGD Training Loss: 0.00586177078075707 | SGD Training Accuracy 1.0\n",
      "Dataset 1 | Epoch 40 | SGD Training Loss: 0.005857049805733065 | SGD Training Accuracy 1.0\n",
      "Dataset 1 | Epoch 50 | SGD Training Loss: 0.005855523911304772 | SGD Training Accuracy 1.0\n",
      "Dataset 1 | SGD Test Loss: 0.3502943217754364 | SGD Test Accuracy 0.8799999999999999\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Dataset 1 | Epoch 10 | Adam Training Loss: 3.8546564269381633e-05 | Adam Training Accuracy 1.0\n",
      "Dataset 1 | Epoch 20 | Adam Training Loss: 6.54836337995827e-06 | Adam Training Accuracy 1.0\n",
      "Dataset 1 | Epoch 30 | Adam Training Loss: 7.184334255801635e-07 | Adam Training Accuracy 1.0\n",
      "Dataset 1 | Epoch 40 | Adam Training Loss: 2.2729227590427097e-07 | Adam Training Accuracy 1.0\n",
      "Dataset 1 | Epoch 50 | Adam Training Loss: 1.1126195952707954e-07 | Adam Training Accuracy 1.0\n",
      "Dataset 1 | Adam Test Loss: 0.38626790046691895 | Adam Test Accuracy 0.9199999999999999\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "Dataset 2 | Epoch 10 | SGD Training Loss: 0.006148186318265895 | SGD Training Accuracy 1.0\n",
      "Dataset 2 | Epoch 20 | SGD Training Loss: 0.005089899792801588 | SGD Training Accuracy 1.0\n",
      "Dataset 2 | Epoch 30 | SGD Training Loss: 0.00501969795829306 | SGD Training Accuracy 1.0\n",
      "Dataset 2 | Epoch 40 | SGD Training Loss: 0.005015897556828955 | SGD Training Accuracy 1.0\n",
      "Dataset 2 | Epoch 50 | SGD Training Loss: 0.005015226632046203 | SGD Training Accuracy 1.0\n",
      "Dataset 2 | SGD Test Loss: 0.8190561532974243 | SGD Test Accuracy 0.72\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Dataset 2 | Epoch 10 | Adam Training Loss: 0.0001513108582003042 | Adam Training Accuracy 1.0\n",
      "Dataset 2 | Epoch 20 | Adam Training Loss: 1.8141504824598087e-05 | Adam Training Accuracy 1.0\n",
      "Dataset 2 | Epoch 30 | Adam Training Loss: 7.462410295981196e-06 | Adam Training Accuracy 1.0\n",
      "Dataset 2 | Epoch 40 | Adam Training Loss: 3.5667219397813216e-06 | Adam Training Accuracy 1.0\n",
      "Dataset 2 | Epoch 50 | Adam Training Loss: 1.6736940779082944e-06 | Adam Training Accuracy 1.0\n",
      "Dataset 2 | Adam Test Loss: 0.6763269305229187 | Adam Test Accuracy 0.8400000000000001\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "Dataset 3 | Epoch 10 | SGD Training Loss: 0.012243801215663552 | SGD Training Accuracy 1.0\n",
      "Dataset 3 | Epoch 20 | SGD Training Loss: 0.007515955173100035 | SGD Training Accuracy 1.0\n",
      "Dataset 3 | Epoch 30 | SGD Training Loss: 0.007344581947351495 | SGD Training Accuracy 1.0\n",
      "Dataset 3 | Epoch 40 | SGD Training Loss: 0.007335860992316157 | SGD Training Accuracy 1.0\n",
      "Dataset 3 | Epoch 50 | SGD Training Loss: 0.007337612074722225 | SGD Training Accuracy 1.0\n",
      "Dataset 3 | SGD Test Loss: 0.9886261224746704 | SGD Test Accuracy 0.76\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Dataset 3 | Epoch 10 | Adam Training Loss: 0.00014018253568792716 | Adam Training Accuracy 1.0\n",
      "Dataset 3 | Epoch 20 | Adam Training Loss: 3.454318663595283e-05 | Adam Training Accuracy 1.0\n",
      "Dataset 3 | Epoch 30 | Adam Training Loss: 9.773414990377206e-06 | Adam Training Accuracy 1.0\n",
      "Dataset 3 | Epoch 40 | Adam Training Loss: 5.20383506075935e-06 | Adam Training Accuracy 1.0\n",
      "Dataset 3 | Epoch 50 | Adam Training Loss: 3.333071972141018e-06 | Adam Training Accuracy 1.0\n",
      "Dataset 3 | Adam Test Loss: 0.11340596526861191 | Adam Test Accuracy 0.96\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "Dataset 4 | Epoch 10 | SGD Training Loss: 0.0055976045518036695 | SGD Training Accuracy 1.0\n",
      "Dataset 4 | Epoch 20 | SGD Training Loss: 0.004132506119397779 | SGD Training Accuracy 1.0\n",
      "Dataset 4 | Epoch 30 | SGD Training Loss: 0.0040489151456616435 | SGD Training Accuracy 1.0\n",
      "Dataset 4 | Epoch 40 | SGD Training Loss: 0.004043033042398747 | SGD Training Accuracy 1.0\n",
      "Dataset 4 | Epoch 50 | SGD Training Loss: 0.0040416870588766566 | SGD Training Accuracy 1.0\n",
      "Dataset 4 | SGD Test Loss: 0.13237226009368896 | SGD Test Accuracy 0.9199999999999999\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Dataset 4 | Epoch 10 | Adam Training Loss: 7.343271248222057e-05 | Adam Training Accuracy 1.0\n",
      "Dataset 4 | Epoch 20 | Adam Training Loss: 2.0758180629817008e-06 | Adam Training Accuracy 1.0\n",
      "Dataset 4 | Epoch 30 | Adam Training Loss: 5.610776578161373e-07 | Adam Training Accuracy 1.0\n",
      "Dataset 4 | Epoch 40 | Adam Training Loss: 2.9087048195227304e-07 | Adam Training Accuracy 1.0\n",
      "Dataset 4 | Epoch 50 | Adam Training Loss: 1.8914533394346715e-07 | Adam Training Accuracy 1.0\n",
      "Dataset 4 | Adam Test Loss: 0.009593872353434563 | Adam Test Accuracy 1.0\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "Dataset 5 | Epoch 10 | SGD Training Loss: 0.027085142116993664 | SGD Training Accuracy 1.0\n",
      "Dataset 5 | Epoch 20 | SGD Training Loss: 0.008803333761170507 | SGD Training Accuracy 1.0\n",
      "Dataset 5 | Epoch 30 | SGD Training Loss: 0.008431179786566646 | SGD Training Accuracy 1.0\n",
      "Dataset 5 | Epoch 40 | SGD Training Loss: 0.008397110423538834 | SGD Training Accuracy 1.0\n",
      "Dataset 5 | Epoch 50 | SGD Training Loss: 0.008395145794687172 | SGD Training Accuracy 1.0\n",
      "Dataset 5 | SGD Test Loss: 0.4619412124156952 | SGD Test Accuracy 0.8400000000000001\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Dataset 5 | Epoch 10 | Adam Training Loss: 9.946613427018747e-05 | Adam Training Accuracy 1.0\n",
      "Dataset 5 | Epoch 20 | Adam Training Loss: 1.9190354820845337e-05 | Adam Training Accuracy 1.0\n",
      "Dataset 5 | Epoch 30 | Adam Training Loss: 7.723042555577801e-06 | Adam Training Accuracy 1.0\n",
      "Dataset 5 | Epoch 40 | Adam Training Loss: 4.157980614157471e-06 | Adam Training Accuracy 1.0\n",
      "Dataset 5 | Epoch 50 | Adam Training Loss: 2.5494745078920763e-06 | Adam Training Accuracy 1.0\n",
      "Dataset 5 | Adam Test Loss: 0.30980098247528076 | Adam Test Accuracy 0.9199999999999999\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from transformers import ViTModel, ViTFeatureExtractor, ViTForImageClassification\n",
    "\n",
    "fin_test_loss = []\n",
    "fin_test_acc = []\n",
    "\n",
    "fin_test_loss_aug = []\n",
    "fin_test_acc_aug = []\n",
    "\n",
    "\n",
    "loss_results = []\n",
    "acc_results = []\n",
    "\n",
    "# fine-tuning 5 times on different 100 EuroSAT images\n",
    "for i in range(5):\n",
    "    \n",
    "    # Option2:\n",
    "    transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), # Resizing to 224x224\n",
    "    transforms.ToTensor(), #moving to tensor\n",
    "    #v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalizing not needed as \n",
    "    ])\n",
    "    \n",
    "    dataset = torchvision.datasets.ImageFolder('EuroSAT_RGB/EuroSAT_RGB', transform=transform)\n",
    "    dataset = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    # Choose 100 images from EuroSAT dataset\n",
    "    # 25 samples for 5 categories\n",
    "    stop = False\n",
    "    images_arr = []\n",
    "    labels_arr = []\n",
    "    while not stop:## Iterating until stop is True\n",
    "\n",
    "        batch = next(iter(dataset))# Getting batch of 32 images\n",
    "\n",
    "        for imh_num in range(batch[0].shape[0]): # Iterate through each image in batch\n",
    "\n",
    "            image = batch[0][imh_num] \n",
    "            label = batch[1][imh_num].item()\n",
    "\n",
    "            if (len(np.unique(labels_arr)) == 5 and np.isin(label, unique_values) or len(np.unique(labels_arr)) < 5)\\\n",
    "                and len(labels_arr)<100:\n",
    "\n",
    "                unique_values, counts = np.unique(labels_arr, return_counts=True)\n",
    "                indx = np.where(unique_values == label)\n",
    "\n",
    "                if counts[indx] < 20 or not np.isin(label, unique_values):\n",
    "\n",
    "                    images_arr.append(image)\n",
    "                    labels_arr.append(label)\n",
    "\n",
    "            if len(labels_arr) == 100: # Once we reach 100 images we stop\n",
    "                stop = True\n",
    "\n",
    "    ## This is required as Model expects labels to have values starting with 0 if we want to use as final output less values than we had previosuly\n",
    "\n",
    "    value_mapping = dict(zip(np.unique(labels_arr), range(0, len(np.unique(labels_arr)))))\n",
    "    arr_mapped = np.vectorize(value_mapping.get)(labels_arr)\n",
    "\n",
    "    # Randomly choose 25 images as training set\n",
    "    # 5 images for 5 categories\n",
    "    \n",
    "    train_img, test_img, train_labels, test_labels = train_test_split(images_arr, list(arr_mapped), test_size = 0.75, random_state = 0, stratify = labels_arr)\n",
    "    train_data_loader = torch.utils.data.DataLoader(list(zip(train_img, train_labels)), batch_size=5, shuffle=True)\n",
    "    test_data_loader = torch.utils.data.DataLoader(list(zip(test_img, test_labels)), batch_size=5, shuffle=True)\n",
    "\n",
    "## Model with SGD & Scheduler; Unfrozen 3 layers; ViT 30 epochs\n",
    "    ## Loading the model each time for the training\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    image_processor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "    vit = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224\", return_dict=False)\n",
    "    vit = vit.to(device)\n",
    "\n",
    "    for param in vit.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    vit.classifier = nn.Linear(768,64) # Chaning final output layer to map our problem\n",
    "\n",
    "    model = vit # Initialize the model structure\n",
    "    model.load_state_dict(torch.load('vit_model_5ep.pt', map_location=torch.device('cpu')))\n",
    "    \n",
    "    ## Unfreeze layer 9, 10, and 11:\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'encoder.layer.9' in name or 'encoder.layer.10' in name or 'encoder.layer.11' in name:\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    model.classifier = nn.Linear(768, 5)\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = 0.001, momentum=0.9\n",
    "                                )\n",
    "    \n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "\n",
    "    for epoch in range(50):\n",
    "        bce_loss = nn.CrossEntropyLoss()\n",
    "        model.train()\n",
    "        running_train_loss = 0.\n",
    "        running_train_acc = 0.\n",
    "\n",
    "        for g, data in enumerate(train_data_loader):\n",
    "            images, labels = data\n",
    "            labels = labels.type(torch.LongTensor) ## This is required as it expect in Long format, but for some reason after replacing label values with 0,1,2... it returned as wide format\n",
    "            images = [transform(img) for img in images] ## Apply random transformation to images\n",
    "            images = torch.stack(images)\n",
    "            images = list(images.unbind())  # Unbind the images tensor into a list of image tensors\n",
    "            images = image_processor(images=images, do_normalize = False)\n",
    "            images = torch.tensor(np.stack(images['pixel_values'], axis = 0))\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred_labels = model.forward(images)\n",
    "\n",
    "            loss = bce_loss(pred_labels[0], labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_train_acc += get_acc(torch.argmax(pred_labels[0], dim = 1).detach().cpu().numpy(), labels.detach().cpu().numpy())\n",
    "            running_train_loss += loss.item()\n",
    "\n",
    "        scheduler.step()\n",
    "        avg_train_loss = running_train_loss / len(train_data_loader)\n",
    "        avg_train_acc = running_train_acc / len(train_data_loader)\n",
    "\n",
    "        if (epoch+1)%10==0:\n",
    "            print(f'Dataset {i+1} | Epoch {epoch+1} | SGD Training Loss: {avg_train_loss} | SGD Training Accuracy {avg_train_acc}')\n",
    "\n",
    "    # Test model on the rest 75 samples\n",
    "    # Show results\n",
    "\n",
    "    ## Evaluating model on train test to see our accuracy\n",
    "    model.eval()\n",
    "\n",
    "    running_test_acc = 0.\n",
    "    running_test_loss = 0.\n",
    "    \n",
    "    for g, data in enumerate(test_data_loader):\n",
    "        bce_loss = nn.CrossEntropyLoss()\n",
    "        images_test, labels_test = data\n",
    "        labels_test = labels_test.type(torch.LongTensor)\n",
    "        images_test = list(images_test.unbind())  # Unbind the images tensor into a list of image tensors\n",
    "        images_test = image_processor(images=images_test, do_normalize = False)\n",
    "        images_test = torch.tensor(np.stack(images_test['pixel_values'], axis = 0))\n",
    "        images_test, labels_test = images_test.to(device), labels_test.to(device)\n",
    "    \n",
    "        y_pred_labels = model.forward(images_test)\n",
    "        test_loss = bce_loss(y_pred_labels[0], labels_test)\n",
    "    \n",
    "        running_test_loss += test_loss\n",
    "        running_test_acc += get_acc(torch.argmax(y_pred_labels[0], dim = 1).detach().cpu().numpy(), labels_test.detach().cpu().numpy())\n",
    "        \n",
    "        \n",
    "    avg_test_loss = running_test_loss / len(test_data_loader)\n",
    "    avg_test_acc = running_test_acc / len(test_data_loader)\n",
    "    \n",
    "    print(f'Dataset {i+1} | SGD Test Loss: {avg_test_loss} | SGD Test Accuracy {avg_test_acc}')\n",
    "    print('-'*110)\n",
    "\n",
    "    fin_test_loss.append(avg_test_loss)\n",
    "    fin_test_acc.append(avg_test_acc)\n",
    "\n",
    "### Here starts model Adam; Unfrozen 3 layers; ViT 5 epochs\n",
    "\n",
    "    # Option2\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    ## Preloading model same as in previous steps\n",
    "    ## Loading the model each time for the training\n",
    "    image_processor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "    vit = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224\", return_dict=False)\n",
    "    vit = vit.to(device)\n",
    "    \n",
    "    for param in vit.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    vit.classifier = nn.Linear(768,64) # Chaning final output layer to map our problem\n",
    "\n",
    "    model = vit # Initialize the model structure\n",
    "    model.load_state_dict(torch.load('vit_model_5ep.pt', map_location=torch.device('cpu')))\n",
    "    \n",
    "    ## Unfreeze layer 9, 10, and 11:\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'encoder.layer.9' in name or 'encoder.layer.10' in name or 'encoder.layer.11' in name:\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    model.classifier = nn.Linear(768, 5)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    ls = []\n",
    "    ac = []\n",
    "\n",
    "    for epoch in range(50):\n",
    "        bce_loss = nn.CrossEntropyLoss()\n",
    "        model.train()\n",
    "        running_train_loss = 0.\n",
    "        running_train_acc = 0.\n",
    "\n",
    "        for g, data in enumerate(train_data_loader):\n",
    "            images, labels = data\n",
    "            labels = labels.type(torch.LongTensor) ## This is required as it expect in Long format, but for some reason after replacing label values with 0,1,2... it returned as wide format\n",
    "            images = [transform(img) for img in images] ## Apply random transformation to images\n",
    "            images = torch.stack(images)\n",
    "            images = list(images.unbind())  # Unbind the images tensor into a list of image tensors\n",
    "            images = image_processor(images=images, do_normalize = False)\n",
    "            images = torch.tensor(np.stack(images['pixel_values'], axis = 0))\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred_labels = model.forward(images)\n",
    "            pred_labels = pred_labels[0]\n",
    "\n",
    "            loss = bce_loss(pred_labels, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_train_acc += get_acc(torch.argmax(pred_labels, dim = 1).detach().cpu().numpy(), labels.detach().cpu().numpy())\n",
    "            running_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss_aug = running_train_loss / len(train_data_loader)\n",
    "        avg_train_acc_aug = running_train_acc / len(train_data_loader)\n",
    "\n",
    "        ls.append(avg_train_loss_aug)\n",
    "        ac.append(avg_train_acc_aug)\n",
    "\n",
    "        if (epoch+1)%10==0:\n",
    "            print(f'Dataset {i+1} | Epoch {epoch+1} | Adam Training Loss: {avg_train_loss_aug} | Adam Training Accuracy {avg_train_acc_aug}')\n",
    "\n",
    "    loss_results.append(ls)\n",
    "    acc_results.append(ac)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    running_test_acc = 0.\n",
    "    running_test_loss = 0.\n",
    "    \n",
    "    for g, data in enumerate(test_data_loader):\n",
    "        bce_loss = nn.CrossEntropyLoss()\n",
    "        images_test, labels_test = data\n",
    "        labels_test = labels_test.type(torch.LongTensor)\n",
    "        images_test = list(images_test.unbind())  # Unbind the images tensor into a list of image tensors\n",
    "        images_test = image_processor(images=images_test, do_normalize = False)\n",
    "        images_test = torch.tensor(np.stack(images_test['pixel_values'], axis = 0))\n",
    "        images_test, labels_test = images_test.to(device), labels_test.to(device)\n",
    "    \n",
    "        y_pred_labels = model.forward(images_test)\n",
    "        y_pred_labels = y_pred_labels[0]\n",
    "        test_loss = bce_loss(y_pred_labels, labels_test)\n",
    "    \n",
    "        running_test_loss += test_loss\n",
    "        running_test_acc += get_acc(torch.argmax(y_pred_labels, dim = 1).detach().cpu().numpy(), labels_test.detach().cpu().numpy())\n",
    "        \n",
    "        \n",
    "    avg_test_loss = running_test_loss / len(test_data_loader)\n",
    "    avg_test_acc = running_test_acc / len(test_data_loader)\n",
    "    \n",
    "    print(f'Dataset {i+1} | Adam Test Loss: {avg_test_loss} | Adam Test Accuracy {avg_test_acc}')\n",
    "    print('-'*125)\n",
    "\n",
    "    fin_test_loss_aug.append(avg_test_loss)\n",
    "    fin_test_acc_aug.append(avg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD avg test accuracy is 0.8240000000000001 and loss is 0.5504580140113831\n",
      "Adam avg test accuracy is 0.9279999999999999 and loss is 0.299079130217433\n"
     ]
    }
   ],
   "source": [
    "# VIT TEST WITH SGD OPT & SCHED VS ADAM, 3 UNFROZEN LAYERS; ViT 5 epochs\n",
    "\n",
    "fin_test_loss_aug = [x.item() for x in fin_test_loss_aug]\n",
    "fin_test_loss = [x.item() for x in fin_test_loss]\n",
    "\n",
    "\n",
    "print (f'SGD avg test accuracy is {np.mean(fin_test_acc)} and loss is {np.mean(fin_test_loss)}')\n",
    "print (f'Adam avg test accuracy is {np.mean(fin_test_acc_aug)} and loss is {np.mean(fin_test_loss_aug)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 EuroSAT: ViT w & w/o changed optimizer: Adam VS RMS prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 | Epoch 10 | RMS Training Loss: 0.0015762366897736986 | RMS Training Accuracy 1.0\n",
      "Dataset 1 | Epoch 20 | RMS Training Loss: 0.0005385743919759989 | RMS Training Accuracy 1.0\n",
      "Dataset 1 | Epoch 30 | RMS Training Loss: 0.00022847149884910322 | RMS Training Accuracy 1.0\n",
      "Dataset 1 | Epoch 40 | RMS Training Loss: 0.00010333715714902306 | RMS Training Accuracy 1.0\n",
      "Dataset 1 | Epoch 50 | RMS Training Loss: 4.7653232892722976e-05 | RMS Training Accuracy 1.0\n",
      "Dataset 1 | RMS Test Loss: 0.4401203691959381 | RMS Test Accuracy 0.8800000000000001\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Dataset 1 | Epoch 10 | Adam Training Loss: 5.89576349360262e-05 | Adam Training Accuracy 1.0\n",
      "Dataset 1 | Epoch 20 | Adam Training Loss: 2.3707082592257698e-05 | Adam Training Accuracy 1.0\n",
      "Dataset 1 | Epoch 30 | Adam Training Loss: 1.093357414276852e-05 | Adam Training Accuracy 1.0\n",
      "Dataset 1 | Epoch 40 | Adam Training Loss: 6.3132245581224804e-06 | Adam Training Accuracy 1.0\n",
      "Dataset 1 | Epoch 50 | Adam Training Loss: 3.957708740169134e-06 | Adam Training Accuracy 1.0\n",
      "Dataset 1 | Adam Test Loss: 0.33564141392707825 | Adam Test Accuracy 0.8799999999999999\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "Dataset 2 | Epoch 10 | RMS Training Loss: 0.0017075611200804512 | RMS Training Accuracy 1.0\n",
      "Dataset 2 | Epoch 20 | RMS Training Loss: 0.0004794217413291335 | RMS Training Accuracy 1.0\n",
      "Dataset 2 | Epoch 30 | RMS Training Loss: 0.00017980291013373063 | RMS Training Accuracy 1.0\n",
      "Dataset 2 | Epoch 40 | RMS Training Loss: 7.460810641835754e-05 | RMS Training Accuracy 1.0\n",
      "Dataset 2 | Epoch 50 | RMS Training Loss: 3.244642224065804e-05 | RMS Training Accuracy 1.0\n",
      "Dataset 2 | RMS Test Loss: 0.8252637982368469 | RMS Test Accuracy 0.72\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Dataset 2 | Epoch 10 | Adam Training Loss: 5.2246582883223405e-05 | Adam Training Accuracy 1.0\n",
      "Dataset 2 | Epoch 20 | Adam Training Loss: 1.4838846057803797e-05 | Adam Training Accuracy 1.0\n",
      "Dataset 2 | Epoch 30 | Adam Training Loss: 7.031683776403952e-06 | Adam Training Accuracy 1.0\n",
      "Dataset 2 | Epoch 40 | Adam Training Loss: 3.5969207639633774e-06 | Adam Training Accuracy 1.0\n",
      "Dataset 2 | Epoch 50 | Adam Training Loss: 1.5258783463423243e-07 | Adam Training Accuracy 1.0\n",
      "Dataset 2 | Adam Test Loss: 1.1624146699905396 | Adam Test Accuracy 0.8800000000000001\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "Dataset 3 | Epoch 10 | RMS Training Loss: 0.0018992067663930357 | RMS Training Accuracy 1.0\n",
      "Dataset 3 | Epoch 20 | RMS Training Loss: 0.0004969926172634587 | RMS Training Accuracy 1.0\n",
      "Dataset 3 | Epoch 30 | RMS Training Loss: 0.00018099618415969113 | RMS Training Accuracy 1.0\n",
      "Dataset 3 | Epoch 40 | RMS Training Loss: 7.520094295614399e-05 | RMS Training Accuracy 1.0\n",
      "Dataset 3 | Epoch 50 | RMS Training Loss: 3.2576768959794813e-05 | RMS Training Accuracy 1.0\n",
      "Dataset 3 | RMS Test Loss: 0.12916061282157898 | RMS Test Accuracy 0.96\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Dataset 3 | Epoch 10 | Adam Training Loss: 4.3454900507337393e-05 | Adam Training Accuracy 1.0\n",
      "Dataset 3 | Epoch 20 | Adam Training Loss: 1.7319737601913705e-05 | Adam Training Accuracy 1.0\n",
      "Dataset 3 | Epoch 30 | Adam Training Loss: 9.482533588804169e-06 | Adam Training Accuracy 1.0\n",
      "Dataset 3 | Epoch 40 | Adam Training Loss: 5.812585427141433e-06 | Adam Training Accuracy 1.0\n",
      "Dataset 3 | Epoch 50 | Adam Training Loss: 3.956130770651119e-06 | Adam Training Accuracy 1.0\n",
      "Dataset 3 | Adam Test Loss: 0.0018539121374487877 | Adam Test Accuracy 1.0\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "Dataset 4 | Epoch 10 | RMS Training Loss: 0.0009194235239798824 | RMS Training Accuracy 1.0\n",
      "Dataset 4 | Epoch 20 | RMS Training Loss: 0.0003355087678452643 | RMS Training Accuracy 1.0\n",
      "Dataset 4 | Epoch 30 | RMS Training Loss: 0.00014566683530574663 | RMS Training Accuracy 1.0\n",
      "Dataset 4 | Epoch 40 | RMS Training Loss: 6.654508482218565e-05 | RMS Training Accuracy 1.0\n",
      "Dataset 4 | Epoch 50 | RMS Training Loss: 3.10349272088691e-05 | RMS Training Accuracy 1.0\n",
      "Dataset 4 | RMS Test Loss: 0.7120702862739563 | RMS Test Accuracy 0.8400000000000001\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Dataset 4 | Epoch 10 | Adam Training Loss: 9.075562995046008e-06 | Adam Training Accuracy 1.0\n",
      "Dataset 4 | Epoch 20 | Adam Training Loss: 1.7499870655986646e-06 | Adam Training Accuracy 1.0\n",
      "Dataset 4 | Epoch 30 | Adam Training Loss: 8.296952808943085e-07 | Adam Training Accuracy 1.0\n",
      "Dataset 4 | Epoch 40 | Adam Training Loss: 4.688894089592092e-07 | Adam Training Accuracy 1.0\n",
      "Dataset 4 | Epoch 50 | Adam Training Loss: 3.0517555866064564e-07 | Adam Training Accuracy 1.0\n",
      "Dataset 4 | Adam Test Loss: 0.5074569582939148 | Adam Test Accuracy 0.8800000000000001\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "Dataset 5 | Epoch 10 | RMS Training Loss: 0.0020467378742371994 | RMS Training Accuracy 1.0\n",
      "Dataset 5 | Epoch 20 | RMS Training Loss: 0.0005924379239634921 | RMS Training Accuracy 1.0\n",
      "Dataset 5 | Epoch 30 | RMS Training Loss: 0.00023147491447161883 | RMS Training Accuracy 1.0\n",
      "Dataset 5 | Epoch 40 | RMS Training Loss: 0.00010012315154502478 | RMS Training Accuracy 1.0\n",
      "Dataset 5 | Epoch 50 | RMS Training Loss: 4.499282125228395e-05 | RMS Training Accuracy 1.0\n",
      "Dataset 5 | RMS Test Loss: 0.6037315726280212 | RMS Test Accuracy 0.8\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Dataset 5 | Epoch 10 | Adam Training Loss: 6.563414032522512e-05 | Adam Training Accuracy 1.0\n",
      "Dataset 5 | Epoch 20 | Adam Training Loss: 2.218754872653032e-05 | Adam Training Accuracy 1.0\n",
      "Dataset 5 | Epoch 30 | Adam Training Loss: 8.738625604109984e-06 | Adam Training Accuracy 1.0\n",
      "Dataset 5 | Epoch 40 | Adam Training Loss: 2.8371646339545956e-06 | Adam Training Accuracy 1.0\n",
      "Dataset 5 | Epoch 50 | Adam Training Loss: 1.141227488687946e-06 | Adam Training Accuracy 1.0\n",
      "Dataset 5 | Adam Test Loss: 0.5477522015571594 | Adam Test Accuracy 0.8799999999999999\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from transformers import ViTModel, ViTFeatureExtractor, ViTForImageClassification\n",
    "\n",
    "fin_test_loss = []\n",
    "fin_test_acc = []\n",
    "\n",
    "fin_test_loss_aug = []\n",
    "fin_test_acc_aug = []\n",
    "\n",
    "\n",
    "loss_results = []\n",
    "acc_results = []\n",
    "\n",
    "# fine-tuning 5 times on different 100 EuroSAT images\n",
    "for i in range(5):\n",
    "    \n",
    "    # Option2:\n",
    "    transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), # Resizing to 224x224\n",
    "    transforms.ToTensor(), #moving to tensor\n",
    "    #v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalizing not needed as \n",
    "    ])\n",
    "    \n",
    "    dataset = torchvision.datasets.ImageFolder('EuroSAT_RGB/EuroSAT_RGB', transform=transform)\n",
    "    dataset = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    # Choose 100 images from EuroSAT dataset\n",
    "    # 25 samples for 5 categories\n",
    "    stop = False\n",
    "    images_arr = []\n",
    "    labels_arr = []\n",
    "    while not stop:## Iterating until stop is True\n",
    "\n",
    "        batch = next(iter(dataset))# Getting batch of 32 images\n",
    "\n",
    "        for imh_num in range(batch[0].shape[0]): # Iterate through each image in batch\n",
    "\n",
    "            image = batch[0][imh_num] \n",
    "            label = batch[1][imh_num].item()\n",
    "\n",
    "            if (len(np.unique(labels_arr)) == 5 and np.isin(label, unique_values) or len(np.unique(labels_arr)) < 5)\\\n",
    "                and len(labels_arr)<100:\n",
    "\n",
    "                unique_values, counts = np.unique(labels_arr, return_counts=True)\n",
    "                indx = np.where(unique_values == label)\n",
    "\n",
    "                if counts[indx] < 20 or not np.isin(label, unique_values):\n",
    "\n",
    "                    images_arr.append(image)\n",
    "                    labels_arr.append(label)\n",
    "\n",
    "            if len(labels_arr) == 100: # Once we reach 100 images we stop\n",
    "                stop = True\n",
    "\n",
    "    ## This is required as Model expects labels to have values starting with 0 if we want to use as final output less values than we had previosuly\n",
    "\n",
    "    value_mapping = dict(zip(np.unique(labels_arr), range(0, len(np.unique(labels_arr)))))\n",
    "    arr_mapped = np.vectorize(value_mapping.get)(labels_arr)\n",
    "\n",
    "    # Randomly choose 25 images as training set\n",
    "    # 5 images for 5 categories\n",
    "    \n",
    "    train_img, test_img, train_labels, test_labels = train_test_split(images_arr, list(arr_mapped), test_size = 0.75, random_state = 0, stratify = labels_arr)\n",
    "    train_data_loader = torch.utils.data.DataLoader(list(zip(train_img, train_labels)), batch_size=5, shuffle=True)\n",
    "    test_data_loader = torch.utils.data.DataLoader(list(zip(test_img, test_labels)), batch_size=5, shuffle=True)\n",
    "\n",
    "## Model with RMS prop; Unfrozen 3 layers; ViT 30 epochs\n",
    "    ## Loading the model each time for the training\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    image_processor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "    vit = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224\", return_dict=False)\n",
    "    vit = vit.to(device)\n",
    "\n",
    "    for param in vit.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    vit.classifier = nn.Linear(768,64) # Chaning final output layer to map our problem\n",
    "\n",
    "    model = vit # Initialize the model structure\n",
    "    model.load_state_dict(torch.load('vit_model_5ep.pt', map_location=torch.device('cpu')))\n",
    "    \n",
    "    ## Unfreeze layer 9, 10, and 11:\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'encoder.layer.9' in name or 'encoder.layer.10' in name or 'encoder.layer.11' in name:\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    model.classifier = nn.Linear(768, 5)\n",
    "\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(), lr = 0.0001)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "\n",
    "    for epoch in range(50):\n",
    "        bce_loss = nn.CrossEntropyLoss()\n",
    "        model.train()\n",
    "        running_train_loss = 0.\n",
    "        running_train_acc = 0.\n",
    "\n",
    "        for g, data in enumerate(train_data_loader):\n",
    "            images, labels = data\n",
    "            labels = labels.type(torch.LongTensor) ## This is required as it expect in Long format, but for some reason after replacing label values with 0,1,2... it returned as wide format\n",
    "            images = [transform(img) for img in images] ## Apply random transformation to images\n",
    "            images = torch.stack(images)\n",
    "            images = list(images.unbind())  # Unbind the images tensor into a list of image tensors\n",
    "            images = image_processor(images=images, do_normalize = False)\n",
    "            images = torch.tensor(np.stack(images['pixel_values'], axis = 0))\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred_labels = model.forward(images)\n",
    "\n",
    "            loss = bce_loss(pred_labels[0], labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_train_acc += get_acc(torch.argmax(pred_labels[0], dim = 1).detach().cpu().numpy(), labels.detach().cpu().numpy())\n",
    "            running_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = running_train_loss / len(train_data_loader)\n",
    "        avg_train_acc = running_train_acc / len(train_data_loader)\n",
    "\n",
    "        if (epoch+1)%10==0:\n",
    "            print(f'Dataset {i+1} | Epoch {epoch+1} | RMS Training Loss: {avg_train_loss} | RMS Training Accuracy {avg_train_acc}')\n",
    "\n",
    "    # Test model on the rest 75 samples\n",
    "    # Show results\n",
    "\n",
    "    ## Evaluating model on train test to see our accuracy\n",
    "    model.eval()\n",
    "\n",
    "    running_test_acc = 0.\n",
    "    running_test_loss = 0.\n",
    "    \n",
    "    for g, data in enumerate(test_data_loader):\n",
    "        bce_loss = nn.CrossEntropyLoss()\n",
    "        images_test, labels_test = data\n",
    "        labels_test = labels_test.type(torch.LongTensor)\n",
    "        images_test = list(images_test.unbind())  # Unbind the images tensor into a list of image tensors\n",
    "        images_test = image_processor(images=images_test, do_normalize = False)\n",
    "        images_test = torch.tensor(np.stack(images_test['pixel_values'], axis = 0))\n",
    "        images_test, labels_test = images_test.to(device), labels_test.to(device)\n",
    "    \n",
    "        y_pred_labels = model.forward(images_test)\n",
    "        test_loss = bce_loss(y_pred_labels[0], labels_test)\n",
    "    \n",
    "        running_test_loss += test_loss\n",
    "        running_test_acc += get_acc(torch.argmax(y_pred_labels[0], dim = 1).detach().cpu().numpy(), labels_test.detach().cpu().numpy())\n",
    "        \n",
    "        \n",
    "    avg_test_loss = running_test_loss / len(test_data_loader)\n",
    "    avg_test_acc = running_test_acc / len(test_data_loader)\n",
    "    \n",
    "    print(f'Dataset {i+1} | RMS Test Loss: {avg_test_loss} | RMS Test Accuracy {avg_test_acc}')\n",
    "    print('-'*110)\n",
    "\n",
    "    fin_test_loss.append(avg_test_loss)\n",
    "    fin_test_acc.append(avg_test_acc)\n",
    "\n",
    "### Here starts model Adam; Unfrozen 3 layers; ViT 5 epochs\n",
    "\n",
    "    # Option2\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    ## Preloading model same as in previous steps\n",
    "    ## Loading the model each time for the training\n",
    "    image_processor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "    vit = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224\", return_dict=False)\n",
    "    vit = vit.to(device)\n",
    "    \n",
    "    for param in vit.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    vit.classifier = nn.Linear(768,64) # Chaning final output layer to map our problem\n",
    "\n",
    "    model = vit # Initialize the model structure\n",
    "    model.load_state_dict(torch.load('vit_model_5ep.pt', map_location=torch.device('cpu')))\n",
    "    \n",
    "    ## Unfreeze layer 9, 10, and 11:\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'encoder.layer.9' in name or 'encoder.layer.10' in name or 'encoder.layer.11' in name:\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    model.classifier = nn.Linear(768, 5)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    ls = []\n",
    "    ac = []\n",
    "\n",
    "    for epoch in range(50):\n",
    "        bce_loss = nn.CrossEntropyLoss()\n",
    "        model.train()\n",
    "        running_train_loss = 0.\n",
    "        running_train_acc = 0.\n",
    "\n",
    "        for g, data in enumerate(train_data_loader):\n",
    "            images, labels = data\n",
    "            labels = labels.type(torch.LongTensor) ## This is required as it expect in Long format, but for some reason after replacing label values with 0,1,2... it returned as wide format\n",
    "            images = [transform(img) for img in images] ## Apply random transformation to images\n",
    "            images = torch.stack(images)\n",
    "            images = list(images.unbind())  # Unbind the images tensor into a list of image tensors\n",
    "            images = image_processor(images=images, do_normalize = False)\n",
    "            images = torch.tensor(np.stack(images['pixel_values'], axis = 0))\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred_labels = model.forward(images)\n",
    "            pred_labels = pred_labels[0]\n",
    "\n",
    "            loss = bce_loss(pred_labels, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_train_acc += get_acc(torch.argmax(pred_labels, dim = 1).detach().cpu().numpy(), labels.detach().cpu().numpy())\n",
    "            running_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss_aug = running_train_loss / len(train_data_loader)\n",
    "        avg_train_acc_aug = running_train_acc / len(train_data_loader)\n",
    "\n",
    "        ls.append(avg_train_loss_aug)\n",
    "        ac.append(avg_train_acc_aug)\n",
    "\n",
    "        if (epoch+1)%10==0:\n",
    "            print(f'Dataset {i+1} | Epoch {epoch+1} | Adam Training Loss: {avg_train_loss_aug} | Adam Training Accuracy {avg_train_acc_aug}')\n",
    "\n",
    "    loss_results.append(ls)\n",
    "    acc_results.append(ac)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    running_test_acc = 0.\n",
    "    running_test_loss = 0.\n",
    "    \n",
    "    for g, data in enumerate(test_data_loader):\n",
    "        bce_loss = nn.CrossEntropyLoss()\n",
    "        images_test, labels_test = data\n",
    "        labels_test = labels_test.type(torch.LongTensor)\n",
    "        images_test = list(images_test.unbind())  # Unbind the images tensor into a list of image tensors\n",
    "        images_test = image_processor(images=images_test, do_normalize = False)\n",
    "        images_test = torch.tensor(np.stack(images_test['pixel_values'], axis = 0))\n",
    "        images_test, labels_test = images_test.to(device), labels_test.to(device)\n",
    "    \n",
    "        y_pred_labels = model.forward(images_test)\n",
    "        y_pred_labels = y_pred_labels[0]\n",
    "        test_loss = bce_loss(y_pred_labels, labels_test)\n",
    "    \n",
    "        running_test_loss += test_loss\n",
    "        running_test_acc += get_acc(torch.argmax(y_pred_labels, dim = 1).detach().cpu().numpy(), labels_test.detach().cpu().numpy())\n",
    "        \n",
    "        \n",
    "    avg_test_loss = running_test_loss / len(test_data_loader)\n",
    "    avg_test_acc = running_test_acc / len(test_data_loader)\n",
    "    \n",
    "    print(f'Dataset {i+1} | Adam Test Loss: {avg_test_loss} | Adam Test Accuracy {avg_test_acc}')\n",
    "    print('-'*125)\n",
    "\n",
    "    fin_test_loss_aug.append(avg_test_loss)\n",
    "    fin_test_acc_aug.append(avg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMS avg test accuracy is 0.8400000000000001 and loss is 0.5420693278312683\n",
      "Adam avg test accuracy is 0.9039999999999999 and loss is 0.5110238311812282\n"
     ]
    }
   ],
   "source": [
    "# VIT TEST WITH RMS prop VS ADAM, 3 UNFROZEN LAYERS; ViT 5 epochs\n",
    "\n",
    "fin_test_loss_aug = [x.item() for x in fin_test_loss_aug]\n",
    "fin_test_loss = [x.item() for x in fin_test_loss]\n",
    "\n",
    "\n",
    "print (f'RMS avg test accuracy is {np.mean(fin_test_acc)} and loss is {np.mean(fin_test_loss)}')\n",
    "print (f'Adam avg test accuracy is {np.mean(fin_test_acc_aug)} and loss is {np.mean(fin_test_loss_aug)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vit.embeddings.cls_token: Requires Grad - False\n",
      "vit.embeddings.position_embeddings: Requires Grad - False\n",
      "vit.embeddings.patch_embeddings.projection.weight: Requires Grad - False\n",
      "vit.embeddings.patch_embeddings.projection.bias: Requires Grad - False\n",
      "vit.encoder.layer.0.attention.attention.query.weight: Requires Grad - False\n",
      "vit.encoder.layer.0.attention.attention.query.bias: Requires Grad - False\n",
      "vit.encoder.layer.0.attention.attention.key.weight: Requires Grad - False\n",
      "vit.encoder.layer.0.attention.attention.key.bias: Requires Grad - False\n",
      "vit.encoder.layer.0.attention.attention.value.weight: Requires Grad - False\n",
      "vit.encoder.layer.0.attention.attention.value.bias: Requires Grad - False\n",
      "vit.encoder.layer.0.attention.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.0.attention.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.0.intermediate.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.0.intermediate.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.0.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.0.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.0.layernorm_before.weight: Requires Grad - False\n",
      "vit.encoder.layer.0.layernorm_before.bias: Requires Grad - False\n",
      "vit.encoder.layer.0.layernorm_after.weight: Requires Grad - False\n",
      "vit.encoder.layer.0.layernorm_after.bias: Requires Grad - False\n",
      "vit.encoder.layer.1.attention.attention.query.weight: Requires Grad - False\n",
      "vit.encoder.layer.1.attention.attention.query.bias: Requires Grad - False\n",
      "vit.encoder.layer.1.attention.attention.key.weight: Requires Grad - False\n",
      "vit.encoder.layer.1.attention.attention.key.bias: Requires Grad - False\n",
      "vit.encoder.layer.1.attention.attention.value.weight: Requires Grad - False\n",
      "vit.encoder.layer.1.attention.attention.value.bias: Requires Grad - False\n",
      "vit.encoder.layer.1.attention.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.1.attention.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.1.intermediate.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.1.intermediate.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.1.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.1.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.1.layernorm_before.weight: Requires Grad - False\n",
      "vit.encoder.layer.1.layernorm_before.bias: Requires Grad - False\n",
      "vit.encoder.layer.1.layernorm_after.weight: Requires Grad - False\n",
      "vit.encoder.layer.1.layernorm_after.bias: Requires Grad - False\n",
      "vit.encoder.layer.2.attention.attention.query.weight: Requires Grad - False\n",
      "vit.encoder.layer.2.attention.attention.query.bias: Requires Grad - False\n",
      "vit.encoder.layer.2.attention.attention.key.weight: Requires Grad - False\n",
      "vit.encoder.layer.2.attention.attention.key.bias: Requires Grad - False\n",
      "vit.encoder.layer.2.attention.attention.value.weight: Requires Grad - False\n",
      "vit.encoder.layer.2.attention.attention.value.bias: Requires Grad - False\n",
      "vit.encoder.layer.2.attention.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.2.attention.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.2.intermediate.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.2.intermediate.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.2.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.2.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.2.layernorm_before.weight: Requires Grad - False\n",
      "vit.encoder.layer.2.layernorm_before.bias: Requires Grad - False\n",
      "vit.encoder.layer.2.layernorm_after.weight: Requires Grad - False\n",
      "vit.encoder.layer.2.layernorm_after.bias: Requires Grad - False\n",
      "vit.encoder.layer.3.attention.attention.query.weight: Requires Grad - False\n",
      "vit.encoder.layer.3.attention.attention.query.bias: Requires Grad - False\n",
      "vit.encoder.layer.3.attention.attention.key.weight: Requires Grad - False\n",
      "vit.encoder.layer.3.attention.attention.key.bias: Requires Grad - False\n",
      "vit.encoder.layer.3.attention.attention.value.weight: Requires Grad - False\n",
      "vit.encoder.layer.3.attention.attention.value.bias: Requires Grad - False\n",
      "vit.encoder.layer.3.attention.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.3.attention.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.3.intermediate.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.3.intermediate.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.3.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.3.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.3.layernorm_before.weight: Requires Grad - False\n",
      "vit.encoder.layer.3.layernorm_before.bias: Requires Grad - False\n",
      "vit.encoder.layer.3.layernorm_after.weight: Requires Grad - False\n",
      "vit.encoder.layer.3.layernorm_after.bias: Requires Grad - False\n",
      "vit.encoder.layer.4.attention.attention.query.weight: Requires Grad - False\n",
      "vit.encoder.layer.4.attention.attention.query.bias: Requires Grad - False\n",
      "vit.encoder.layer.4.attention.attention.key.weight: Requires Grad - False\n",
      "vit.encoder.layer.4.attention.attention.key.bias: Requires Grad - False\n",
      "vit.encoder.layer.4.attention.attention.value.weight: Requires Grad - False\n",
      "vit.encoder.layer.4.attention.attention.value.bias: Requires Grad - False\n",
      "vit.encoder.layer.4.attention.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.4.attention.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.4.intermediate.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.4.intermediate.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.4.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.4.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.4.layernorm_before.weight: Requires Grad - False\n",
      "vit.encoder.layer.4.layernorm_before.bias: Requires Grad - False\n",
      "vit.encoder.layer.4.layernorm_after.weight: Requires Grad - False\n",
      "vit.encoder.layer.4.layernorm_after.bias: Requires Grad - False\n",
      "vit.encoder.layer.5.attention.attention.query.weight: Requires Grad - False\n",
      "vit.encoder.layer.5.attention.attention.query.bias: Requires Grad - False\n",
      "vit.encoder.layer.5.attention.attention.key.weight: Requires Grad - False\n",
      "vit.encoder.layer.5.attention.attention.key.bias: Requires Grad - False\n",
      "vit.encoder.layer.5.attention.attention.value.weight: Requires Grad - False\n",
      "vit.encoder.layer.5.attention.attention.value.bias: Requires Grad - False\n",
      "vit.encoder.layer.5.attention.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.5.attention.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.5.intermediate.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.5.intermediate.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.5.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.5.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.5.layernorm_before.weight: Requires Grad - False\n",
      "vit.encoder.layer.5.layernorm_before.bias: Requires Grad - False\n",
      "vit.encoder.layer.5.layernorm_after.weight: Requires Grad - False\n",
      "vit.encoder.layer.5.layernorm_after.bias: Requires Grad - False\n",
      "vit.encoder.layer.6.attention.attention.query.weight: Requires Grad - False\n",
      "vit.encoder.layer.6.attention.attention.query.bias: Requires Grad - False\n",
      "vit.encoder.layer.6.attention.attention.key.weight: Requires Grad - False\n",
      "vit.encoder.layer.6.attention.attention.key.bias: Requires Grad - False\n",
      "vit.encoder.layer.6.attention.attention.value.weight: Requires Grad - False\n",
      "vit.encoder.layer.6.attention.attention.value.bias: Requires Grad - False\n",
      "vit.encoder.layer.6.attention.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.6.attention.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.6.intermediate.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.6.intermediate.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.6.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.6.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.6.layernorm_before.weight: Requires Grad - False\n",
      "vit.encoder.layer.6.layernorm_before.bias: Requires Grad - False\n",
      "vit.encoder.layer.6.layernorm_after.weight: Requires Grad - False\n",
      "vit.encoder.layer.6.layernorm_after.bias: Requires Grad - False\n",
      "vit.encoder.layer.7.attention.attention.query.weight: Requires Grad - False\n",
      "vit.encoder.layer.7.attention.attention.query.bias: Requires Grad - False\n",
      "vit.encoder.layer.7.attention.attention.key.weight: Requires Grad - False\n",
      "vit.encoder.layer.7.attention.attention.key.bias: Requires Grad - False\n",
      "vit.encoder.layer.7.attention.attention.value.weight: Requires Grad - False\n",
      "vit.encoder.layer.7.attention.attention.value.bias: Requires Grad - False\n",
      "vit.encoder.layer.7.attention.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.7.attention.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.7.intermediate.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.7.intermediate.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.7.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.7.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.7.layernorm_before.weight: Requires Grad - False\n",
      "vit.encoder.layer.7.layernorm_before.bias: Requires Grad - False\n",
      "vit.encoder.layer.7.layernorm_after.weight: Requires Grad - False\n",
      "vit.encoder.layer.7.layernorm_after.bias: Requires Grad - False\n",
      "vit.encoder.layer.8.attention.attention.query.weight: Requires Grad - False\n",
      "vit.encoder.layer.8.attention.attention.query.bias: Requires Grad - False\n",
      "vit.encoder.layer.8.attention.attention.key.weight: Requires Grad - False\n",
      "vit.encoder.layer.8.attention.attention.key.bias: Requires Grad - False\n",
      "vit.encoder.layer.8.attention.attention.value.weight: Requires Grad - False\n",
      "vit.encoder.layer.8.attention.attention.value.bias: Requires Grad - False\n",
      "vit.encoder.layer.8.attention.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.8.attention.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.8.intermediate.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.8.intermediate.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.8.output.dense.weight: Requires Grad - False\n",
      "vit.encoder.layer.8.output.dense.bias: Requires Grad - False\n",
      "vit.encoder.layer.8.layernorm_before.weight: Requires Grad - False\n",
      "vit.encoder.layer.8.layernorm_before.bias: Requires Grad - False\n",
      "vit.encoder.layer.8.layernorm_after.weight: Requires Grad - False\n",
      "vit.encoder.layer.8.layernorm_after.bias: Requires Grad - False\n",
      "vit.encoder.layer.9.attention.attention.query.weight: Requires Grad - True\n",
      "vit.encoder.layer.9.attention.attention.query.bias: Requires Grad - True\n",
      "vit.encoder.layer.9.attention.attention.key.weight: Requires Grad - True\n",
      "vit.encoder.layer.9.attention.attention.key.bias: Requires Grad - True\n",
      "vit.encoder.layer.9.attention.attention.value.weight: Requires Grad - True\n",
      "vit.encoder.layer.9.attention.attention.value.bias: Requires Grad - True\n",
      "vit.encoder.layer.9.attention.output.dense.weight: Requires Grad - True\n",
      "vit.encoder.layer.9.attention.output.dense.bias: Requires Grad - True\n",
      "vit.encoder.layer.9.intermediate.dense.weight: Requires Grad - True\n",
      "vit.encoder.layer.9.intermediate.dense.bias: Requires Grad - True\n",
      "vit.encoder.layer.9.output.dense.weight: Requires Grad - True\n",
      "vit.encoder.layer.9.output.dense.bias: Requires Grad - True\n",
      "vit.encoder.layer.9.layernorm_before.weight: Requires Grad - True\n",
      "vit.encoder.layer.9.layernorm_before.bias: Requires Grad - True\n",
      "vit.encoder.layer.9.layernorm_after.weight: Requires Grad - True\n",
      "vit.encoder.layer.9.layernorm_after.bias: Requires Grad - True\n",
      "vit.encoder.layer.10.attention.attention.query.weight: Requires Grad - True\n",
      "vit.encoder.layer.10.attention.attention.query.bias: Requires Grad - True\n",
      "vit.encoder.layer.10.attention.attention.key.weight: Requires Grad - True\n",
      "vit.encoder.layer.10.attention.attention.key.bias: Requires Grad - True\n",
      "vit.encoder.layer.10.attention.attention.value.weight: Requires Grad - True\n",
      "vit.encoder.layer.10.attention.attention.value.bias: Requires Grad - True\n",
      "vit.encoder.layer.10.attention.output.dense.weight: Requires Grad - True\n",
      "vit.encoder.layer.10.attention.output.dense.bias: Requires Grad - True\n",
      "vit.encoder.layer.10.intermediate.dense.weight: Requires Grad - True\n",
      "vit.encoder.layer.10.intermediate.dense.bias: Requires Grad - True\n",
      "vit.encoder.layer.10.output.dense.weight: Requires Grad - True\n",
      "vit.encoder.layer.10.output.dense.bias: Requires Grad - True\n",
      "vit.encoder.layer.10.layernorm_before.weight: Requires Grad - True\n",
      "vit.encoder.layer.10.layernorm_before.bias: Requires Grad - True\n",
      "vit.encoder.layer.10.layernorm_after.weight: Requires Grad - True\n",
      "vit.encoder.layer.10.layernorm_after.bias: Requires Grad - True\n",
      "vit.encoder.layer.11.attention.attention.query.weight: Requires Grad - True\n",
      "vit.encoder.layer.11.attention.attention.query.bias: Requires Grad - True\n",
      "vit.encoder.layer.11.attention.attention.key.weight: Requires Grad - True\n",
      "vit.encoder.layer.11.attention.attention.key.bias: Requires Grad - True\n",
      "vit.encoder.layer.11.attention.attention.value.weight: Requires Grad - True\n",
      "vit.encoder.layer.11.attention.attention.value.bias: Requires Grad - True\n",
      "vit.encoder.layer.11.attention.output.dense.weight: Requires Grad - True\n",
      "vit.encoder.layer.11.attention.output.dense.bias: Requires Grad - True\n",
      "vit.encoder.layer.11.intermediate.dense.weight: Requires Grad - True\n",
      "vit.encoder.layer.11.intermediate.dense.bias: Requires Grad - True\n",
      "vit.encoder.layer.11.output.dense.weight: Requires Grad - True\n",
      "vit.encoder.layer.11.output.dense.bias: Requires Grad - True\n",
      "vit.encoder.layer.11.layernorm_before.weight: Requires Grad - True\n",
      "vit.encoder.layer.11.layernorm_before.bias: Requires Grad - True\n",
      "vit.encoder.layer.11.layernorm_after.weight: Requires Grad - True\n",
      "vit.encoder.layer.11.layernorm_after.bias: Requires Grad - True\n",
      "vit.layernorm.weight: Requires Grad - False\n",
      "vit.layernorm.bias: Requires Grad - False\n",
      "classifier.weight: Requires Grad - True\n",
      "classifier.bias: Requires Grad - True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import ViTModel, ViTFeatureExtractor, ViTForImageClassification\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "image_processor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "vit = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224\", return_dict=False)\n",
    "vit = vit.to(device)\n",
    "for param in vit.parameters():\n",
    "    param.requires_grad = False\n",
    "vit.classifier = nn.Linear(768,64).to(device) # Chaning final output layer to map our problem\n",
    "model = vit # Initialize the model structure\n",
    "model.load_state_dict(torch.load('vit_model_5ep.pt', map_location=torch.device('cpu')))\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if 'encoder.layer.9' in name or 'encoder.layer.10' in name or 'encoder.layer.11' in name:\n",
    "        param.requires_grad = True\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: Requires Grad - {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If its possible, you can evaluate on the other datasets such as CropDiseases, CUB, ISIC, ChestX, etc. (This part will be used as a bonus item, 2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on other datasets\n",
    "# CropDiseases / CUB / ISIC / ChestX / etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
